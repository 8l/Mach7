\documentclass[preprint]{sigplanconf}

\usepackage{breakurl}             % Not needed if you use pdflatex only.
\usepackage{listings}

\lstdefinestyle{Caml}{language=Caml,%
  literate={when}{{{\bf when}}}4
}

\lstdefinestyle{C++}{language=C++,%
showstringspaces=false,
  columns=fullflexible,
  escapechar=@,
  basicstyle=\sffamily,
%  commentstyle=\rmfamily\itshape,
  moredelim=**[is][\color{white}]{~}{~},
  literate={[<]}{{\textless}}1      {[>]}{{\textgreater}}1 %
           {<}{{$\langle$}}1        {>}{{$\rangle$}}1 %
           {<=}{{$\leq$}}1          {>=}{{$\geq$}}1          {!=}{{$\neq$}}1 %
           {=>}{{$\Rightarrow\;$}}1 {->}{{$\rightarrow{}$}}1 %
           {<:}{{$\subtype{}\ $}}1  {<-}{{$\leftarrow$}}1 %
           {Match}{{\emph{Match}}}5 %
           {EndMatch}{{\emph{EndMatch}}}8 %
           {Case}{{\emph{Case}}}4 %
           {CM}{{\emph{CM}}}2 {KS}{{\emph{KS}}}2 {KV}{{\emph{KV}}}2 
}
\lstset{style=C++}
\DeclareRobustCommand{\code}[1]{{\lstinline[breaklines=false]{#1}}}
\DeclareRobustCommand{\codehaskell}[1]{{\lstinline[breaklines=false,language=Haskell]{#1}}}
\DeclareRobustCommand{\codeocaml}[1]{{\lstinline[breaklines=false,language=Caml]{#1}}}

\begin{document}

\conferenceinfo{DSL 2011}{Bordeaux, France} 
\copyrightyear{2011} 
\copyrightdata{[to be supplied]} 

\titlebanner{Technical Report}        % These are ignored unless
\preprintfooter{Y.Solodkyy, G.Dos Reis, B.Stroustrup: Pattern Matching for C++}   % 'preprint' option specified.

\title{Pattern Matching for C++}
%\subtitle{your \code{visit}, Jim, is not \code{accept}able anymore}

\authorinfo{Yuriy Solodkyy\and Gabriel Dos Reis\and Bjarne Stroustrup}
           {Texas A\&M University\\ Texas, USA}
           {\{yuriys,gdr,bs\}@cse.tamu.edu}

\maketitle

\begin{abstract}
Pattern matching has been known in functional programming community as an 
abstraction mechanism that greatly simplifies the code. Following the success of 
functional languages, several imperative programming languages had introduced 
pattern matching into them. While this is relatively easy to do a-priori, when 
designing a new language, this might become quite a challenge to do a-posteriori 
when trying to introduce it into an industry strength language like C++. We 
present functional style pattern matching for C++ implemented as a library. 
Depending on a use case, our solution matches our outperforms its de facto 
contender -- the visitor design pattern, traditionally used in pattern matching 
scenarios in C++. Unlike the visitor pattern, our solution is non-intrusive, 
open to new classes, avoids the control inversion and is much more concise, 
easier to read, maintain and comprehend. It also mimics many of the pattern 
matching facilities available in other languages on the first class basis, 
letting us experiment with them without any changes to the compiler. The 
solution can be reused in other object-oriented languages to implement
\emph{type switching}, \emph{type testing}, \emph{pattern matching} and 
\emph{multiple dispatch} efficiently.
\end{abstract}

\category{CR-number}{subcategory}{third-level}

\terms
Languages, Design

\keywords
Pattern Matching, Visitor Design Pattern, Expression Problem, C++

\section{Introduction} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:intro}

%Motivate the problem
%Give a summary of the paper: what you did and how
%Explicitly state your contribution

Pattern matching is an abstraction supported by many programming languages, which 
allows the user to describe in a breve manner a (possibly infinite) set of 
values accepted by the pattern. Pattern represents effectively a predicate on 
values, and is usually expected to be much more concise and readable than the 
equivalent predicate spelled out directly.

Popularized by functional programming community, most notably Hope\cite{BMS80}, 
ML\cite{ML90}, Miranda\cite{Miranda85} and Haskell\cite{Haskell98Book}, for 
providing syntax very close to mathematical notations, pattern matching has 
since been making its way into many imperative programming languages like 
Pizza\cite{Odersky97pizzainto}, Scala\cite{Scala2nd}, Fortress\cite{RPS10}, 
Java\cite{Liu03jmatch:iterable,HydroJ2003}, C++\cite{Prop96}, 
Eiffel\cite{Moreau:2003} and others. While this is relatively
easy to do a-priori when designing a new language, the introduction of pattern 
matching into an industry strengths language a-posteriori might become a 
challenge. The obvious utility of the feature may be overshadowed by the 
complications in the language semantics necessary to make pattern matching work 
with other features of the language. A prototype implementation will likely 
require a lot of effort, but will be hard to publish due to lack of novelty.

To balance the utility and effort we decided to start with a Semantically 
Enhanced Library Language\cite{SELL} approach, that promotes subsetting a 
general-purpose programming language with a library, extended with a tool 
support. This will typically not provide you 100\% of the functionality that a 
language extension would do, but will rather give you 80\% of it at 20\% of the 
time. This turned out to be a very economic decision as we ended up not requiring 
any external tool support at all, while providing a descent level of convenience 
and a great performance.

Naturally, our library-only solution has limitations and inconveniencies that 
stem from the fact that we work in a SELL setting. We are certain, however, that 
those can be easily overcome in a language solution and we provide relevant 
discussions when necessary. We regard our current solution as a proof of  
concept that sets the minimum threshold for performance, brevity, clarity and 
usefulness of the ultimate language solution for pattern matching in C++. It is 
a fully functional transitional facility, that lets users experiment with 
pattern matching in C++, while letting us experiment with and eventually shape 
the language solution.

To give a quick taste of what our library enables, let us look at an example from 
the domain where pattern matching is known to cut the edge of laconism and 
clarity -- compiler construction. Imagine a simple language of expressions:

\begin{lstlisting}
exp ::= val | exp + exp | exp - exp | exp * exp | exp / exp
\end{lstlisting}

OCaml data type describing this grammar as well as simple evaluator of expressions 
in it can be declared as following:

\begin{lstlisting}[language=Caml,keepspaces,columns=flexible]
type expr = Value  of int
          | Plus   of expr * expr
          | Minus  of expr * expr
          | Times  of expr * expr
          | Divide of expr * expr
          ;;

let rec eval e =
  match e with
            Value  v      -> v
          | Plus   (a, b) -> (eval a) + (eval b)
          | Minus  (a, b) -> (eval a) - (eval b)
          | Times  (a, b) -> (eval a) * (eval b)
          | Divide (a, b) -> (eval a) / (eval b)
          ;;
\end{lstlisting}

The corresponding C++ data types are slightly more verbose, though the only 
reason we have not parameterized them was to keep the example simple.

\begin{lstlisting}[keepspaces,columns=flexible]
struct Expr { virtual @$\sim$@Expr() {} };
struct Value  : Expr { int value; };
struct Plus   : Expr { Expr* exp1; Expr* exp2; };
struct Minus  : Expr { Expr* exp1; Expr* exp2; };
struct Times  : Expr { Expr* exp1; Expr* exp2; };
struct Divide : Expr { Expr* exp1; Expr* exp2; };
\end{lstlisting}

Together with evaluator presented below, they form an instance of the 
\emph{Interpreter Design Pattern}\cite{DesignPatterns1993}. Unlike the type 
definitions, the evaluator for the language, implemented on top of our pattern 
matching library is almost as laconic as its version in OCaml:

\begin{lstlisting}[keepspaces,columns=flexible]
int eval(const Expr* e)
{
    Match(e)@\footnote{We use alternative formatting on symbols representing preprocessor macros}@
    {
    Case(Value,  n)    return n;
    Case(Plus,   a, b) return eval(a) + eval(b);
    Case(Minus,  a, b) return eval(a) - eval(b);
    Case(Times,  a, b) return eval(a) * eval(b);
    Case(Divide, a, b) return eval(a) / eval(b);
    }
    EndMatch
}
\end{lstlisting}

The only definitions we omitted here that prevent the example from being fully 
functional are the mappings of class members to corresponding binding positions. 
We list them here for completeness, while their meaning will be explained later 
in section~\ref{}. Here we would like to mention though that these definitions are only 
needed to support the variables binding and not the type switching functionality 
of the \code{Match}.

\begin{lstlisting}[keepspaces,columns=flexible]
template <> struct bindings<Value>  { CM(0,Value::value); };
template <> struct bindings<Plus>   { CM(0,Plus::exp1); 
  ...                                 CM(1,Plus::exp2);   };
template <> struct bindings<Divide> { CM(0,Divide::exp1); 
                                      CM(1,Divide::exp2); };
\end{lstlisting}

The above syntax is enabled without any external tool support using new C++0x 
features\cite{C++0x}, template meta-programming and macros. As we 
show in section~\ref{sec:eval}, it runs up to 80\% faster (depending on the usage 
scenario, compiler and underlain hardware) than a similar code crafted with the 
\emph{Visitor Design Pattern}.

\subsection{Motivation}

%\subsection{Excursus}

The ideas and the library presented here originated from our rather 
unsatisfactory experience in working with various C++ front-ends and program 
analysis frameworks developed in C++\cite{Pivot09,Phoenix,Clang,Lise}. The 
problem was not in the frameworks per se, but in the fact that we had to use 
\emph{Visitor Design Pattern}\cite{DesignPatterns1993} to inspect, traverse and 
elaborate abstract syntax trees of their target languages. Having written enough 
visitors to realize how unsuitable they were for the job, we started looking for 
other mechanisms to work with abstract syntax trees, even if they would have 
turned out to be significantly slower. 
Presence of dynamic casts in many places, often nested, to answer simple 
structural questions without having to resort to visitors, was a strong 
indicator that even though visitors were fast, in many non-critical cases 
users preferred shorter, cleaner and a more clear code to performance.
The usage of \code{dynamic\_cast} in those cases resembled the use of 
pattern matching in functional languages to unpack algebraic data types. 
Functional languages have been long known to be very suitable for developing 
program analysis tools because of the brevity with which the necessary 
algorithms can be expressed. This is why our initial goal was to develop a 
domain-specific library within C++ that would enable us to express various 
predicates on tree-like structures with the laconism of functional languages.

%[From Emir PhD Thesis 1.3]
%In the context of the JAVA virtual machine (and any other object system that supports runtime
%type information), a much more direct way of obtaining the dynamic type of a value is
%to use an instanceof-check. Although these are considered bad style, programmers make
%use of them frequently, in order to avoid the overhead of using a Visitor implementation.
%They are error prone since it is possible to perform a cast without a preceding check.

\subsection{Visitor Design Pattern}
\label{sec:vdp}

%Discuss visitor design pattern and its problems.
%\begin{itemize}
%\item Intrusive - requires changes to the hierarchy
%\item Not open  - addition of new classes changes visitor interface
%\item Doesn't provide by default relation between visitors of base and derived classes
%\item Control inversion
%\item Cannot be generically extended to handling n arguments
%\end{itemize}

%[From Extensible Algebraic Datatypes with Defaults]
%In the object-oriented approach, data is modelled by a set of classes, sharing 
%a common interface. Each subclass defines its own implementation of eval. Whereas
%extending the datatype with new variants is simply done by
%creating new classes, adding new operations involves modifications
%of the abstract base class.

\emph{Visitor Design Pattern}\cite{DesignPatterns1993} was devised to solve a problem 
of extending existing classes with new functions in object-oriented languages. 
Consider the above Expr example and imagine we would like to provide a pretty 
printing of expressions. A typical object-oriented approach would be to 
introduce a virtual function \code{virtual void print() const = 0;} inside the 
abstract base class \code{Expr}, which will be implemented correspondingly in all derived 
classes. This works well as long as we know all the required operations on the 
abstract class in advance. Unfortunately, this is very difficult to achieve in 
reality as the code evolves, especially in production environment. To put this 
in context, imagine that after the above interface with pretty printing 
functionality has been deployed, we decided that we need a similar functionality 
that saves the expression in XML format. Adding new virtual function implies 
modifying the base class and creating a versioning problem with the code that 
has been deployed already using the old interface.

To alleviate this problem, Visitor Design Pattern separates the 
\emph{commonality} of all such future member-functions from their 
\emph{specifics}. The former deals with identifying the most specific derived 
class of the receiver object, known to the system at the time the base class was 
designed. The latter provides implementation of the required functionality once 
the most specific derived class has been identified. The interaction between the 
two is encoded in the protocol that fixes \emph{visitation interface} 
enumerating all known derived classes on one side and a dispatching mechanism 
that guarantees to select the most specific case with respect to the dynamic 
type of the receiver in the visitation interface. An implementation of this 
protocol for our Expr example might look as following:

\begin{lstlisting}
// Forward declaration of known derived classes
struct Value; struct Plus; ... struct Divide;
// Visitation interface
struct ExprVisitor
{
    virtual void visit(const Value&)  = 0;
    virtual void visit(const Plus&)   = 0;
    ...  // One virtual function per each known derived class
    virtual void visit(const Divide&) = 0;
};
// Abstract base and known derived classes
struct Expr { 
    virtual void accept(ExprVisitor&) const = 0; };
struct Value : Expr { ...
    void accept(ExprVisitor& v) const { v.visit(*this); } };
struct Plus  : Expr { ...
    void accept(ExprVisitor& v) const { v.visit(*this); } };
\end{lstlisting}

Note that even though implementations of \code{accept} member-functions are 
syntactically identical, a different \code{visit} is called. We rely here on the 
overload resolution mechanism of C++ to pick the most specialized \code{visit} 
member-function applicable to the static type of \code{*this}. This mere code 
maintenance convenience unfortunately, often confuses novices on what 
is going on. We thus would like to point out that member-functions in the 
visitation interface are not required to be called with the same name, -- we 
could have equally well called them \code{visit_value}, \code{visit_plus} etc. 
making the corresponding changes to calls inside \code{Value::accept}, 
\code{Plus::accept} etc.

A user can now implement his new functions similarly to the following function 
to convert expressions to string:

\begin{lstlisting}
std::string to_str(const Expr* e); // Forward declaration

struct ToStrVisitor : ExprVisitor
{
    void visit(const Value& e) { result = std::to_string(e.value); }
    ...
    void visit(const Divide& e) { 
        result = to_str(e.exp1) + '/' + to_str(e.exp2); 
    }
    std::string result;
};
// Actual implementation based on visitor
std::string to_str(const Expr* e)
{
    ToStrVisitor v;
    e->accept(v);
    return v.result;
}
\end{lstlisting}

Function \code{eval} we presented above as well as any new function that we 
would like to add to \code{Expr} can now be implemented in much the same way, 
without the need to change base interface. This flexibility does not come for 
free though and we would like to point out some pros and cons of this solution.

The most important advantage of the visitor design pattern is possibility to add 
new operations to the class hierarchy without the necessity to change the 
interface each time. It's second most quoted advantage is typically speed -- the 
overhead of two virtual function calls incurred by the double dispatch present 
in the visitor design pattern is often negligible on the modern architectures. 
There are quite a few disadvantages however.

The {\bf increased amount of boilerplate code} that has to be added to support 
the above solution cannot go unnoticed. Several entities had to be forward 
declared because of the mutual recursivity of their definitions. The solution is 
{\bf specific to hierarchy}, as we had to declare a visitation interface 
specific to the base class. It is also {\bf intrusive} since we had to inject 
syntactically the same definition of \code{accept} method into every class 
participating in visitation. The amount of the necessary support increases, as 
additional arguments have to be passed into the visitor to be available during 
the visitation. This aspect can be seen in the example from 
section~\ref{sec:xmpl} where we have to store both functors inside the visitor.  

More importantly, visitors {\bf hinder extensibility} of the class hierarchy: 
new classes added to the hierarchy after the visitation interface has been 
fixed, will be treated as their most derived base class present in the interface.
A solution to this problem has been proposed in the form of \emph{Extensible 
Visitors with Default Cases}\cite[\textsection 4.2]{Zenger:2001}, however the solution, after 
remapping it onto C++, has problems of its own. The visitation interface 
hierarchy can easily be grown linearly (adding new cases for the new classes in 
the original hierarchy each time), but independent extensions by different  
authorities require developer's intervention to unify them all, before they can 
be used together. This may not be feasible in environments that use dynamic 
linking. To avoid writing even more boilerplate code in new visitors, the 
solution would require usage of virtual inheritance, which typically has 
an overhead of extra memory dereferencing. On top of the double dispatch already 
present in the visitor pattern, the solution will incur two additional virtual 
calls and a dynamic cast for each level of visitor extension. Additional double 
dispatch is incurred by forwarding of default handling from base visitor to a 
derived one, while the dynamic cast is required for safety and can be replaced 
with a static case when visitation interface is guaranteed to be grown linearly 
(extended by one authority only). Yet another virtual call is required to be 
able to forward computations to subcomponents on tree-like structures to the 
most derived visitor. This last function lets one avoid the necessity of using 
heap to allocate a temporary visitor through the \emph{Factory Design 
Pattern}\cite{DesignPatterns1993} used in \emph{Extensible Visitor} solution 
originally proposed by Krishnamurti, Felleisen and Friedman\cite{Krishnamurthi98}.

Once all the boilerplate related to visitors has been written and the visitation 
interface has been fixed we are still left with some annoyances incurred by the 
pattern. One of them is the necessity to work with the {\bf control inversion} 
that visitors put in place. Because of it we have to save any local state and 
any arguments that some of the \code{visit} callbacks might need from the 
calling environment. Similarly, we have to save the result of the visitation, 
as we cannot assume that all the visitors that will potentially be implemented 
on a given hierarchy will use the same result type. Using visitors in a generic 
algorithm requires even more precautions. We summarize these visitor-related 
issues in the following motivating example, followed by an illustration of a 
pattern matching solution to the same problem enabled with our library.

%[From The Essence of the Visitor Pattern]
%For object-oriented programming, the Visitor pattern en-
%ables the denition of a new operation on an object structure without
%changing the classes of the objects. The price has been that the set of
%classes must be xed in advance, and they must each have a so-called
%accept method.

%[From Emir PhD Thesis 1.4.2]
%Apart from readability and safety, a high-level construct for pattern matching provides opportunities
%for optimization and for static checks.
%A drawback of all object-oriented solutions above is that standard compilers do not check
%whether such hand-crafted case distinction based on type-tests and type-casts cover all the
%cases, nor whether all branches can actually be entered. Pattern matching constructs in functional
%programming languages can be checked statically for incompleteness and redundancy,
%which helps catch many programmer mistakes.

\subsection{Motivating Example}
\label{sec:xmlp}

While comparing generic programming facilities available to functional and 
imperative languages (mainly Haskell and C++), Dos Reis and Jarvi present the 
following example in Haskell describing a sum functor\cite{DRJ05}:

\begin{lstlisting}[language=Haskell]
data Either a b = Left a | Right b

eitherLift :: (a -> c) -> (b -> d) -> Either a b -> Either c d
eitherLift f g (Left  x) = Left  (f x)
eitherLift f g (Right y) = Right (g y)
\end{lstlisting}

In simple words, the function \codehaskell{eitherLift} above takes two functions and an 
object and depending on the actual type constructor the object was created with, 
calls first or second function on the embedded value, encoding the result 
correspondingly.

Its equivalent in C++ is not as straightforward. The idiomatic handling of 
discriminated unions in C++ typically assumes use of the \emph{Visitor Design 
Pattern}\cite{DesignPatterns1993}.

\begin{lstlisting}
template <class X, class Y> class Either;
template <class X, class Y> class Left;
template <class X, class Y> class Right;

template <class X, class Y>
struct EitherVisitor {
    virtual void visit(const  Left<X,Y>&) = 0;
    virtual void visit(const Right<X,Y>&) = 0;
};

template <class X, class Y>
struct Either {
    virtual @$\sim$@Either() {}
    virtual void accept(EitherVisitor<X,Y>& v) const = 0;
};

template <class X, class Y>
struct Left : Either<X,Y> {
    const X& x;
    Left(const X& x) : x(x) {}
    void accept(EitherVisitor<X,Y>& v) const { v.visit(*this); }
};

template <class X, class Y>
struct Right : Either<X,Y> {
    const Y& y;
    Right(const Y& y) : y(y) {}
    void accept(EitherVisitor<X,Y>& v) const { v.visit(*this); }
};
\end{lstlisting}

The code above defines the necessary parameterized data structures as well as a 
correspondingly parameterized visitor class capable of introspecting it at 
run-time. The authors agree with us \emph{``The code has a fair amount of 
boilerplate to simulate pattern matching...''} The actual implementation of 
\codehaskell{lift} in C++ now amounts to declaring and invoking a visitor:

\begin{lstlisting}
template <class X, class Y, class S, class T>
const Either<S,T>& lift(const Either<X,Y>& e, S f(X), T g(Y))
{
    typedef S (*F)(X);
    typedef T (*G)(Y);
    struct Impl : EitherVisitor<X,Y> {
        F f;
        G g;
        const Either<S,T>* value;
        Impl(F f, G g) : f(f), g(g), value() {}
        void visit(const Left<X,Y>& e) {
            value = left<S,T>(f(e.x));
        }
        void visit(const Right<X,Y>& e) {
            value = right<S,T>(g(e.y));
        }
    };
    Impl vis(f, g);
    e.accept(vis);
    return *vis.value;
}
\end{lstlisting}

The same function expressed with our pattern matching facility seems to be much 
closer to the original Haskell definition:

\begin{lstlisting}[keepspaces,columns=flexible]
template <class X, class Y, class S, class T>
const Either<S,T>* lift(const Either<X,Y>& e, S f(X), T g(Y))
{
    Match@$^T$@(e)@\footnote{T indicates that the user will have to use TMatch, TCase and TEndMatch versions of the macros respectively since the substituted code has to be correct in the template environment}@
      Case(( Left<X,Y>), x)  return  left<S,T>(f(x));@\footnote{We need to take the first argument in parentheses to avoid interpretation of comma in template argument list by the preprocessor}@
      Case((Right<X,Y>), y)  return right<S,T>(g(y));
    EndMatch
}
\end{lstlisting}

It is also as fast as the visitor solution, but unlike the visitors based 
approach neither requires \code{EitherVisitor} class anymore (together with 
forward declarations it needed), nor any of the \code{accept} member-functions 
injected in all three classes. We do require binding definitions though to be 
able to bind variables \code{x} and \code{y}:
\footnote{Definitions of obvious functions \code{left} and \code{right} have 
been ommitted in both cases.}

\begin{lstlisting}[keepspaces,columns=flexible]
template <class X, class Y> 
    struct bindings<Left<X,Y>>  { CM(0, Left<X,Y>::x); };
template <class X, class Y> 
    struct bindings<Right<X,Y>> { CM(0,Right<X,Y>::y); };
\end{lstlisting}

Note that these binding definitions are made once for all possible instantiations 
with the use of partial template specialization in C++.

\subsection{Summary}

The contributions of the paper can be summarized as following:

\begin{itemize}
\item We present a technique that can be used to implement type switching 
      effectively based on the run-time type of the argument. 
  \begin{itemize}
  \item The technique outperforms its de facto contender -- visitor design 
        pattern without sacrificing extensibility.
  \item It works in the presence of multiple inheritance, including repeated and 
        virtual inheritance as well as in generic code.
  \item The technique generalizes to other object-oriented languages that use 
        virtual tables to implement dynamic dispatch.
  \end{itemize}
\item We present a functional style pattern matching for C++ built as a library 
      employing the above technique.
  \begin{itemize}
  \item The solution is open, non-intrusive and can be applied to any class 
        hierarchy retroactively.
  \item It allows one to avoid the control inversion typical for visitors.
  \item We provide performance and ease of use comparison based on real code.
  \end{itemize}
\end{itemize}

The novelty of the paper lays in a new method that can be used by compilers of 
object-oriented languages as well as libraries written in them to implement 
\emph{type switching}, \emph{type testing}, \emph{pattern matching} and 
\emph{multiple dispatch} efficiently. We look at different approaches that are 
taken in implementing algebraic data types in C++ today and present a unified 
pattern matching syntax that works uniformly with all of them. We also 
generalize Haskell's n+k patterns to any invertible operations. Semantics issues 
that typically accompany n+k pattern are handled transparently by forwarding the 
problem into the concepts domain, thanks to the fact that we work in a library 
setting. A practical benefit of our solution is that it can be used right away 
with any compiler with a descent support of C++0x without requiring to install 
any additional tools or preprocessors.

The rest of this paper is structured as following. In Section~\ref{sec:bg}, we 
present evolution of pattern matching in different languages, presenting 
informally through example commonly used terminology and semantics of various 
pattern matching facilities. Section~\ref{sec:pm} presents various approaches 
that are taken in C++ to implementing algebraic data types as well as 
demonstrates uniform handling of them in our pattern matching library. 
Section~\ref{sec:impl} discusses the \emph{v-table caching} technique that made 
the efficient implementation of pattern matching possible, while 
Section~\ref{sec:eval} provides performance evaluation of this technique against 
common alternatives. Section~\ref{sec:rw} discusses some related work, while 
Section~\ref{sec:cc} concludes by discussing some future directions and possible 
improvements.

\section{Background} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:bg}

%[From Emir PhD 1.1]
%In functional programming languages, pattern matching has been closely related to algebraic
%data types since its beginning - Burstall\cite{Burstall69provingproperties} is the first to define a pattern matching
%construct that resembles the one found in statically typed functional languages today.

Pattern matching in the context of a programming language was first introduced 
in a string manipulation language SNOBOL\cite{SNOBOL64}. Its fourth 
reincarnation SNOBOL4 had patterns as first-class data types providing 
operations of concatenation and alternation on them\cite{SNOBOL71}. The first 
reference to a pattern matching construct that resembles the one found in 
statically typed functional languages today is usually attributed to Burstall 
and his work on structural induction\cite{Burstall69provingproperties}.

%[From Emir PhD thesis 1.6]
%The SCALA compiler is the effort of several researchers, and combining pattern matching
%and object-oriented programming has been approached before\cite{Odersky97pizzainto,Zenger:2001}.

In the context of object-oriented programming, pattern matching has been first 
explored in Pizza programming language\cite{Odersky97pizzainto}. These efforts 
have been continued in Scala\cite{Scala2nd} and together with notable work of 
Burak Emir on \emph{Object-Oriented Pattern Matching}\cite{EmirThesis} have 
resulted in incorporation of pattern matching into the language.

%The first tree based pattern matching methods were found in Fred McBride's 
%extension of LISP in 1970.

%ML and Haskell further popularized pattern matching ...

Pattern matching has been closely related to \emph{algebraic data types} and 
\emph{equational reasoning} since the early days of functional programming.
In languages like ML and Haskel an \emph{Algebraic Data Type} is a data type 
each of whose values is picked from a disjoint sum of (possibly recursive) data 
types, called \emph{variants}. Each of the variants is marked with a unique 
symbolic constant called \emph{constructor}. Constructors provide a 
convenient way of creating a value of its variant type as well as a way of 
discriminating its variant type from the algebraic data type through pattern 
matching.

Algebraic data type \codeocaml{expr} from Section~\ref{sec:intro} consists of 5 
variants, marked with constructors \codeocaml{Value}, \codeocaml{Plus}, 
\codeocaml{Minus}, \codeocaml{Times} and \codeocaml{Divide} respectively. 
Constructor \codeocaml{Value} expects a value of type \codeocaml{int} during 
construction, as well as any pattern that admits values of type \codeocaml{int} 
during decomposition through pattern matching. Similarly, the other four 
constructors expect a value of a cartesian product of two \codeocaml{expr} 
types during construction, as well as any pattern that would admit a value of 
such type during decomposition.

Algebraic data types can be parameterized and recursive, as demonstrated by the 
following Haskell code that defines a binary tree parameterized on type 
\codehaskell{k} of keys and type \codehaskell{d} of data stored in the nodes:

\begin{lstlisting}[language=Haskell]
data Tree k d = Node k d (Tree k d) (Tree k d) | Leaf
\end{lstlisting}

Naturally, they can be decomposed in a generic algorithm like the function 
\code{find} below, defined through case analysis on the tree's structure:

\begin{lstlisting}[language=Haskell]
find :: (Ord k) => k -> Tree k d -> Maybe d
find i Leaf = Nothing
find i (Node key item left right) = 
    if i == key 
    then Just item 
    else 
        if i [<] key 
        then find i left 
        else find i right
\end{lstlisting}

The set of values described by a given algebraic data type is defined 
inductively as the least set closed under constructor functions of its variants.
Algebraic data types draw their name from the practice of using case distinction 
in mathematical function definitions and proofs that involve \emph{algebraic 
terms}.

One of the main differences of algebraic data types from classes in 
object-oriented languages is that an algebraic data type definition is 
\emph{closed} because it fixes the structure of its instances once and for all. 
Once we have listed all the variants a given algebraic data type may have we 
cannot extend it with new variants without modifying its definition. This is not 
the case in object-oriented languages, where classes are \emph{open} to 
extension through subclassing. 

Closeness of algebraic data types is particularly useful in reasoning about 
programs by case analysis and allows the compiler to perform an automatic 
\emph{incompleteness} check -- test of whether a given match expression covers all 
possible cases. A related notion of \emph{redundancy} checking arises from the 
tradition of using \emph{first-fit} strategy in pattern matching. It warns the 
user of any \emph{case clause} inside a \emph{matching expression} that will 
never be entered because of preceding one being more general. Object-oriented 
languages, especially C++, typically prefer \emph{best-fit} strategy (e.g. for 
overload resolution and class template specialization) because it is not prone 
to errors where semantics of a statement might change depending on the ordering 
of preceding definitions. The notable exception in C++ semantics that prefers 
the \emph{first-fit} strategy is ordering of \code{catch} handlers of a 
try-block. Similarly to functional languages the C++ compiler will perform 
\emph{redundancy} checking on catch handlers and issue a warning that lists the 
redundant cases.

%[From Emir PhD 1.4.2]
%Incompleteness describes a match expression that does not cover all cases, 
%whereas redundancy indicates a case that can never be entered because of a 
%preceding one being more general. 

%The constructor tags are special cases of T, which provides a relationship between the set
%of instances tagged with a particular constructor and the set of instances of T that is akin
%to nominal (explicitly declared) subtyping. One major difference is that an algebraic data
%type forms a "closed world": the set of constructors and their signature cannot be changed.
%The reason for this restriction ist that an algebraic data types defines a sum type and allows
%straightforward reasoning on its fixed structure. A welcome consequence of this restriction
%is that algebraic data types can be represented efficiently by replacing constructor tags with
%an integer constant.

%Since the set of constructors forms a closed world, an automatic check for incompleteness
%can be performed on match expressions: The compiler can thus warn programmers who by
%mistake omit a case from their match expressions, which would leave the match expression
%incomplete. This check is very helpful if there are many constructors or when nested patterns
%allow for combinatorial combinations of algebraic data types (e.g. for a pair of two SrchT
%instances).

%[From Emir PhD 2.1.1]
%In typed functional programming languages like HOPE [14], MIRANDA [90], HASKELL [47]
%and ML [64], users can define concrete data types as disjoint sums of primitive types, tuples
%and function types. Each variant, or constructor, is identified with a symbolic constant.
%Such data types can then be discriminated using patterns, which mention the constructor
%label along with a collection of sub-patterns or variables to bind the constituents of a matching
%instance. This data definition mechanism should be considered as a building block for
%the wider goal of functional programming, which is give clear semantics to data and enable
%equational reasoning about programs.
%
%Algebraic data types like SrchT are defined inductively as the least set closed under their
%constructor functions.

The patterns that work with algebraic data types we have seen so far are 
generally called \emph{tree patterns} or \emph{data constructor patterns}. 
Special cases of these patterns are \emph{list patterns} and \emph{tuple 
patterns}. The former lets one split a list into a sequence of elements in its 
beginning and a tail with the help of list constructor \codehaskell{:} and an 
empty list constructor \codehaskell{[]} e.g. \codehaskell{[x:y:rest]}. The 
latter does the same with tuples using tuple constructor 
\codehaskell{(,,...,)} e.g. \codehaskell{([x:xs],'b',(1,2.0),"hi",True)}.

Pattern matching is not used solely with algebraic data types and can equally 
well be applied to built-in types. The following Haskell code defines factorial 
function in the form of equations:

\begin{lstlisting}[language=Haskell]
factorial 0 = 1
factorial n = n * factorial (n-1)
\end{lstlisting}

Here 0 in the left hand side of the first \emph{equation} is an example of a 
\emph{value pattern} (also known as \emph{constant pattern}) that will only 
match when the actual argument passed to the function factorial is 0. The 
\emph{variable pattern} \codehaskell{n} (also referred to as \emph{identifier 
pattern}) in the left hand side of the second equation will match any value, 
\emph{binding} variable \codehaskell{n} to that value in the right hand side of 
equation. Similarly to variable  
pattern, \emph{wildcard pattern} \codehaskell{_} will match any value with the 
exception that the matched value will not be bound to any variable. Value 
patterns, variable patterns and wildcard patterns are generally called 
\emph{primitive patterns}. Patterns like variable and wildcard patterns that 
never fail to match are called \emph{irrefutable}, in contrast to 
\emph{refutable} patterns like value patterns, which may fail to match.

In Haskell 98\cite{Haskell98Book} the above definition of factorial could also 
be written as:

\begin{lstlisting}[language=Haskell]
factorial 0 = 1
factorial (n+1) = (n+1) * factorial n
\end{lstlisting}

The \codehaskell{(n+1)} pattern in the left hand side of equation is an example of 
\emph{n+k pattern}. Accordingly to its informal semantics ``Matching an $n+k$ 
pattern (where $n$ is a variable and $k$ is a positive integer literal) against 
a value $v$ succeeds if $v \ge k$, resulting in the binding of $n$ to $v-k$, and 
fails otherwise''\cite{haskell98}. n+k patterns were introduced into Haskel to 
let users express inductive functions on natural numbers in much the same way as 
functions defined through case analysis on algebraic data types. Besides 
succinct notation, such language feature could facilitate automatic proof of 
termination of such functions by compiler. Peano numbers, used as an analogy to 
algebraic data type representation of natural numbers, is not always the best 
abstraction for representing other mathematical operations however. This,  
together with numerous ways of defining semantics of generalized n+k patterns 
were some of the reasons why the feature was never generalized in Haskell to 
other kinds of expressions, even though there were plenty of known applications. 
Moreover, numerous debates over semantics and usefulness of the feature 
resulted in n+k patterns being removed from the language altogether in Haskell 
2010 standard\cite{haskell2010}. Generalization of n+k patterns, called 
\emph{application patterns} has been studied by Nikolaas N. Oosterhof in his 
Master's thesis\cite{OosterhofThesis}.

While n+k patterns were something very few languages had, another common feature of 
many programming languages with pattern matching are guards. A \emph{guard} 
is a predicate attached to a pattern that may make use of the variables bound in 
it. The result of its evaluation will determine whether the case clause and the 
body associated with it will be \emph{accepted} or \emph{rejected}. The 
following OCaml code for $exp$ language from Section~\ref{sec:intro} defines the 
rules for factorizing expressions $e_1e_2+e_1e_3$ into $e_1(e_2+e_3)$ and 
$e_1e_2+e_3e_2$ into $(e_1+e_3)e_2$ with the help of guards spelled out after 
keyword \codeocaml{when}:

\begin{lstlisting}[language=Caml,keepspaces,columns=flexible]
let factorize e =
    match e with
      Plus(Times(e1,e2), Times(e3,e4)) when e1 = e3 
          -> Times(e1, Plus(e2,e4))
    | Plus(Times(e1,e2), Times(e3,e4)) when e2 = e4 
          -> Times(Plus(e1,e3), e4)
    |   e -> e
    ;;
\end{lstlisting}

One may wonder why could not we simply write the above case clause as 
\codeocaml{Plus(Times(e,e2), Times(e,e4))} to avoid the guard? Patterns that 
permit use of the same variable in them multiple times are called 
\emph{equivalence patterns}, while the requirement of absence of such patterns 
in a language is called \emph{linearity}. Unfortunately, neither OCaml nor 
Haskell support such patterns. Miranda\cite{Miranda85} is one of the languages 
that permit them. 

The example above illustrates yet another common pattern matching facility -- 
\emph{nesting of patterns}. With a simple expression in the case clause we 
define a predicate that tests the top-level expression to be tagged with a
\codeocaml{Plus} constructor, while both of its arguments to be marked with 
\codeocaml{Times} constructor, binding their arguments (or potentially pattern 
matching further) respectively. Note that the visitor design pattern does not 
provide this level of flexibility and each of the nested tests might have 
required a new visitor to be written. Nesting of patterns like the one above is 
typically where users resort to \emph{type tests} and \emph{type casts} that in 
case of C++ can be combined into a single call to \code{dynamic_cast}.

Related to nested patterns are \emph{as-patterns} that help one take a value 
apart while still maintaining its integrity. The following rule could have been 
a part of a hypothetical rewriting system in OCaml similar to the one above. Its 
intention is to rewrite expressions of the form $\frac{e_1/e_2}{e_3/e_4}$ into 
$\frac{e_1}{e_2}\frac{e_4}{e_3} \wedge e_2\neq0 \wedge e_3\neq0 \wedge e_4\neq0$.

\begin{lstlisting}[language=Caml,keepspaces,columns=flexible]
    | Divide(Divide(_,e2) as numerator, Divide(e3,e4))
          -> Times(numerator, Divide(e4, e3))
\end{lstlisting}

We introduced a name ``numerator'' as a synonym of the result of matching the 
entire sub-expression \codeocaml{Divide(_,e2)} in order to refer it without 
recomposing in the right-hand side of the case clause. We omitted the 
conjunction of relevant non-zero checks for brevity, one can see that we will 
need access to \codeocaml{e2} in it however.

Decomposing algebraic data types through pattern matching has an important 
drawback that was originally spotted by Wadler\cite{Wadler87}: they expose 
concrete representation of an abstract data type, which conflicts with the 
principle of \emph{data abstraction}. To overcome the problem he proposed the 
notion of \emph{views} that represent conversions between different 
representations that are implicitly applied during pattern matching. As an 
example, imagine polar and cartesian representations of complex numbers. A user 
might choose polar representation as a concrete representation for the abstract 
data type \codeocaml{complex}, treating cartesian representation as view or vice 
versa:\footnote{We use syntax from Wadler's original paper for this example}

\begin{lstlisting}[language=Haskell,columns=flexible]
complex ::= Pole real real
view complex ::= Cart real real
  in  (Pole r t) = Cart (r * cos t) (r * sin t)
  out (Cart x y) = Pole (sqrt(x^2 + y^2)) (atan2 x y)
\end{lstlisting}

The operations then might be implemented in whatever representation is the most 
suitable, while the compiler will implicitly convert representation if needed:

\begin{lstlisting}[language=Haskell,columns=flexible]
  add  (Cart x1 y1) (Cart x2 y2) = Cart (x1 + x2) (y1 + y2)
  mult (Pole r1 t1) (Pole r2 t2) = Pole (r1 * r2) (t1 + t2)
\end{lstlisting}

The idea of views were later adopted in various forms in several languages: 
Haskell\cite{views96}, Standard ML\cite{views98}, Scala (in the form of 
\emph{extractors}\cite{EmirThesis}) and F$\sharp$ (under the name of 
\emph{active patterns}\cite{Syme07}).

%Views in functional programming languages [92, 71] are conversions from one data type to
%another that are implicitly applied in pattern matching. They play a role similar to extractors
%in Scala, in that they permit to abstract from the concrete data-type of the matched objects.
%However, unlike extractors, views are anonymous and are tied to a particular target data
%type.

Logic programming languages like Prolog take pattern matching to even greater 
level. The main difference between pattern matching in logic languages and 
functional languages is that functional pattern matching is a ``one-way'' 
matching where patterns are matched against values, possibly binding some 
variables in the pattern along the way. Pattern matching in logic programming is 
``two-way'' matching based on \emph{unification} where patterns can be matched 
against other patterns, possibly binding some variables in both patterns and 
potentially leaving some variables \emph{unbound} or partially bound -- i.e. 
bound to patterns. A hypothetical example of such functionality can be matching 
a pattern \codeocaml{Plus(x,Times(x,1))} against another pattern 
\codeocaml{Plus(Divide(y,2),z)}, which will result in binding \codeocaml{x} to a 
\codeocaml{Divide(y,2)} and \codeocaml{z} to \codeocaml{Times(Divide(y,2),1)} 
with \codeocaml{y} left unbound, leaving both \codeocaml{x} and \codeocaml{z} 
effectively a pattern.

%[From Emir 2.1.2]
%Apart from testing for constructors, patterns can also test whether a data item is equal to
%a literal constant, a named constant or, in languages with subtyping, whether it has a certain
%type. The nesting of patterns can express structural constraints, which can be used to
%represent information.
%For instance, the pattern (Node 42 Leaf) matches values of SrchT that contains the literals
%and a leaf in this particular configuration.
%Nested patterns make programs very concise and readable, because the shape of a pattern
%determines the meaning of the program, which leaves many visual clues in the source code.
%For instance, to a programmer with a mathematical background but no prior exposure to
%pattern matching, it soon becomes self-evident that a pattern like (42,y) matches pairs
%whose left component is 42 and whose right component can be any value.

%[From Emir 2.1.3]
%An algebraic data type definition T fixes the structure of the instances of T once and for all.
%The constructor tags are special cases of T, which provides a relationship between the set
%of instances tagged with a particular constructor and the set of instances of T that is akin
%to nominal (explicitly declared) subtyping. One major difference is that an algebraic data
%type forms a "closed world": the set of constructors and their signature cannot be changed.
%The reason for this restriction ist that an algebraic data types defines a sum type and allows
%straightforward reasoning on its fixed structure. A welcome consequence of this restriction
%is that algebraic data types can be represented efficiently by replacing constructor tags with
%an integer constant.

%Since the set of constructors forms a closed world, an automatic check for incompleteness
%can be performed on match expressions: The compiler can thus warn programmers who by
%mistake omit a case from their match expressions, which would leave the match expression
%incomplete. This check is very helpful if there are many constructors or when nested patterns
%allow for combinatorial combinations of algebraic data types (e.g. for a pair of two SrchT
%instances).

\section{Implementation} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:pm}

\section{Evaluation} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:eval}

\section{Related Work} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:rw}

\section{Future Work} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:fw}

\section{Conclusions} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:cc}

We described a technique for implementing efficiently various language 
facilities that depend on a run-time type of an argument: type switching, type 
testing, pattern matching etc. The technique is open to class extensions and 
interacts well with multiple inheritance in C++ (including repetitive and 
virtual inheritance) as well as templates. The technique can also be reused in 
other object-oriented language that use v-tables to implement dynamic dispatch.

Using the above technique we implemented a pattern matching library for C++ that 
closely resembles pattern-matching facilities available in other languages on a 
first-class bases. Our implementation is very similar or outperforms its closest 
contender -- visitor design pattern as well as overcomes the restrictions, 
inconveniences and difficulties in teaching and using, typically associated with 
it.

We used the library to rewrite an existing code that was relying heavily on 
visitors and discovered that resulting code became much shorter, simpler, easier 
to maintain and comprehend.

%In this work we describe design and implementation of a library that brings 
%pattern matching facilities similar to those of functional programming languages 
%into C++. Our solution does not requre any changes to the compiler and in its 
%main part can be implemented in the standard C++98. Several extensions might 
%require use of C++0x features, readily available in todays mainstream compilers.
%The solution is non-intrusive and can be applied to any given class taxonomy 
%retroactively. Its main utility lays in avoiding the control inversion problem 
%typical to Visitor Design Pattern, which results in more clear, direct and much 
%more consciece code. Our evaluation demonstrates that the solution scales to 
%real-sized projects, while the performance results show that it comes close to 
%its hand-crafted visitor alternative. The main novelty of the paper is in 
%generalizing Haskell's n+k patterns to any invertible operations and 
%demonstrating how to do it generically in a library setting. Backward semantics 
%of expression templates used to implement this feature is also to the best of 
%our knowledge first application of backward semantics to expression templates.

\bibliographystyle{eptcs}
\bibliography{mlpatmat}
\end{document}
