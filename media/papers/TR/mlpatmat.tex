\documentclass[preprint]{sigplanconf}

\usepackage{breakurl}             % Not needed if you use pdflatex only.
\usepackage{listings}

\lstdefinestyle{C++}{language=C++,%
showstringspaces=false,
  columns=fullflexible,
  escapechar=@,
  basicstyle=\sffamily,
%  commentstyle=\rmfamily\itshape,
  moredelim=**[is][\color{white}]{~}{~},
  literate={<}{{$\langle$}}1        {>}{{$\rangle$}}1 %
           {<=}{{$\leq$}}1          {>=}{{$\geq$}}1          {!=}{{$\neq$}}1 %
           {=>}{{$\Rightarrow\;$}}1 {->}{{$\rightarrow{}$}}1 %
           {<:}{{$\subtype{}\ $}}1  {<-}{{$\leftarrow$}}1 %
           {Match}{{\emph{Match}}}5 %
           {EndMatch}{{\emph{EndMatch}}}8 %
           {Case}{{\emph{Case}}}4 %
           {CM}{{\emph{CM}}}2 {KS}{{\emph{KS}}}2 {KV}{{\emph{KV}}}2 
}
\lstset{style=C++}
\DeclareRobustCommand{\code}[1]{{\lstinline[breaklines=false]{#1}}}

\begin{document}

\conferenceinfo{DSL 2011}{Bordeaux, France} 
\copyrightyear{2011} 
\copyrightdata{[to be supplied]} 

\titlebanner{Technical Report}        % These are ignored unless
\preprintfooter{Y.Solodkyy, G.Dos Reis, B.Stroustrup: Pattern Matching for C++}   % 'preprint' option specified.

\title{Pattern Matching for C++}
\subtitle{An attempt to retire Visitor Design Pattern}

\authorinfo{Yuriy Solodkyy\and Gabriel Dos Reis\and Bjarne Stroustrup}
           {Texas A\&M University\\ Texas, USA}
           {\{yuriys,gdr,bs\}@cse.tamu.edu}

\maketitle

\begin{abstract}
Pattern matching has been known in functional programming community as an
abstraction mechanism that greatly simplifies the code. Following the success of 
functional languages, several imperative programming languages had introduced 
pattern matching into them. While this is relatively easy to do a-priori, when 
designing a new language, this might become quite a challenge to do a-posteriori 
when trying to introduce it into an industry strength language like C++. 
We present ML-like pattern matching for C++ implemented as a pure library in a 
form of Domain Specific Language built on top of standard C++. Our solution 
comes very close in terms of performance to its de facto contender -- the visitor 
design pattern, traditionally used in pattern matching scenarios in C++. Unlike 
the visitor pattern our solution is non intrusive, open to new classes, avoids 
the control inversion and is much more conscise, easier to read, maintain and 
comprehend. It also mimics many of the pattern matching facilities (e.g. guards 
and n+k patterns) available in other languages on the first class basis, letting 
us experiment with them without any changes to the compiler, while offsetting 
the semantic discussions that typically go along into the domain of concepts.
\end{abstract}

\category{CR-number}{subcategory}{third-level}

\terms
Languages, Design

\keywords
Pattern Matching, Visitor Design Pattern, Expression Problem, C++

\section{Introduction} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:intro}

%Motivate the problem
%Give a summary of the paper: what you did and how
%Explicitly state your contribution

Pattern matching is an abstraction supported by many programming languages, which 
allows the user to describe in a breve manner a (possibly infinite) set of 
values accepted by the pattern. Pattern represents effectively a predicate on 
values, and is usually expected to be much more consciese and readable than the 
equivalent predicate spelled out directly.

Popularized by functional programming community, most notably ML\cite{ML90} and 
Haskell\cite{Haskell98Book}, for providing syntax very close to mathematical 
notations, pattern matching has since been making its way into many imperative 
programming languages like Scala\cite{Scala2nd}, 
Java\cite{Liu03jmatch:iterable,HydroJ2003}, C++\cite{Prop96}, 
C\cite{Moreau:2003} and others. While this is relatively  
easy to do a-priori when designing a new language, the introduction of pattern 
matching into an industry strengths language a-posteriori might become a 
challenge. The obvious utility of the feature may be overshadowed by the 
complications in the language semantics necessary to make pattern matching work 
with other features of the language. A prototype implementation will likely 
require a lot of effort, but will be hard to publish due to lack of novelty.

To balance the utility and effort we follow the approach of Semantically 
Enhanced Library Languages\cite{SELL}, under which one should rather consider 
subsetting a general-purpose programming language (C++ in our case), extended 
with a tool support (which would be convenient, but not necessary here). Such 
approach will typically not give you 100\% of functionality, but instead would 
rather give you 80\% of it at 20\% of the time. This was exactly the case with 
our solution as instead of typical half a year to get any major feature 
implemented on a scale of C++ language, it took us less than a month to 
implement it as a SELL and under a week to rewrite an existing application using 
it.

Naturally, a library only solution might have limitations that can be overcome in 
a language solution, which is why we do not propose our current approach as the 
ultimate library solution, but instead as a transition facility that lets users 
experiment with pattern matching in C++ while letting us experiment with and 
eventually shape the the language solution. The library only solution exposes 
all the functionality that will eventually be available through compiler.

To give a quick taste of what our library enables, let's look at an example from 
the domain where pattern matching is known to cut the edge of brevity and 
readibility -- compiler construction. Imagine a simple language of expressions:

\begin{lstlisting}
exp ::= val | exp + exp | exp - exp | exp * exp | exp / exp
\end{lstlisting}

OCaml datatype describing this grammar as well as simple evaluator of expressions 
in it can be declared as following:

\begin{lstlisting}[language=Caml,keepspaces,columns=flexible]
type expr = Value  of int
          | Plus   of expr * expr
          | Minus  of expr * expr
          | Times  of expr * expr
          | Divide of expr * expr
          ;;

let rec eval e =
  match e with
            Value  v      -> v
          | Plus   (a, b) -> (eval a) + (eval b)
          | Minus  (a, b) -> (eval a) - (eval b)
          | Times  (a, b) -> (eval a) * (eval b)
          | Divide (a, b) -> (eval a) / (eval b)
          ;;
\end{lstlisting}

The corresponding C++ data types are slightly more verbose, though the only 
reason we have not parameterized them was to keep the example simple.

\begin{lstlisting}[keepspaces,columns=flexible]
struct Expr { virtual @$\sim$@Expr() {} };
struct Value  : Expr { int value; };
struct Plus   : Expr { Expr* exp1; Expr* exp2; };
struct Minus  : Expr { Expr* exp1; Expr* exp2; };
struct Times  : Expr { Expr* exp1; Expr* exp2; };
struct Divide : Expr { Expr* exp1; Expr* exp2; };
\end{lstlisting}

Together with evaluator they form an instance of the \emph{Interpreter Design 
Pattern}\cite{DesignPatterns1993}. Unlike the type definitions, the evaluator 
for the language, implemented on top of our pattern matching library is almost 
as breve as its version in OCaml:

\begin{lstlisting}[keepspaces,columns=flexible]
int eval(const Expr* e)
{
    Match(e)@\footnote{We use alternative formatting on symbols representing preprocessor macros}@
    {
    Case(Value,  n)    return n;
    Case(Plus,   a, b) return eval(a) + eval(b);
    Case(Minus,  a, b) return eval(a) - eval(b);
    Case(Times,  a, b) return eval(a) * eval(b);
    Case(Divide, a, b) return eval(a) / eval(b);
    }
    EndMatch
}
\end{lstlisting}

The only definitions we omited here that prevent the example from being fully 
functional are the mappings of class members to corresponding binding positions. 
We list them here for completeness, while their meaning will be explained later 
in section~\ref{}. Here we'd like to mention though that these definitions are only 
needed to support the variables binding and not the type switching functionality 
of the \code{Match}.

\begin{lstlisting}[keepspaces,columns=flexible]
template <> struct bindings<Value>  { CM(0,Value::value); };
template <> struct bindings<Plus>   { CM(0,Plus::exp1); 
  ...                                 CM(1,Plus::exp2);   };
template <> struct bindings<Divide> { CM(0,Divide::exp1); 
                                      CM(1,Divide::exp2); };
\end{lstlisting}

The above syntax is enabled without any external tool support through the use
of new C++0x features\cite{C++0x}, template meta-programming and macros. As we 
show in section~\ref{       }, it runs up to 80\% faster (depending on the usage 
scenario, compiler and underlain hardware) than a similar code crafted with the 
\emph{Visitor Design Pattern}.

\subsection{Motivation}

%\subsection{Excursus}

The ideas and the library presented here originated from our rather 
unsatisfactory expirience in working with various C++ front-ends and program 
analysis frameworks developed in C++\cite{Pivot09,Phoenix,Clang,Lise}. The 
problem was not in the frameworks per se, but in the fact that we had to use 
\emph{Visitor Design Pattern}\cite{DesignPatterns1993} to inspect, traverse and 
elaborate abstract syntax trees of their target languages. Having written enough 
visitors to realize how unsuitable they were for the job, we started looking for 
other mechanisms to work with abstract syntax trees, even if they would have 
turned out to be significantly slower. 
Presense of dynamic casts in many places, often nested, to answer simple 
structural questions without having to resort to visitors, was a strong 
indicator that even though visitors were fast, in many non-critical cases 
users preferred shorter, cleaner and a more clear code to performance.
The usage of \code{dynamic\_cast} in those cases was resembling the use of 
pattern matching in functional languages to unpack algebraic data types. 
Functional languages have been long known to be very suitable for developing 
program analysis tools because of the brevity with which the necessary 
algorithms can be expressed. This is why our initial goal was to develop a 
domain-specific library within C++ that would enable us to express various 
predicates on tree-like structures with the brevity of functional languages.

%[From Emir PhD Thesis 1.3]
%In the context of the JAVA virtual machine (and any other object system that supports runtime
%type information), a much more direct way of obtaining the dynamic type of a value is
%to use an instanceof-check. Although these are considered bad style, programmers make
%use of them frequently, in order to avoid the overhead of using a Visitor implementation.
%They are error prone since it is possible to perform a cast without a preceding check.

\subsection{Visitor Design Pattern}

%Discuss visitor design pattern and its problems.
%\begin{itemize}
%\item Intrusive - requires changes to the hierarchy
%\item Not open  - addition of new classes changes visitor interface
%\item Doesn't provide by default relation between visitors of base and derived classes
%\item Control inversion
%\item Cannot be generically extended to handling n arguments
%\end{itemize}

%[From Extensible Algebraic Datatypes with Defaults]
%In the object-oriented approach, data is modelled by a set of classes, sharing 
%a common interface. Each subclass defines its own implementation of eval. Whereas
%extending the datatype with new variants is simply done by
%creating new classes, adding new operations involves modifications
%of the abstract base class.

\emph{Visitor Design Pattern}\cite{DesignPatterns1993} was devised to solve a problem 
of extending existing classes with new functions in object-oriented languages. 
Consider the above Expr example and imagine we would like to provide a pretty 
printing of expressions. A typical object-oriented approach would be to 
introduce a virtual function \code{virtual void print() const = 0;} inside the 
abstract base class \code{Expr}, which will be implemented correspondingly in all derived 
classes. This works well as long as we know all the required operations on the 
abstract class in advance. Unfortunately this is very difficult to achieve in 
reality as the code evolves, especially in production environment. To put this 
in context, imagine that after the above interface with pretty printing 
functionality has been deployed, we decided that we need a similar functionality 
that persists the expression in XML format. Adding new virtual function implies 
modifying the base class and creating a versioning problem with the code that 
has been deployed already using the old interface.

To alleviate this problem, Visitor Design Pattern separates the 
\emph{commonality} of all such future member-functions from their 
\emph{specifics}. The former deals with identifying the most specific derived 
class of the reciever object, known to the system at the time the base class was 
designed. The latter provides implementation of the required functionality once 
the most specific derived class has been identified. The interaction between the 
two is encoded in the protocol that fixes \emph{visitation interface} 
enumerating all known derived classes on one side and a dispatching mechanism 
that guarantees to select the most specific case with respect to the dynamic 
type of the reciever in the visitation interface. An implementation of this 
protocol for our Expr example might look as following:

\begin{lstlisting}
// Forward declaration of known derived classes
struct Value; struct Plus; ... struct Divide;
// Visitation interface
struct ExprVisitor
{
    virtual void visit(const Value&)  = 0;
    virtual void visit(const Plus&)   = 0;
    ...  // One virtual function per each known derived class
    virtual void visit(const Divide&) = 0;
};
// Abstract base and known derived classes
struct Expr { 
    virtual void accept(ExprVisitor&) const = 0; };
struct Value : Expr { ...
    void accept(ExprVisitor& v) const { v.visit(*this); } };
struct Plus  : Expr { ...
    void accept(ExprVisitor& v) const { v.visit(*this); } };
\end{lstlisting}

Note that even though implementations of \code{accept} member-functions are 
syntactically identical, a different \code{visit} is called. We rely here on the 
overload resolution mechanism of C++ to pick the most specialized \code{visit} 
member-function applicable to the static type of \code{*this}. This is a mere 
code maintenance convenience that, unfortunately, often confuses novices on what 
is going on. We thus would like to point out that member-functions in the 
visitation interface are not required to be called with the same name, -- we 
could have equally well called them \code{visit_value}, \code{visit_plus} etc. 
making the corresponding changes to calls inside \code{Value::accept}, 
\code{Plus::accept} etc.

A user can now implement his new functions similarly to the following function 
to convert expressions to string:

\begin{lstlisting}
std::string to_str(const Expr* e); // Forward declaration

struct ToStrVisitor : ExprVisitor
{
    void visit(const Value& e) { result = std::to_string(e.value); }
    ...
    void visit(const Divide& e) { 
        result = to_str(e.exp1) + '/' + to_str(e.exp2); 
    }
    std::string result;
};
// Actual implementation based on visitor
std::string to_str(const Expr* e)
{
    ToStrVisitor v;
    e->accept(v);
    return v.result;
}
\end{lstlisting}

Function \code{eval} we presented above as well as any new function that we 
would like to add to \code{Expr} can now be implemented in much the same way, 
witihout the need to change base interface. This flexibility does not come for 
free thought and we would like to point out some pros and cons of this solution.

The most important advantage of the visitor design pattern is possibility to add 
new operations to the class hierarchy without the necessity to change the 
interface each time. It's second most quoted advantage is typically speed -- the 
overhead of two virtual function calls incurred by the double dispatch present 
in the visitor design pattern is often negligable on the modern architectures. 
There are quite a few disadvantages however.

The {\bf increased amount of boilerplate code} that has to be added to support 
the above solution cannot go unnoticed. Several entities had to be forward 
declared because of the mutual recursivity of their definitions. The solution is 
{\bf specific to hierarchy} as we had to declare a visitation interface 
specific to the base class. It is also {\bf intrusive} since we had to inject 
syntactically the same definition of \code{accept} method into every class 
participating in visitation. The amount of the necessary support increases as 
additional arguments have to be passed into the visitor to be available during 
the visitation. This aspect can be seen in the example~\ref{} where we have to 
store both functors inside the visitor.

More importantly, visitors {\bf hinder extensibility} of the class hierarchy: 
new classes added to the hierarchy after the visitation interface has been 
fixed, will be treated as their most derived base class present in the interface.
A solution to this problem has been proposed in the form of \emph{Extensible 
Visitors with Default Cases}\cite[\textsection 4.2]{Zenger:2001}, however the solution, after 
remapping it onto C++, has problems of its own. The visitation interface 
hierarchy can easily be grown linearly (adding new cases for the new classes in 
the original hierarchy each time), but independent extensions by different  
authorities require developer's intervention to unify them all, before they can 
be used together. This may not be feasible in environments that use dynamic 
linking. To avoid writing even more boilerplate code in new visitors, the 
solution would require usage of virtual inheritance\cite{}, which typically has 
an overhead of extra memory dereferencing. On top of the double dispatch already 
present in the visitor pattern, the solution will incure two additional virtual 
calls and a dynamic cast for each level of visitor extension. Additional double 
dispatch is incurred by forwarding of default handling from base visitor to a 
derived one, while the dynamic cast is required for safety and can be replaced 
with a static case when visitation interface is guaranteed to be grown linearly 
(extended by one authority only). Yet another virtual call is required to be 
able to forward computations to subcomponents on tree-like structures to the 
most derived visitor. This last function lets one avoid the necessesity of using 
heap to allocate a temporary visitor through the \emph{Factory Design 
Pattern}\cite{DesignPatterns1993} used in \emph{Extensible Visitor} solution 
originally proposed by by Krishnamurti, Felleisen and 
Friedman\cite{Krishnamurthi98}.

Once all the boilerplate related to visitors has been written and the visitation 
interface has been fixed we are still left with some annoyances incurred by the 
pattern. One of them is the necessity to work with the {\bf control inversion} 
that visitors put in place. Because of it we have to save any local state and 
any arguments that some of the \code{visit} call-backs might need from the 
calling environment. Similarly, we have to save the result of the visitation 
as we cannot assume that all the visitors that will potenitally be implemented 
on a given hierarchy will use the same result type. Using visitors in a generic 
algorithm requires even more precautions. We summarize these visitor-related 
issues in the following motivating example, followed by an illustration of a 
pattern matching solution to the same problem enabled with our library.

%[From The Essence of the Visitor Pattern]
%For object-oriented programming, the Visitor pattern en-
%ables the denition of a new operation on an object structure without
%changing the classes of the objects. The price has been that the set of
%classes must be xed in advance, and they must each have a so-called
%accept method.

%[From Emir PhD Thesis 1.4.2]
%Apart from readability and safety, a high-level construct for pattern matching provides opportunities
%for optimization and for static checks.
%A drawback of all object-oriented solutions above is that standard compilers do not check
%whether such hand-crafted case distinction based on type-tests and type-casts cover all the
%cases, nor whether all branches can actually be entered. Pattern matching constructs in functional
%programming languages can be checked statically for incompleteness and redundancy,
%which helps catch many programmer mistakes.

\subsection{Motivating Example}

While comparing generic programming facilities available to functional and 
imperative languages (mainly Haskell and C++), Dos Reis and Jarvi present the 
following example in Haskell describing a sum functor\cite{DRJ05}:

\begin{lstlisting}[language=Haskell]
data Either a b = Left a | Right b

eitherLift :: (a -> c) -> (b -> d) -> Either a b -> Either c d
eitherLift f g (Left  x) = Left  (f x)
eitherLift f g (Right y) = Right (g y)
\end{lstlisting}

In simple words, the function \code{eitherLift} above takes two functions and an 
object and depending on the actual type constructor the object was created with, 
calls first or second function on the embedded value, encoding the result 
corresondingly.

Its equivalent in C++ is not as straightforward. The idiomatic handling of 
discriminated unions in C++ typically assumes use of the \emph{Visitor Design 
Pattern}\cite{DesignPatterns1993}.

\begin{lstlisting}
template <class X, class Y> class Either;
template <class X, class Y> class Left;
template <class X, class Y> class Right;

template <class X, class Y>
struct EitherVisitor {
    virtual void visit(const  Left<X,Y>&) = 0;
    virtual void visit(const Right<X,Y>&) = 0;
};

template <class X, class Y>
struct Either {
    virtual @$\sim$@Either() {}
    virtual void accept(EitherVisitor<X,Y>& v) const = 0;
};

template <class X, class Y>
struct Left : Either<X,Y> {
    const X& x;
    Left(const X& x) : x(x) {}
    void accept(EitherVisitor<X,Y>& v) const { v.visit(*this); }
};

template <class X, class Y>
struct Right : Either<X,Y> {
    const Y& y;
    Right(const Y& y) : y(y) {}
    void accept(EitherVisitor<X,Y>& v) const { v.visit(*this); }
};
\end{lstlisting}

The code above defines the necessary parameterized data structures as well as a 
correspondingly parameterized visitor class capable of introspecting it at 
run-time. The authors agree with us that \emph{``The code has a fair amount of 
boilerplate to simulate pattern matching...''} The actual implementation of 
\code{lift} in C++ now amounts to declaring and invoking a visitor:

\begin{lstlisting}
template <class X, class Y, class S, class T>
const Either<S,T>& lift(const Either<X,Y>& e, S f(X), T g(Y))
{
    typedef S (*F)(X);
    typedef T (*G)(Y);
    struct Impl : EitherVisitor<X,Y> {
        F f;
        G g;
        const Either<S,T>* value;
        Impl(F f, G g) : f(f), g(g), value() {}
        void visit(const Left<X,Y>& e) {
            value = left<S,T>(f(e.x));
        }
        void visit(const Right<X,Y>& e) {
            value = right<S,T>(g(e.y));
        }
    };
    Impl vis(f, g);
    e.accept(vis);
    return *vis.value;
}
\end{lstlisting}

The same function expressed with our pattern matching facility seems to be much 
closer to the original Haskell definition:

\begin{lstlisting}[keepspaces,columns=flexible]
template <class X, class Y, class S, class T>
const Either<S,T>* lift(const Either<X,Y>& e, S f(X), T g(Y))
{
    Match@$^T$@(e)@\footnote{T indicates that the user will have to use TMatch, TCase and TEndMatch versions of the macros respectively since the substituted code has to be correct in the template environment}@
      Case(( Left<X,Y>), x)  return  left<S,T>(f(x));@\footnote{We need to take the first argument in parentheses to avoid interpretation of comma in template argument list by the preprocessor}@
      Case((Right<X,Y>), y)  return right<S,T>(g(y));
    EndMatch
}
\end{lstlisting}

It is also as fast as the visitor solution, but unlike the visitors based 
approach neither requires \code{EitherVisitor} class anymore (together with 
forward declarations it needed), nor any of the \code{accept} member-functions 
injected in all three classes. We do require binding definitions though to be 
able to bind variables \code{x} and \code{y}:
\footnote{Definitions of obvious functions \code{left} and \code{right} have 
been ommitted in both cases.}

\begin{lstlisting}[keepspaces,columns=flexible]
template <class X, class Y> 
    struct bindings<Left<X,Y>>  { CM(0, Left<X,Y>::x); };
template <class X, class Y> 
    struct bindings<Right<X,Y>> { CM(0,Right<X,Y>::y); };
\end{lstlisting}

Note that these binding definitons are made once for all possible instantiations 
with the use of partial template specialization in C++.

\subsection{Summary}

The contributions of the paper can be summarized as following:

\begin{itemize}
\item We present a technique that can be used to implement type switching 
      effectively based on the run-time type of the argument. 
  \begin{itemize}
  \item The technique outperforms its de facto contender -- visitor design 
        pattern without sacrifying extensibility.
  \item It works in the presense of multiple inheritance, including virtual 
        inheritance.
  \item The technique generalizes to other object-oriented languages that use 
        virtual tables to implement dynamic dispatch.
  \end{itemize}
\item We present a functional style pattern matching for C++ built as a library 
      employing the above technique.
  \begin{itemize}
  \item The solution is open, non-intrusive and can be applied to any class 
        hierarchy retroactively.
  \item It allows one to avoid the control inversion typical for visitors.
  \item We provide performance and ease of use comparison based on a real code
  \end{itemize}
\end{itemize}

The novelty of the paper lays in a new method that can be used by compilers of 
object-oriented languages as well as libraries written in them to implement 
\emph{type switching}, \emph{type testing}, \emph{pattern matching} and 
\emph{multiple dispatch} efficiently. We look at different approaches that are 
taken in implementing algebraic data types in C++ today and present a unified 
pattern matching syntax that works uniformly with all of them. We also 
generalize Haskell's n+k patterns to any invertable operations. Semantics issues 
that typically accompany n+k pattern are handled transparently by forwarding the 
problem into the concepts domain, thanks to the fact that we work in a library 
setting.

The rest of this paper is structured as following. In Section~\ref{sec:bg} we 
present evolution of pattern matching in different languages, presenting 
informally semantics of various pattern matching facilities by example. 
Section~\ref{sec:pm} presents various approaches that are taken in C++ to 
implementing algebraic data types as well as demonstrates uniform handling of 
them in our pattern matching library. Section~\ref{sec:impl} discusses the 
\emph{v-table caching} technique that made the efficient implementation of 
pattern matching possible, while Section~\ref{sec:eval} provides performance 
evaluation of this technique against common alternatives. Section~\ref{sec:rw} 
discusses some related work, while Section~\ref{sec:cc} concludes by discussing 
some future directions and possible improvements.

\section{Background} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:bg}

%[From Emir PhD 1.1]
%In functional programming languages, pattern matching has been closely related to algebraic
%data types since its beginning - Burstall\cite{Burstall69provingproperties} is the first to define a pattern matching
%construct that resembles the one found in statically typed functional languages today.

Pattern matching in the context of a programming language was first introduced 
in a string manipulation language SNOBOL\cite{SNOBOL64}. It's fourth 
reincarnation SNOBOL4 had patterns as first-class data types providing 
operations of concatenation and alternation on them\cite{SNOBOL71}. The first 
reference to a pattern matching construct that resembles the one found in 
statically typed functional languages today is usually attributed to Burstall 
and his work on structural induction\cite{Burstall69provingproperties}.

%[From Emir PhD thesis 1.6]
%The SCALA compiler is the effort of several researchers, and combining pattern matching
%and object-oriented programming has been approached before\cite{Odersky97pizzainto,Zenger:2001}.

In the context of object-oriented programming, pattern matching has been first 
explored in Pizza programming language\cite{Odersky97pizzainto}. These efforts 
have been continued in Scala\cite{Scala2nd} and together with notable work of 
Burak Emir on \emph{Object-Oriented Pattern Matching}\cite{EmirThesis} have 
resulted in incorporation of pattern matching into the language.

%The first tree based pattern matching methods were found in Fred McBride's 
%extension of LISP in 1970.

%ML and Haskell further popularized pattern matching ...

Pattern matching has been closely related to \emph{algebraic data types} and 
\emph{equational reasoning} since the early days of functional programming.
In languages like ML and Haskel an \emph{Algebraic Data Type} is a data type 
each of whose values is picked from a disjoint sum of (possibly recursive) data 
types, called \emph{variants}. Each of the variants is marked with a unique 
symbolic constant called \emph{constructor}. Constructors provide a 
convenient way of creating a value of its variant type as well as a way of 
discriminating its variant type from the algebraic data type through pattern 
matching.

Algebraic data type \code{expr} from Section~\ref{sec:intro} consists of 5 
variants, marked with constructors \code{Value}, \code{Plus}, \code{Minus}, 
\code{Times} and \code{Divide} respectively. Constructor \code{Value} expects a 
value of type \code{int} during construction, as well as any pattern that admits 
values of type \code{int} during decomposition through pattern matching. 
Similarly, the other four constructors expect a value of a carthesian product of 
two \code{expr} types during construction, as well as any pattern that would 
admit a value of such type during decomposition.

Algebraic data types can be parameterized and recursive, as demonstrated by the 
following Haskell code that defines a binary tree parameterized on type \code{k} 
of keys and type \code{d} of data stored in the nodes:

\begin{lstlisting}[language=Haskell]
data Tree k d = Node k d (Tree k d) (Tree k d) 
              | Leaf
\end{lstlisting}

They can also be decomposed in a generic algorithm like the function \code{find} 
below, defined through case analysis on the tree's structure:

\begin{lstlisting}[language=Haskell]
find :: Int -> Tree Int d -> Maybe d
find i t = case t of
    Leaf -> Nothing
    Node key item left right ->
        if i = key then Just item else
            if i < key then find i left else find i right
\end{lstlisting}

The set of values described by a given algebraic data type is defined 
inductively as the least set closed under constructor functions of its variants.
Algebraic data types draw their name from the practice of using case distinction 
in mathematical function definitions and proofs that involve \emph{algebraic 
terms}.

One of the main differences of algebraic data types from object-oriented data 
structures is that an algebraic data type definition fixes the structure of its 
instances once and for all. Once we have listed all the variants a given 
algebraic data type may have we cannot extend it with new variants without 
modifying its defintion. This is not the case in object-oriented languages, 
where classes can be extended arbitrarily.

%The constructor tags are special cases of T, which provides a relationship between the set
%of instances tagged with a particular constructor and the set of instances of T that is akin
%to nominal (explicitly declared) subtyping. One major difference is that an algebraic data
%type forms a "closed world": the set of constructors and their signature cannot be changed.
%The reason for this restriction ist that an algebraic data types defines a sum type and allows
%straightforward reasoning on its fixed structure. A welcome consequence of this restriction
%is that algebraic data types can be represented efficiently by replacing constructor tags with
%an integer constant.

%Since the set of constructors forms a closed world, an automatic check for incompleteness
%can be performed on match expressions: The compiler can thus warn programmers who by
%mistake omit a case from their match expressions, which would leave the match expression
%incomplete. This check is very helpful if there are many constructors or when nested patterns
%allow for combinatorial combinations of algebraic data types (e.g. for a pair of two SrchT
%instances).


%[From Emir PhD 2.1.1]
%In typed functional programming languages like HOPE [14], MIRANDA [90], HASKELL [47]
%and ML [64], users can define concrete data types as disjoint sums of primitive types, tuples
%and function types. Each variant, or constructor, is identified with a symbolic constant.
%Such data types can then be discriminated using patterns, which mention the constructor
%label along with a collection of sub-patterns or variables to bind the constituents of a matching
%instance. This data definition mechanism should be considered as a building block for
%the wider goal of functional programming, which is give clear semantics to data and enable
%equational reasoning about programs.
%
%Algebraic data types like SrchT are defined inductively as the least set closed under their
%constructor functions.

Functional programming community 
algebraic data type (sometimes also called a variant type[1]) is a datatype each 
of whose values is data from other datatypes wrapped in one of the constructors 
of the datatype. Any wrapped datum is an argument to the constructor. In 
contrast to other datatypes, the constructor is not executed and the only way to 
operate on the data is to unwrap the constructor using pattern matching.




In programming languages like ML\cite{ML90} and Haskell\cite{Haskell98Book}, a 
function can be defined by a sequence of pattern-expression pairs. Evaluating 
such a function is equivalent to evaluation of the expression corresponding to 
the first pattern that matches the arguments. Most of the languages distinguish 
\emph{primitive patterns} (described by a given value or a variable) and 
\emph{tree patterns} (arise from decomposing algebraic data types through the 
use of constructors). Consider the following Haskell code defining factorial 
function:

\begin{lstlisting}[language=Haskell]
factorial 0 = 1
factorial n = n * factorial (n-1)
\end{lstlisting}

Here 0 in the left hand side of the first \emph{equation} is an example of a 
\emph{value pattern} that will only match when the actual argument passed to the 
function factorial is 0. The \emph{variable pattern} \code{n} in the left hand 
side of the second equation will match any value, \emph{binding} variable 
\code{n} to that value in the right hand side of equation. 

Tree patterns arise in many different contexts: description of tree-like 
structures, algebraic data types, class hierarchies etc.

Veldhuizen discovered a very powerful technique called Expression 
templates\cite{Veldhuizen95expressiontemplates}.

Other languages that use pattern matching include: ...

Interestingly enough C++ has a pure functional sublanguage in it that has a 
striking similarity to ML and Haskell. The sublanguage in question is template 
facilities of C++ that has been shown to be turing 
complete\cite{veldhuizen:templates_turing_complete}. In fact there were 
attempts to use Haskell as a pseudocode language for template metaprogramming in 
C++\cite{Milewski11}. A key observation in this analogy is that partial and 
explicit template specialization of C++ class templates are similar to defining 
equations for Haskell functions. Consider as an example the above factorial 
function expressed in terms of compile-time pattern matching facilities of C++:

\begin{lstlisting}
template <int N> struct factorial    { enum { result = N*factorial<N-1>::result }; };
template <>      struct factorial<0> { enum { result = 1 }; };
\end{lstlisting}

Coincidentaly, we use this compile-time pattern matching facility as a 
meta-language to implement its run-time counterpart.

A place where C++ does have a primitive run-time pattern matching is the catch 
clause of exception handling. The order of clauses matters, which is similar to 
the order of patterns. 

Patterns such as formal parameters that never fail to match are said to be 
irrefutable, in contrast to refutable patterns which may fail to match. The 
pattern used in the contrived example above is refutable. There are three other 
kinds of irrefutable patterns:

* As-patterns
* Wild-cards 

Pattern matching in Haskell is different from that found in logic programming 
languages such as Prolog; in particular, it can be viewed as "one-way" matching, 
whereas Prolog allows "two-way" matching (via unification), along with implicit 
backtracking in its evaluation mechanism.) 

We note that our approach is not limited to handling only these specific 
representations of algebraic datatypes in C++, but can be applied to any class 
hierarchy, viewing patternm matching as a generalization of 
dynamic\_cast.

%[From Emir 2.1.2]
%Apart from testing for constructors, patterns can also test whether a data item is equal to
%a literal constant, a named constant or, in languages with subtyping, whether it has a certain
%type. The nesting of patterns can express structural constraints, which can be used to
%represent information.
%For instance, the pattern (Node 42 Leaf) matches values of SrchT that contains the literals
%and a leaf in this particular configuration.
%Nested patterns make programs very concise and readable, because the shape of a pattern
%determines the meaning of the program, which leaves many visual clues in the source code.
%For instance, to a programmer with a mathematical background but no prior exposure to
%pattern matching, it soon becomes self-evident that a pattern like (42,y) matches pairs
%whose left component is 42 and whose right component can be any value.

%[From Emir 2.1.3]
%An algebraic data type definition T fixes the structure of the instances of T once and for all.
%The constructor tags are special cases of T, which provides a relationship between the set
%of instances tagged with a particular constructor and the set of instances of T that is akin
%to nominal (explicitly declared) subtyping. One major difference is that an algebraic data
%type forms a "closed world": the set of constructors and their signature cannot be changed.
%The reason for this restriction ist that an algebraic data types defines a sum type and allows
%straightforward reasoning on its fixed structure. A welcome consequence of this restriction
%is that algebraic data types can be represented efficiently by replacing constructor tags with
%an integer constant.

%Since the set of constructors forms a closed world, an automatic check for incompleteness
%can be performed on match expressions: The compiler can thus warn programmers who by
%mistake omit a case from their match expressions, which would leave the match expression
%incomplete. This check is very helpful if there are many constructors or when nested patterns
%allow for combinatorial combinations of algebraic data types (e.g. for a pair of two SrchT
%instances).

%[From Extensible Algebraic Datatypes with Defaults]
%The traditional object-oriented and functional approaches
%both make extensions in one dimension easy, but extensions
%in the other dimension very hard. In the object-oriented approach,
%data is modelled by a set of classes, sharing a common
%interface. For the lambda term example, there would
%be an interface or abstract class Term specifying the eval
%method with subclasses Lambda, Apply and Variable. Each
%subclass defines its own implementation of eval. W hereas
%extending the datatype with new variants is simply done by
%creating new classes, adding new operations involves modifications
%of the abstract base class.
%On the other hand, in the functional approach, the variants
%of a datatype are typically implemented as an algebraic
%type. Here, defining new operations is easy. One just writes
%a new function which matches against the data variants.
%But since ordinary algebraic datatypes cannot be extended
%without modifications to the source code, it would not be
%possible to add new variants.
%Each of the two approaches can encode the other. In
%one direction, object-oriented languages can model the functional
%approach using the Visitor design pattern [14]. In
%the other direction, objects can be represented in functional
%languages as closures taking an algebraic datatype of messages
%as parameter. However, each of these encodings exchanges
%both the strengths and weaknesses of one approach
%with the strengths and the weaknesses of the other; neither
%encoding gains simultaneous extensibility of both data and
%operations.

\section{Pattern Matching for C++} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:pm}

\subsection{Algebraic Datatypes in C++}

%[From Emir PhD 2.1.1]
%In typed functional programming languages like HOPE [14], MIRANDA [90], HASKELL [47]
%and ML [64], users can define concrete data types as disjoint sums of primitive types, tuples
%and function types. Each variant, or constructor, is identified with a symbolic constant.
%Such data types can then be discriminated using patterns, which mention the constructor
%label along with a collection of sub-patterns or variables to bind the constituents of a matching
%instance. This data definition mechanism should be considered as a building block for
%the wider goal of functional programming, which is give clear semantics to data and enable
%equational reasoning about programs.
%
%Algebraic data types like SrchT are defined inductively as the least set closed under their
%constructor functions.

Functional programming community 
algebraic data type (sometimes also called a variant type[1]) is a datatype each 
of whose values is data from other datatypes wrapped in one of the constructors 
of the datatype. Any wrapped datum is an argument to the constructor. In 
contrast to other datatypes, the constructor is not executed and the only way to 
operate on the data is to unwrap the constructor using pattern matching.

There are at least 3 different ways to represent them in C++
We unify syntax 

An ML datatype of the form 

\begin{lstlisting}[language=ML]
datatype DT = C1 of {L11:T11,...,L1m:T1m} |...| Cr of {Lr1:Tr1,..., Lrn:Trn}
\end{lstlisting}

Can be encoded in C++ in at least the 4 following ways:

The important difference between algebraic data types and classes in C++ is that
algebraic data types are closed and once constructors have been defined, no new
constructors can be added. C++ classes on the other hand are always open: user 
may extend any class with a new constructor. Work on extensible data types 
exist\cite{ExtensibleDatatypes,LohHinze2006}

%Emir gives the following terminology in 2.1.1:
%The \emph{match expression} Match(...) contains \emph{case clauses} Case(T,...), 
%each with a pattern to match instances tagged with corresponding constructor.
%
% Algebraic data types like SrchT are defined inductively as the least set 
% closed under their constructor functions.

The result of invoking \code{match<T>(a,b,c)} is a \emph{pattern} that can be applied 
to a given instance of any type U, that is related by inheritance to T (i.e. is 
a base of, derived from or a sibling of). Applying given pattern to an instance 
returns a pointer to type T if matching succeeds along with binding all the 
variables and subexpressions the pattern was created with.

---------------

Similarly to Haskell, we employ \emph{first-fit} pattern matching under which the 
equations are matched linearly from top to bottom. This is why putting 
Otherwise() not at the end of the switch statement will effectively close all 
subsequent equations.

We first present informally the pattern matching facilities our library exposes.

Let's assume we have a simple class hierarchy of shapes:

\begin{lstlisting}
typedef std::pair<double,double> loc;

struct Shape
{
    virtual @$\sim$@Shape() {} // to enable RTTI
};

struct Circle : Shape
{
    Circle(const loc& c, const double& r) : center(c), radius(r) {}
    const loc& get_center() const { return center; }
    loc    center;
    double radius;
};


struct Square : Shape
{
    Square(const loc& c, const double& s) : upper_left(c), side(s) {}
    loc    upper_left;
    double side;
};

struct Triangle : Shape
{
    Triangle(const loc& a, const loc& b, const loc& c) : first(a), second(b), third(c) {}
    loc first, second, third;
};
\end{lstlisting}

Before the library can be used, the user has to provide decomposition into a 
tuple of all the data structures against which pattern matching will be 
performed. This is done through specializing traits-like class match\_members:

\begin{lstlisting}
template <> struct bindings<Shape>    {};
template <> struct bindings<Circle>   { CM(0,Circle::get_center); CM(1,Circle::radius); };
template <> struct bindings<Square>   { CM(0,Square::upper_left); CM(1,Square::side);   };
template <> struct bindings<Triangle> { CM(0,Triangle::first);    
                                        CM(1,Triangle::second); 
                                        CM(2,Triangle::third); };
\end{lstlisting}

The first argument of CM represent a position, while the second argument 
represents the member of the class that will be matched against in that position. 
Members don't have to be data members only, but can also be nullary member 
functions providing access to given subcomponent (as Circle::get\_center above).
With these definition we can write our first function using pattern matching.

\begin{lstlisting}
double area(const Shape& shape)
{
    wildcard _; // Meta variable
    loc      x,y,z;
    double   r,s;

    if (match<Circle>(_,r)(shape))
        return 3.14 * r * r;

    if (match<Square>(_,s)(shape))
        return s * s;

    if (match<Triangle>(x,y,z)(shape))
        return heron(x,y,z);

    assert(!"Inexhaustive search");
}
\end{lstlisting}

Unfortunately we have to predeclare variables as we are in a library setting and 
cannot change the compiler, while C++ requires all the variables to be forward 
declared. The binding of variables though works exactly as in other languages. 
One may have noticed that the wildcard has to be predeclared as well. This is 
not required as the library may provide a global variable with such name, we 
just wanted to mention here that the name of the meta variable may be arbitrary, 
it is its type that triggers the proper matching behavior.

TODO: Discuss exceptions while accessing members

\subsection{Guards}

The following pattern will match circles with any center but only those whose 
radius is greater than 3 and smaller than 5. The value of the radius of such 
matching Circle will be bound to r.

\begin{lstlisting}
    variable<double> r;
    if (match<Circle>(_, r |= r > 3 && r < 5)(shape)) ...
\end{lstlisting}

The expression in the guard can be arbitrarily complicated and unlike the 
pattern itself, the variables might be mentioned several times as by the time 
the guard is going to be evaluated, the variable will be bound. The |= operator 
that defines the guard was chosen arbitrarily from those that have pretty low 
precedence in C++ in order to allow most of the other operators be used in the 
condition part (right hand side) without parenthesis. The variable in the left 
hand side of the guard operator is the one that will be bound by the pattern. 
The condition part of the guard may include only this variable and the variables 
bound in preceeding positions. For example:

\begin{lstlisting}
    variable<double> x,y;
    if (match<Circle>(match<loc>(x, y |= y == x))(shape)) ...
\end{lstlisting}

This code will effectively match circles with the center on the line $y=x$. Note 
that the more straitforward notation:

\begin{lstlisting}
    if (match<Circle>(match<loc>(x, x))(shape)) ...
\end{lstlisting}

is invalid in most of the languages as it uses the same variable twice in the 
binding position. This can be given a semantics that the first use is the 
binding use, while the second one is the use as a bound value, but one would 
have to argue it won't lead to confusion and mistakes in more complicated 
expressions.

The important bit about our implementation of guards is that variables used in 
guards have to be explicitly wrapped into \code{variable<>} template in order to let 
the library build the corresponding expression template. The convenient notion 
that allowed us to use normal variables inside matches seen before will not work 
for guards as the expression would simply be evaluated using the C++ semantics 
and the resulting value will be passed to the match function as the value (and 
not the expression) we would like to match against.

We chose to provide syntax for guards directly in binding expressions in order 
to make sure we can determine certain pattern doesn't match as soon as possible 
and thus not have to compute matching for subsequent arguments. An alternative 
syntax for guards used in other languages is after the entire match expression, 
using traditional predicates.

\subsection{The (in)famous n+k patterns}

Similarly to Haskell (until 2010), we provide support for the n+k patterns. With 
them one can define factorial in the following way:

\begin{lstlisting}
int factorial(int n)
{
    variable<int> m;

    if (match<int>(0)(n))   return 1;
    if (match<int>(m+1)(n)) return (m+1)*factorial(m);
    return 0; // Should never happen
}
\end{lstlisting}

Unlike Haskell however, our patterns are not limited n+k form only and are 
generalized to any invertible operations. The definition of fast algorithm that 
computes x to the power of n can be written as following in the library:

\begin{lstlisting}
double power(double x, int n)
{
    variable<int> m;

    if (match<int>(0)(n))     return 1.0;
    if (match<int>(1)(n))     return x;
    if (match<int>(m*2)(n))   return sqr(power(x,m));
    if (match<int>(m*2+1)(n)) return x*power(x,2*m);
    return 0.0; // Should never happen
}
\end{lstlisting}

Another typical example that appears in the context of discussions about 
generalizing n+k patterns in Haskell is fast fibbonaci algorithm given below:

\begin{lstlisting}
int fib(int n)
{
    variable<int> m;

    if (match<int>(1)(n))     return 1;
    if (match<int>(2)(n))     return 1;
    if (match<int>(m*2)(n))   return sqr(fib(m+1)) - sqr(fib(m-1));
    if (match<int>(m*2+1)(n)) return sqr(fib(m+1)) + sqr(fib(m));
    return 0.0; // Should never happen
}
\end{lstlisting}

Interestingly enought instead of generalization, the n+k patterns were made 
obsolete in Haskell as of 2010\cite{HaskelDocMakingThis}. This was result of 
many discussions trying to provide semantics to them in the context of user 
defined types. Here, we are not claiming to solve the relevant discussions, but 
instead are making sure that our solution is transparent in such a way that we 
can use the C++0x forthcoming concept mechanism to deal with relevant issues. In 
particular when having a generalized n+k pattern on \code{variable<T>} we try to make 
sure that 

Scala uses a very stylistic approach to disambiguating variables that need to be 
bound from named constants. In particular they require that named constants 
start with capital letter while variables start with lowercase 
letter\cite[\textsection 2.8]{EmirPhd}. While such a requirement is inline with similar 
requirements for naming a constructor in various functional languages, this will 
raise eyebrowse in C++. We thus form our distinction between variables to be 
bound and values to be matched based on type of the expression: expressions that 
will bind to a reference type are assumed to be used as variables that have to 
be bound; expressions that will only bind to const reference are assumed to be 
values that have to be matched instead, even if they are named.

\subsection{Views}

Our extractors are similar to extractors in Scala, which in turn resemble Views 
proposed for Haskell.

TODO: Add discussion of pattern matching in generic code.

%[From Emir PhD Thesis 1.3]
%Adapting algebraic data types to the object-oriented context has been initiated by Wadler
%and Odersky's PIZZA extension to the JAVA programming language [70]. This language offers
%generics, closures and also algebraic data types and pattern matching. This extension
%was the first version of case classes: within the scope of class B, algebraic data type constructors
%Ki could be defined writing a constructor signature caseKi(T1f1, . . . , Tnfn). The
%compiler lifted these, turning them to full classes that extended the containing class B. Thus,
%classes Ki existed that inherited methods from B. The compiler also recognized calls to the
%constructor that were not preceded by the new keyword.

%In the SCALA programming language [69], case classes turned into classes that did not need
%to live in the scope of an enclosing class. The case has become merely a modifier that can
%turn any class into a case class - with the sole restriction that case classes could not inherit
%from case classes.

%This restriction was motivated by the implementation: at the time all these systems were
%designed, the JVM did not have the same aggressive optimizations that they have now. So
%the designers did not want to commit to slow instanceof checks and thus restricted case
%classes such that they could not have a direct or indirect parent that is also a case class. This
%way, a pattern match could always be optimized using integer tags (Chapter 4) takes up the
%idea or replacing type tests with integer tags.

Our notion of \emph{layout} is similar to Wadler's notion of Case class\cite{}

Discuss layouts as a way of handling pattern matching for cases of multiple 
inheritance.

%[From Emir PhD Thesis 1.4]
%For instancem, in his compiler textbook Appel [6,
%pp.94] contrasts compilers with graphic user interface toolkits, observing two orthogonal directions
%of modularity: both applications have a matrix of data and operations, but whereas
%for compilers, the data (syntax trees) is seldom changed but operations (compiler passes)
%are evolving, for a user interface toolkit, the operations (Redisplay, Move, . . . ) are fixed and
%the data (widgets) are unknown. Compilers need to separate operations from the classes
%that represent syntax trees, since it is inconvenient to change every syntax tree class when
%a single operation is added. In contrast, graphical user interface toolkits blend well with
%object-oriented style, since every widget can be implemented as a new class that will implement
%the interface that contains all the operations it has to support.

\section{Evaluation} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:eval}

In this section we evaluate the performance of our solution in comparison to the 
de facto standard -- visitor design pattern.

To evaluate the performance of our solution we've taken a working piece of code 
that operates visitor pattern on a fairly large class hierarchy and 
reimplemented it using pattern matching.

Preliminary evaluation results obtained on synthetic examples are as following:

As long as dynamic cast doesn't have to be invoked (e.g. we do n+k patterns or 
guards, the overhead is reasonable and is between 15 and 30 persent.

As soon as dynamic cast has to be used inside the match, the overhead easily 
becomes 10 times slower than visitor's single virtual function call. Because of 
sequential order of tests, the overhead for classes tested later becomes 
significant, effectively requiring the user to prioritize the order of tests.

\section{Discussion} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:dsc}

We considered using smaller types for storing line numbers based on our 
observation that we haven't found many C++ source files that had more than 65535 
lines. This was saving us space for hash tables but resulted in worse 
performance due to access of smaller words from memory.

We also looked into storing differences between switch'es head line number and 
case's line number, following the observation that very occasionaly we saw more 
than 256 cases in a pattern matching switch. This also degraded performance so 
we did not use it.

We would like to note that in presence of deeper hierarchy, visitors often 
implement members by forwarding call to their base, which may incure additional 
overhead.

\section{Related Work} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:rw}

A good survey of work on general pattern matching can be found in in a term 
project paper by Miller\cite{Miller10}.

Great overview of pattern matching in Scala compared to several other languages 
is presented in\cite{ScalaPM}.

Prop was an attempt to add pattern matching together with algebraic datatypes 
and other functional features into C++\cite{Prop96}.

JMatch was a similar incentive to add pattern matching to Java.

Sankel provides a good educational overview of how algebraic datatypes can be 
implemented in C++\cite{SankelFP10,Sankel10}. 

Emir's PhD thesis provides an extensive analysis of pattern matching in the 
context of object-oriented languages\cite{EmirThesis}.

Cook et al used expression templates to implement a query language to Pivot's 
IPR\cite{iql04}. The principal difference of their work from this work is that 
authors were essentially creating a pattern matcher for a given class hierarchy 
and thus could take the semantics of the entities represented by classes in the 
hierarchy into account. Our approach is parametrized over class hierarchy and 
thus provides a rather lower level pattern matching functionality that lets one 
simplify work with that hierarchy.  One can think of it as a generalized 
dynamic\_cast.

In his dissertation, Pirkelbauer provides a different pattern matcher against 
Pivot's IPR\cite{PirkelbauerThesis}.

Dos Reis et al compares functional and imperative approaches to generic 
programming and discusses the role of pattern matching in expressing generic 
algorithms in the functional approach\cite{dos_reis:05:what_is_gp}. They also 
demonstrate with an elegant example the amount of boilerplate code necessary to 
write in C++ in order to describe a sum-functor.k

Boost::proto is a library for creating DSL using expression templates.

TOM is a pattern matching compiler that adds pattern matching facilities to 
imperative languages such as C, Java, or Eiffel.\cite{Moreau:2003}

\section{Future Work} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:fw}

Describe formally concepts used in our expression templates.

Find better recursive patterns for sequences.

Make patterns more reusable by eliminating variables from those, saved into 
auto.

Multi-threaded environment support.

\section{Conclusions} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:cc}

In this work we describe design and implementation of a library that brings 
pattern matching facilities similar to those of functional programming languages 
into C++. Our solution does not requre any changes to the compiler and in its 
main part can be implemented in the standard C++98. Several extensions might 
require use of C++0x features, readily available in todays mainstream compilers.
The solution is non-intrusive and can be applied to any given class taxonomy 
retroactively. Its main utility lays in avoiding the control inversion problem 
typical to Visitor Design Pattern, which results in more clear, direct and much 
more consciece code. Our evaluation demonstrates that the solution scales to 
real-sized projects, while the performance results show that it comes close to 
its hand-crafted visitor alternative. The main novelty of the paper is in 
generalizing Haskell's n+k patterns to any invertible operations and 
demonstrating how to do it generically in a library setting. Backward semantics 
of expression templates used to implement this feature is also to the best of 
our knowledge first application of backward semantics to expression templates.

\section{ToDo} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
%\item + Profile Guided Optimizations on Visual C++ code
\item Separate sequential, random, repetitive into separate test programs
      and make one that combines them all. This is to test PGO effectiveness.
%\item Computation of irrelevant that minimizes amount of collisions
\item Proof that recomputations of irrelevant won't be done forever and will 
      stabilize
\item Instrument existing apps to see VTBL behavior
\item Finish experimenting with congruence hierarchy
%\item + Take difference of line numbers to have case labels small.
\item Justification/proof from Itanium ABI for our approach
%\item + Rethink switch for unions
%\item + Unify syntax of all the switches
\item Multiple dispatch switch
\item Different values of the same dynamic type
\item FIX: Value that would match type but wouldn't match condition may slow 
      down execution significantly. We need exit from switch instead of fall 
      through
\item Lock-free version to be used in multi-threaded environments.
\item Emir's PhD thesis has measurements, compare to those.
\end{itemize}

Discuss: Separating matching arguments from selector prevents us from optimizing
for some obvious but typical cases when type 

Discuss:
Visual C++ seems to generate better visitors code: 185 vs 222 units for GCC.
GCC seems to generate better matching code: 208 vs 209 units for Visual C++.
64 bit code in Visual C++ actually becomes faster: 143(x64) vs 185(w32) for 
visitors and 196(x64) vs 209(w32) for pattern matching. We can't at the moment 
generate 64bit GCC code.
Unlike GCC, we could not find a way to do branch hinting for Visual C++.

MS Visual C++ 10

 32 | Visitors | Matching      64 | Visitors | Matching 
--------------------------    --------------------------
SEQ |   185    |   209        SEQ |   145    |   190    
RND |   186    |   208        RND |   143    |   196    

GCC 4.5.2

 32 | Visitors | Matching      64 | Visitors | Matching 
--------------------------    --------------------------
SEQ |   215    |   189        SEQ |          |          
RND |   222    |   208        RND |          |          

\section{Acknowledgements} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Gregory Berkolaiko for entropy idea. Jaakko Jarvi for Haskell help. Andrew Sutton 
for suggestions. Jasson Cassey for branch hinting. Mani Zandifar for PAPI help.

\section{Scratch}

%[From LohHinze2006]
%The problem of supporting the modular extensibility of both data
%and functions in one programming language at the same time is
%known as the expression problem. Functional languages traditionally
%make it easy to add new functions, but extending data
%(adding new data constructors) requires modifying existing code.
%
%[From Modular Typechecking of Hierarchically Extensible Datatypes and Functions]
%Many researchers have noted a difference in the extensibility bene?ts offered
%by the functional and object-oriented (OO) styles [Reynolds 1978; Cook 1991;
%Odersky and Wadler 1997; Krishnamurthi et al. 1998; Findler and Flatt 1998;
%Garrigue 2000; Zenger and Odersky 2001]. Functional languages like ML allow new operations to be easily added to existing datatypes (by adding new
%fun declarations), without requiring access to existing code. However, new data
%variants cannot be added without a potentially whole-program modi?cation
%(since existing functions must be modi?ed in place to handle the new variants). On the other hand, traditional OO approaches allow new data variants
%to be easily added to existing class hierarchies (by declaring subclasses with
%overriding methods), without modifying existing code. However, adding new operations to existing classes requires access to the source code for those classes
%(since methods cannot be added to existing classes without modifying them in
%place).
%...
%However, such simplicity comes at a cost to programmers, who are forced to choose
%up front whether to represent an abstraction with datatypes or with classes. As
%described above, this decision impacts the kind of extensibility allowable for the
%abstraction. It may be dif?cult to determine a priori which kind of extensibility
%will be required, and it is dif?cult to change the decision after the fact. Further, it is not possible for the abstraction to enjoy both kinds of extensibility at
%once.
%...
%An alternative approach is to generalize existing ML constructs to support
%the OO style. OML [Reppy and Riecke 1996], for example, introduces an objtype
%construct for modeling class hierarchies. This construct can be seen as a generalization of ML datatypes to be hierarchical and extensible. Therefore, programmers need not decide between datatypes and classes up front; both are
%embodied in the objtype construct. However, OML still maintains a distinction
%between methods and functions, which have different bene?ts. New methods
%may not be added to existing objtypes without modifying existing code, while
%ordinary ML functions may be. Methods dynamically dispatch on their associated objtype, while functions support ML-style pattern matching.
%...
%ML? [Bourdoncle and Merz 1997] integrates the OO style further with existing ML constructs. Like OML, ML? generalizes ML datatypes to be hierarchical and extensible. Further, methods are simulated via function cases that use
%OO-style dynamic dispatch semantics. In this approach, programmers need
%not choose between two forms of extensibility; a single language mechanism
%supports the easy addition of both new operations and new variants to existing
%datatypes.
%...
%Classes additionally generalize ML-style datatypes to be extensible, whereby
%new variants can be written in modules other than the one declaring the
%datatype, and hierarchical, whereby variants can have their own "subvariants."
%In addition to
%being extensible and hierarchical, classes are also full-?edged types while ML
%variants are not. For example, classes can appear in a function's argument or
%return type.
%Single inheritance of classes is compatible with the ML style, in which each 
%data variant conceptually singly inherits from the corresponding datatype, as 
%shown in the above encoding of datatypes into classes. However, EML can support 
%multiple interface inheritance, like Java.
%...
%Intuitively, case c1
%is more speci?c than case c2 if the set of values matching c1's pattern is a
%subset of the set of values matching c2's pattern.
%...
%Unlike (both concrete and abstract) classes, interfaces may not appear in
%patterns. This restriction is the EML analogue of Java's restriction that an interface have no concrete methods. Both restrictions remove the potential for
%dynamic-dispatch ambiguities caused by multiple inheritance. Because of EML's
%restriction, interfaces do not impact ITC any differently from abstract classes.
%Therefore we ignore interfaces in the remainder of the paper.

\bibliographystyle{eptcs}
\bibliography{mlpatmat}
\end{document}
