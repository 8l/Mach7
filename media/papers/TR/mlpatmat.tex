\documentclass[preprint]{sigplanconf}

\usepackage{breakurl}             % Not needed if you use pdflatex only.
\usepackage{listings}

\lstdefinestyle{Caml}{language=Caml,%
  literate={when}{{{\bf when}}}4
}

\lstdefinestyle{C++}{language=C++,%
showstringspaces=false,
  columns=fullflexible,
  escapechar=@,
  basicstyle=\sffamily,
%  commentstyle=\rmfamily\itshape,
  moredelim=**[is][\color{white}]{~}{~},
  literate={[<]}{{\textless}}1      {[>]}{{\textgreater}}1 %
           {<}{{$\langle$}}1        {>}{{$\rangle$}}1 %
           {<=}{{$\leq$}}1          {>=}{{$\geq$}}1          {!=}{{$\neq$}}1 %
           {=>}{{$\Rightarrow\;$}}1 {->}{{$\rightarrow{}$}}1 %
           {<:}{{$\subtype{}\ $}}1  {<-}{{$\leftarrow$}}1 %
           {Match}{{\emph{Match}}}5 %
           {EndMatch}{{\emph{EndMatch}}}8 %
           {Case}{{\emph{Case}}}4 %
           {Que}{{\emph{Que}}}3 %
           {CM}{{\emph{CM}}}2 {KS}{{\emph{KS}}}2 {KV}{{\emph{KV}}}2 
}
\lstset{style=C++}
\DeclareRobustCommand{\code}[1]{{\lstinline[breaklines=false]{#1}}}
\DeclareRobustCommand{\codehaskell}[1]{{\lstinline[breaklines=false,language=Haskell]{#1}}}
\DeclareRobustCommand{\codeocaml}[1]{{\lstinline[breaklines=false,language=Caml]{#1}}}

%% grammar commands
\newcommand{\Rule}[1]{{\rmfamily\itshape{#1}}}
\newcommand{\Alt}{\ensuremath{|}}
\newcommand{\is}{$::=$}

\begin{document}

\conferenceinfo{DSL 2011}{Bordeaux, France} 
\copyrightyear{2011} 
\copyrightdata{[to be supplied]} 

\titlebanner{Technical Report}        % These are ignored unless
\preprintfooter{Y.Solodkyy, G.Dos Reis, B.Stroustrup: Pattern Matching for C++}   % 'preprint' option specified.

\title{Pattern Matching for C++}
\subtitle{your \code{visit}, Jim, is not \code{accept}able anymore}

\authorinfo{Yuriy Solodkyy\and Gabriel Dos Reis\and Bjarne Stroustrup}
           {Texas A\&M University\\ Texas, USA}
           {\{yuriys,gdr,bs\}@cse.tamu.edu}

\maketitle

\begin{abstract}
Pattern matching has been known in functional programming community as an 
abstraction mechanism that greatly simplifies the code. Following the success of 
functional languages, several imperative programming languages had introduced 
pattern matching into them. While this is relatively easy to do a-priori, when 
designing a new language, this might become quite a challenge to do a-posteriori 
when trying to introduce it into an industry strength language like C++. We 
present functional style pattern matching for C++ implemented as a library. 
Depending on a use case, our solution matches our outperforms its de facto 
contender -- the visitor design pattern, traditionally used in pattern-matching 
scenarios in C++. Unlike the visitor pattern, our solution is non-intrusive, 
open to new classes, avoids the control inversion and is much more concise, 
easier to read, maintain and comprehend. It also mimics many of the pattern 
matching facilities available in other languages on the first class basis, 
letting us experiment with them without any changes to the compiler. The 
solution can be reused in other object-oriented languages to implement
\emph{type switching}, \emph{type testing}, \emph{pattern matching} and 
\emph{multiple dispatch} efficiently.
\end{abstract}

\category{CR-number}{subcategory}{third-level}

\terms
Languages, Design

\keywords
Pattern Matching, Visitor Design Pattern, Expression Problem, C++

\section{Introduction} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:intro}

%Motivate the problem
%Give a summary of the paper: what you did and how
%Explicitly state your contribution

Pattern matching is an abstraction supported by many programming languages, which 
allows the user to describe in a breve manner a (possibly infinite) set of 
values accepted by the pattern. Pattern represents effectively a predicate on 
values, and is usually expected to be much more concise and readable than the 
equivalent predicate spelled out directly.

Popularized by functional programming community, most notably Hope\cite{BMS80}, 
ML\cite{ML90}, Miranda\cite{Miranda85} and Haskell\cite{Haskell98Book}, for 
providing syntax very close to mathematical notations, pattern matching has 
since been making its way into many imperative programming languages like 
Pizza\cite{Odersky97pizzainto}, Scala\cite{Scala2nd}, Fortress\cite{RPS10}, 
Java\cite{Liu03jmatch:iterable,HydroJ2003}, C++\cite{Prop96}, 
Eiffel\cite{Moreau:2003} and others. While this is relatively
easy to do a-priori when designing a new language, the introduction of pattern 
matching into an industry strengths language a-posteriori might become a 
challenge. The obvious utility of the feature may be overshadowed by the 
complications in the language semantics necessary to make pattern matching work 
with other features of the language. A prototype implementation will likely 
require a lot of effort, but will be hard to publish due to lack of novelty.

To balance the utility and effort we decided to start with a Semantically 
Enhanced Library Language\cite{SELL} approach, that promotes subsetting a 
general-purpose programming language with a library, extended with a tool 
support. This will typically not provide you 100\% of the functionality that a 
language extension would do, but will rather give you 80\% of it at 20\% of the 
time. This turned out to be a very economic decision as we ended up not requiring 
any external tool support at all, while providing a descent level of convenience 
and a great performance.

Naturally, our library-only solution has limitations and inconveniencies that 
stem from the fact that we work in a SELL setting. We are certain, however, that 
those can be easily overcome in a language solution and we provide relevant 
discussions when necessary. We regard our current solution as a proof of  
concept that sets the minimum threshold for performance, brevity, clarity and 
usefulness of the ultimate language solution for pattern matching in C++. It is 
a fully functional transitional facility, that lets users experiment with 
pattern matching in C++, while letting us experiment with and eventually shape 
the language solution.

To give a quick taste of what our library enables, let us look at an example from 
the domain where pattern matching is known to cut the edge of laconism and 
clarity -- compiler construction. Imagine a simple language of expressions:

\begin{lstlisting}
exp ::= val | exp + exp | exp - exp | exp * exp | exp / exp
\end{lstlisting}

OCaml data type describing this grammar as well as simple evaluator of expressions 
in it can be declared as following:

\begin{lstlisting}[language=Caml,keepspaces,columns=flexible]
type expr = Value  of int
          | Plus   of expr * expr
          | Minus  of expr * expr
          | Times  of expr * expr
          | Divide of expr * expr
          ;;

let rec eval e =
  match e with
            Value  v      -> v
          | Plus   (a, b) -> (eval a) + (eval b)
          | Minus  (a, b) -> (eval a) - (eval b)
          | Times  (a, b) -> (eval a) * (eval b)
          | Divide (a, b) -> (eval a) / (eval b)
          ;;
\end{lstlisting}

The corresponding C++ data types are slightly more verbose, though the only 
reason we have not parameterized them was to keep the example simple.

\begin{lstlisting}[keepspaces,columns=flexible]
struct Expr { virtual @$\sim$@Expr() {} };
struct Value  : Expr { int value; };
struct Plus   : Expr { Expr* exp1; Expr* exp2; };
struct Minus  : Expr { Expr* exp1; Expr* exp2; };
struct Times  : Expr { Expr* exp1; Expr* exp2; };
struct Divide : Expr { Expr* exp1; Expr* exp2; };
\end{lstlisting}

Together with evaluator presented below, they form an instance of the 
\emph{Interpreter Design Pattern}\cite{DesignPatterns1993}. Unlike the type 
definitions, the evaluator for the language, implemented on top of our pattern 
matching library is almost as laconic as its version in OCaml:

\begin{lstlisting}[keepspaces,columns=flexible]
int eval(const Expr* e)
{
    Match(e)@\footnote{We use alternative formatting on symbols representing preprocessor macros}@
    {
    Case(Value,  n)    return n;
    Case(Plus,   a, b) return eval(a) + eval(b);
    Case(Minus,  a, b) return eval(a) - eval(b);
    Case(Times,  a, b) return eval(a) * eval(b);
    Case(Divide, a, b) return eval(a) / eval(b);
    }
    EndMatch
}
\end{lstlisting}

The only definitions we omitted here that prevent the example from being fully 
functional are the mappings of class members to corresponding binding positions. 
We list them here for completeness, while their meaning will be explained later 
in section~\ref{}. Here we would like to mention though that these definitions are only 
needed to support the variables binding and not the type switching functionality 
of the \code{Match}.

\begin{lstlisting}[keepspaces,columns=flexible]
template <> struct bindings<Value>  { CM(0,Value::value); };
template <> struct bindings<Plus>   { CM(0,Plus::exp1); 
  ...                                 CM(1,Plus::exp2);   };
template <> struct bindings<Divide> { CM(0,Divide::exp1); 
                                      CM(1,Divide::exp2); };
\end{lstlisting}

The above syntax is enabled without any external tool support using new C++0x 
features\cite{C++0x}, template meta-programming and macros. As we 
show in section~\ref{sec:eval}, it runs up to 80\% faster (depending on the usage 
scenario, compiler and underlain hardware) than a similar code crafted with the 
\emph{Visitor Design Pattern}.

\subsection{Motivation}

%\subsection{Excursus}

The ideas and the library presented here originated from our rather 
unsatisfactory experience in working with various C++ front-ends and program 
analysis frameworks developed in C++\cite{Pivot09,Phoenix,Clang,Lise}. The 
problem was not in the frameworks per se, but in the fact that we had to use 
\emph{Visitor Design Pattern}\cite{DesignPatterns1993} to inspect, traverse and 
elaborate abstract syntax trees of their target languages. Having written enough 
visitors to realize how unsuitable they were for the job, we started looking for 
other mechanisms to work with abstract syntax trees, even if they would have 
turned out to be significantly slower. 
Presence of dynamic casts in many places, often nested, to answer simple 
structural questions without having to resort to visitors, was a strong 
indicator that even though visitors were fast, in many non-critical cases 
users preferred shorter, cleaner and a more clear code to performance.
The usage of \code{dynamic\_cast} in those cases resembled the use of 
pattern matching in functional languages to unpack algebraic data types. 
Functional languages have been long known to be very suitable for developing 
program analysis tools because of the brevity with which the necessary 
algorithms can be expressed. This is why our initial goal was to develop a 
domain-specific library within C++ that would enable us to express various 
predicates on tree-like structures with the laconism of functional languages.

%[From Emir PhD Thesis 1.3]
%In the context of the JAVA virtual machine (and any other object system that supports runtime
%type information), a much more direct way of obtaining the dynamic type of a value is
%to use an instanceof-check. Although these are considered bad style, programmers make
%use of them frequently, in order to avoid the overhead of using a Visitor implementation.
%They are error prone since it is possible to perform a cast without a preceding check.

\subsection{Visitor Design Pattern}
\label{sec:vdp}

%Discuss visitor design pattern and its problems.
%\begin{itemize}
%\item Intrusive - requires changes to the hierarchy
%\item Not open  - addition of new classes changes visitor interface
%\item Doesn't provide by default relation between visitors of base and derived classes
%\item Control inversion
%\item Cannot be generically extended to handling n arguments
%\end{itemize}

%[From Extensible Algebraic Datatypes with Defaults]
%In the object-oriented approach, data is modelled by a set of classes, sharing 
%a common interface. Each subclass defines its own implementation of eval. Whereas
%extending the datatype with new variants is simply done by
%creating new classes, adding new operations involves modifications
%of the abstract base class.

\emph{Visitor Design Pattern}\cite{DesignPatterns1993} was devised to solve a problem 
of extending existing classes with new functions in object-oriented languages. 
Consider the above Expr example and imagine we would like to provide a pretty 
printing of expressions. A typical object-oriented approach would be to 
introduce a virtual function \code{virtual void print() const = 0;} inside the 
abstract base class \code{Expr}, which will be implemented correspondingly in all derived 
classes. This works well as long as we know all the required operations on the 
abstract class in advance. Unfortunately, this is very difficult to achieve in 
reality as the code evolves, especially in production environment. To put this 
in context, imagine that after the above interface with pretty printing 
functionality has been deployed, we decided that we need a similar functionality 
that saves the expression in XML format. Adding new virtual function implies 
modifying the base class and creating a versioning problem with the code that 
has been deployed already using the old interface.

To alleviate this problem, Visitor Design Pattern separates the 
\emph{commonality} of all such future member-functions from their 
\emph{specifics}. The former deals with identifying the most specific derived 
class of the receiver object, known to the system at the time the base class was 
designed. The latter provides implementation of the required functionality once 
the most specific derived class has been identified. The interaction between the 
two is encoded in the protocol that fixes \emph{visitation interface} 
enumerating all known derived classes on one side and a dispatching mechanism 
that guarantees to select the most specific case with respect to the dynamic 
type of the receiver in the visitation interface. An implementation of this 
protocol for our Expr example might look as following:

\begin{lstlisting}
// Forward declaration of known derived classes
struct Value; struct Plus; ... struct Divide;
// Visitation interface
struct ExprVisitor
{
    virtual void visit(const Value&)  = 0;
    virtual void visit(const Plus&)   = 0;
    ...  // One virtual function per each known derived class
    virtual void visit(const Divide&) = 0;
};
// Abstract base and known derived classes
struct Expr { 
    virtual void accept(ExprVisitor&) const = 0; };
struct Value : Expr { ...
    void accept(ExprVisitor& v) const { v.visit(*this); } };
struct Plus  : Expr { ...
    void accept(ExprVisitor& v) const { v.visit(*this); } };
\end{lstlisting}

Note that even though implementations of \code{accept} member-functions are 
syntactically identical, a different \code{visit} is called. We rely here on the 
overload resolution mechanism of C++ to pick the most specialized \code{visit} 
member-function applicable to the static type of \code{*this}. This mere code 
maintenance convenience unfortunately, often confuses novices on what 
is going on. We thus would like to point out that member-functions in the 
visitation interface are not required to be called with the same name, -- we 
could have equally well called them \code{visit_value}, \code{visit_plus} etc. 
making the corresponding changes to calls inside \code{Value::accept}, 
\code{Plus::accept} etc.

A user can now implement his new functions similarly to the following function 
to convert expressions to string:

\begin{lstlisting}
std::string to_str(const Expr* e); // Forward declaration

struct ToStrVisitor : ExprVisitor
{
    void visit(const Value& e) { result = std::to_string(e.value); }
    ...
    void visit(const Divide& e) { 
        result = to_str(e.exp1) + '/' + to_str(e.exp2); 
    }
    std::string result;
};
// Actual implementation based on visitor
std::string to_str(const Expr* e)
{
    ToStrVisitor v;
    e->accept(v);
    return v.result;
}
\end{lstlisting}

Function \code{eval} we presented above as well as any new function that we 
would like to add to \code{Expr} can now be implemented in much the same way, 
without the need to change base interface. This flexibility does not come for 
free though and we would like to point out some pros and cons of this solution.

The most important advantage of the visitor design pattern is possibility to add 
new operations to the class hierarchy without the necessity to change the 
interface each time. It's second most quoted advantage is typically speed -- the 
overhead of two virtual function calls incurred by the double dispatch present 
in the visitor design pattern is often negligible on the modern architectures. 
There are quite a few disadvantages however.

The {\bf increased amount of boilerplate code} that has to be added to support 
the above solution cannot go unnoticed. Several entities had to be forward 
declared because of the mutual recursivity of their definitions. The solution is 
{\bf specific to hierarchy}, as we had to declare a visitation interface 
specific to the base class. It is also {\bf intrusive} since we had to inject 
syntactically the same definition of \code{accept} method into every class 
participating in visitation. The amount of the necessary support increases, as 
additional arguments have to be passed into the visitor to be available during 
the visitation. This aspect can be seen in the example from 
section~\ref{sec:xmpl} where we have to store both functors inside the visitor.  

More importantly, visitors {\bf hinder extensibility} of the class hierarchy: 
new classes added to the hierarchy after the visitation interface has been 
fixed, will be treated as their most derived base class present in the interface.
A solution to this problem has been proposed in the form of \emph{Extensible 
Visitors with Default Cases}\cite[\textsection 4.2]{Zenger:2001}, however the solution, after 
remapping it onto C++, has problems of its own. The visitation interface 
hierarchy can easily be grown linearly (adding new cases for the new classes in 
the original hierarchy each time), but independent extensions by different  
authorities require developer's intervention to unify them all, before they can 
be used together. This may not be feasible in environments that use dynamic 
linking. To avoid writing even more boilerplate code in new visitors, the 
solution would require usage of virtual inheritance, which typically has 
an overhead of extra memory dereferencing. On top of the double dispatch already 
present in the visitor pattern, the solution will incur two additional virtual 
calls and a dynamic cast for each level of visitor extension. Additional double 
dispatch is incurred by forwarding of default handling from base visitor to a 
derived one, while the dynamic cast is required for safety and can be replaced 
with a static case when visitation interface is guaranteed to be grown linearly 
(extended by one authority only). Yet another virtual call is required to be 
able to forward computations to subcomponents on tree-like structures to the 
most derived visitor. This last function lets one avoid the necessity of using 
heap to allocate a temporary visitor through the \emph{Factory Design 
Pattern}\cite{DesignPatterns1993} used in \emph{Extensible Visitor} solution 
originally proposed by Krishnamurti, Felleisen and Friedman\cite{Krishnamurthi98}.

Once all the boilerplate related to visitors has been written and the visitation 
interface has been fixed we are still left with some annoyances incurred by the 
pattern. One of them is the necessity to work with the {\bf control inversion} 
that visitors put in place. Because of it we have to save any local state and 
any arguments that some of the \code{visit} callbacks might need from the 
calling environment. Similarly, we have to save the result of the visitation, 
as we cannot assume that all the visitors that will potentially be implemented 
on a given hierarchy will use the same result type. Using visitors in a generic 
algorithm requires even more precautions. We summarize these visitor-related 
issues in the following motivating example, followed by an illustration of a 
pattern-matching solution to the same problem enabled with our library.

%[From The Essence of the Visitor Pattern]
%For object-oriented programming, the Visitor pattern en-
%ables the denition of a new operation on an object structure without
%changing the classes of the objects. The price has been that the set of
%classes must be xed in advance, and they must each have a so-called
%accept method.

%[From Emir PhD Thesis 1.4.2]
%Apart from readability and safety, a high-level construct for pattern matching provides opportunities
%for optimization and for static checks.
%A drawback of all object-oriented solutions above is that standard compilers do not check
%whether such hand-crafted case distinction based on type-tests and type-casts cover all the
%cases, nor whether all branches can actually be entered. Pattern matching constructs in functional
%programming languages can be checked statically for incompleteness and redundancy,
%which helps catch many programmer mistakes.

\subsection{Motivating Example}
\label{sec:xmlp}

While comparing generic programming facilities available to functional and 
imperative languages (mainly Haskell and C++), Dos Reis and Jarvi present the 
following example in Haskell describing a sum functor\cite{DRJ05}:

\begin{lstlisting}[language=Haskell]
data Either a b = Left a | Right b

eitherLift :: (a -> c) -> (b -> d) -> Either a b -> Either c d
eitherLift f g (Left  x) = Left  (f x)
eitherLift f g (Right y) = Right (g y)
\end{lstlisting}

In simple words, the function \codehaskell{eitherLift} above takes two functions and an 
object and depending on the actual type constructor the object was created with, 
calls first or second function on the embedded value, encoding the result 
correspondingly.

Its equivalent in C++ is not as straightforward. The idiomatic handling of 
discriminated unions in C++ typically assumes use of the \emph{Visitor Design 
Pattern}\cite{DesignPatterns1993}.

\begin{lstlisting}
template <class X, class Y> class Either;
template <class X, class Y> class Left;
template <class X, class Y> class Right;

template <class X, class Y>
struct EitherVisitor {
    virtual void visit(const  Left<X,Y>&) = 0;
    virtual void visit(const Right<X,Y>&) = 0;
};

template <class X, class Y>
struct Either {
    virtual @$\sim$@Either() {}
    virtual void accept(EitherVisitor<X,Y>& v) const = 0;
};

template <class X, class Y>
struct Left : Either<X,Y> {
    const X& x;
    Left(const X& x) : x(x) {}
    void accept(EitherVisitor<X,Y>& v) const { v.visit(*this); }
};

template <class X, class Y>
struct Right : Either<X,Y> {
    const Y& y;
    Right(const Y& y) : y(y) {}
    void accept(EitherVisitor<X,Y>& v) const { v.visit(*this); }
};
\end{lstlisting}

The code above defines the necessary parameterized data structures as well as a 
correspondingly parameterized visitor class capable of introspecting it at 
run-time. The authors agree with us \emph{``The code has a fair amount of 
boilerplate to simulate pattern matching...''} The actual implementation of 
\codehaskell{lift} in C++ now amounts to declaring and invoking a visitor:

\begin{lstlisting}
template <class X, class Y, class S, class T>
const Either<S,T>& lift(const Either<X,Y>& e, S f(X), T g(Y))
{
    typedef S (*F)(X);
    typedef T (*G)(Y);
    struct Impl : EitherVisitor<X,Y> {
        F f;
        G g;
        const Either<S,T>* value;
        Impl(F f, G g) : f(f), g(g), value() {}
        void visit(const Left<X,Y>& e) {
            value = left<S,T>(f(e.x));
        }
        void visit(const Right<X,Y>& e) {
            value = right<S,T>(g(e.y));
        }
    };
    Impl vis(f, g);
    e.accept(vis);
    return *vis.value;
}
\end{lstlisting}

The same function expressed with our pattern-matching facility seems to be much 
closer to the original Haskell definition:

\begin{lstlisting}[keepspaces,columns=flexible]
template <class X, class Y, class S, class T>
const Either<S,T>* lift(const Either<X,Y>& e, S f(X), T g(Y))
{
    Match@$^T$@(e)@\footnote{T indicates that the user will have to use TMatch, TCase and TEndMatch versions of the macros respectively since the substituted code has to be correct in the template environment}@
      Case(( Left<X,Y>), x)  return  left<S,T>(f(x));@\footnote{We need to take the first argument in parentheses to avoid interpretation of comma in template argument list by the preprocessor}@
      Case((Right<X,Y>), y)  return right<S,T>(g(y));
    EndMatch
}
\end{lstlisting}

It is also as fast as the visitor solution, but unlike the visitors based 
approach neither requires \code{EitherVisitor} class anymore (together with 
forward declarations it needed), nor any of the \code{accept} member-functions 
injected in all three classes. We do require binding definitions though to be 
able to bind variables \code{x} and \code{y}:
\footnote{Definitions of obvious functions \code{left} and \code{right} have 
been ommitted in both cases.}

\begin{lstlisting}[keepspaces,columns=flexible]
template <class X, class Y> 
    struct bindings<Left<X,Y>>  { CM(0, Left<X,Y>::x); };
template <class X, class Y> 
    struct bindings<Right<X,Y>> { CM(0,Right<X,Y>::y); };
\end{lstlisting}

Note that these binding definitions are made once for all possible instantiations 
with the use of partial template specialization in C++.

\subsection{Summary}

The contributions of the paper can be summarized as following:

\begin{itemize}
\item We present a technique that can be used to implement type switching 
      effectively based on the run-time type of the argument. 
  \begin{itemize}
  \item The technique outperforms its de facto contender -- visitor design 
        pattern without sacrificing extensibility.
  \item It works in the presence of multiple inheritance, including repeated and 
        virtual inheritance as well as in generic code.
  \item The technique generalizes to other object-oriented languages that use 
        virtual tables to implement dynamic dispatch.
  \end{itemize}
\item We present a functional style pattern matching for C++ built as a library 
      employing the above technique.
  \begin{itemize}
  \item The solution is open, non-intrusive and can be applied to any class 
        hierarchy retroactively.
  \item It allows one to avoid the control inversion typical for visitors.
  \item We provide performance and ease of use comparison based on real code.
  \end{itemize}
\end{itemize}

The novelty of the paper lays in a new method that can be used by compilers of 
object-oriented languages as well as libraries written in them to implement 
\emph{type switching}, \emph{type testing}, \emph{pattern matching} and 
\emph{multiple dispatch} efficiently. We look at different approaches that are 
taken in implementing algebraic data types in C++ today and present a unified 
pattern-matching syntax that works uniformly with all of them. We also 
generalize Haskell's n+k patterns to any invertible operations. Semantics issues 
that typically accompany n+k pattern are handled transparently by forwarding the 
problem into the concepts domain, thanks to the fact that we work in a library 
setting. A practical benefit of our solution is that it can be used right away 
with any compiler with a descent support of C++0x without requiring to install 
any additional tools or preprocessors.

The rest of this paper is structured as following. In Section~\ref{sec:bg}, we 
present evolution of pattern matching in different languages, presenting 
informally through example commonly used terminology and semantics of various 
pattern-matching facilities. Section~\ref{sec:pm} presents various approaches 
that are taken in C++ to implementing algebraic data types as well as 
demonstrates uniform handling of them in our pattern-matching library. 
Section~\ref{sec:impl} discusses the \emph{v-table caching} technique that made 
the efficient implementation of pattern matching possible, while 
Section~\ref{sec:eval} provides performance evaluation of this technique against 
common alternatives. Section~\ref{sec:rw} discusses some related work, while 
Section~\ref{sec:cc} concludes by discussing some future directions and possible 
improvements.

\section{Background} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:bg}

%[From Emir PhD 1.1]
%In functional programming languages, pattern matching has been closely related to algebraic
%data types since its beginning - Burstall\cite{Burstall69provingproperties} is the first to define a pattern matching
%construct that resembles the one found in statically typed functional languages today.

Pattern matching in the context of a programming language was first introduced 
in a string manipulation language SNOBOL\cite{SNOBOL64}. Its fourth 
reincarnation SNOBOL4 had patterns as first-class data types providing 
operations of concatenation and alternation on them\cite{SNOBOL71}. The first 
reference to a pattern-matching construct that resembles the one found in 
statically typed functional languages today is usually attributed to Burstall 
and his work on structural induction\cite{Burstall69provingproperties}.

%[From Emir PhD thesis 1.6]
%The SCALA compiler is the effort of several researchers, and combining pattern matching
%and object-oriented programming has been approached before\cite{Odersky97pizzainto,Zenger:2001}.

In the context of object-oriented programming, pattern matching has been first 
explored in Pizza programming language\cite{Odersky97pizzainto}. These efforts 
have been continued in Scala\cite{Scala2nd} and together with notable work of 
Burak Emir on \emph{Object-Oriented Pattern Matching}\cite{EmirThesis} have 
resulted in incorporation of pattern matching into the language.

%The first tree based pattern matching methods were found in Fred McBride's 
%extension of LISP in 1970.

%ML and Haskell further popularized pattern matching ...

Pattern matching has been closely related to \emph{algebraic data types} and 
\emph{equational reasoning} since the early days of functional programming.
In languages like ML and Haskel an \emph{Algebraic Data Type} is a data type 
each of whose values is picked from a disjoint sum of (possibly recursive) data 
types, called \emph{variants}. Each of the variants is marked with a unique 
symbolic constant called \emph{constructor}. Constructors provide a 
convenient way of creating a value of its variant type as well as a way of 
discriminating its variant type from the algebraic data type through pattern 
matching.

Algebraic data type \codeocaml{expr} from Section~\ref{sec:intro} consists of 5 
variants, marked with constructors \codeocaml{Value}, \codeocaml{Plus}, 
\codeocaml{Minus}, \codeocaml{Times} and \codeocaml{Divide} respectively. 
Constructor \codeocaml{Value} expects a value of type \codeocaml{int} during 
construction, as well as any pattern that admits values of type \codeocaml{int} 
during decomposition through pattern matching. Similarly, the other four 
constructors expect a value of a cartesian product of two \codeocaml{expr} 
types during construction, as well as any pattern that would admit a value of 
such type during decomposition.

Algebraic data types can be parameterized and recursive, as demonstrated by the 
following Haskell code that defines a binary tree parameterized on type 
\codehaskell{k} of keys and type \codehaskell{d} of data stored in the nodes:

\begin{lstlisting}[language=Haskell]
data Tree k d = Node k d (Tree k d) (Tree k d) | Leaf
\end{lstlisting}

Naturally, they can be decomposed in a generic algorithm like the function 
\code{find} below, defined through case analysis on the tree's structure:

\begin{lstlisting}[language=Haskell]
find :: (Ord k) => k -> Tree k d -> Maybe d
find i Leaf = Nothing
find i (Node key item left right) = 
    if i == key 
    then Just item 
    else 
        if i [<] key 
        then find i left 
        else find i right
\end{lstlisting}

The set of values described by a given algebraic data type is defined 
inductively as the least set closed under constructor functions of its variants.
Algebraic data types draw their name from the practice of using case distinction 
in mathematical function definitions and proofs that involve \emph{algebraic 
terms}.

One of the main differences of algebraic data types from classes in 
object-oriented languages is that an algebraic data type definition is 
\emph{closed} because it fixes the structure of its instances once and for all. 
Once we have listed all the variants a given algebraic data type may have we 
cannot extend it with new variants without modifying its definition. This is not 
the case in object-oriented languages, where classes are \emph{open} to 
extension through subclassing. 

Closeness of algebraic data types is particularly useful in reasoning about 
programs by case analysis and allows the compiler to perform an automatic 
\emph{incompleteness} check -- test of whether a given match expression covers all 
possible cases. A related notion of \emph{redundancy} checking arises from the 
tradition of using \emph{first-fit} strategy in pattern matching. It warns the 
user of any \emph{case clause} inside a \emph{matching expression} that will 
never be entered because of preceding one being more general. Object-oriented 
languages, especially C++, typically prefer \emph{best-fit} strategy (e.g. for 
overload resolution and class template specialization) because it is not prone 
to errors where semantics of a statement might change depending on the ordering 
of preceding definitions. The notable exception in C++ semantics that prefers 
the \emph{first-fit} strategy is ordering of \code{catch} handlers of a 
try-block. Similarly to functional languages the C++ compiler will perform 
\emph{redundancy} checking on catch handlers and issue a warning that lists the 
redundant cases.

%[From Emir PhD 1.4.2]
%Incompleteness describes a match expression that does not cover all cases, 
%whereas redundancy indicates a case that can never be entered because of a 
%preceding one being more general. 

%The constructor tags are special cases of T, which provides a relationship between the set
%of instances tagged with a particular constructor and the set of instances of T that is akin
%to nominal (explicitly declared) subtyping. One major difference is that an algebraic data
%type forms a "closed world": the set of constructors and their signature cannot be changed.
%The reason for this restriction ist that an algebraic data types defines a sum type and allows
%straightforward reasoning on its fixed structure. A welcome consequence of this restriction
%is that algebraic data types can be represented efficiently by replacing constructor tags with
%an integer constant.

%Since the set of constructors forms a closed world, an automatic check for incompleteness
%can be performed on match expressions: The compiler can thus warn programmers who by
%mistake omit a case from their match expressions, which would leave the match expression
%incomplete. This check is very helpful if there are many constructors or when nested patterns
%allow for combinatorial combinations of algebraic data types (e.g. for a pair of two SrchT
%instances).

%[From Emir PhD 2.1.1]
%In typed functional programming languages like HOPE [14], MIRANDA [90], HASKELL [47]
%and ML [64], users can define concrete data types as disjoint sums of primitive types, tuples
%and function types. Each variant, or constructor, is identified with a symbolic constant.
%Such data types can then be discriminated using patterns, which mention the constructor
%label along with a collection of sub-patterns or variables to bind the constituents of a matching
%instance. This data definition mechanism should be considered as a building block for
%the wider goal of functional programming, which is give clear semantics to data and enable
%equational reasoning about programs.
%
%Algebraic data types like SrchT are defined inductively as the least set closed under their
%constructor functions.

The patterns that work with algebraic data types we have seen so far are 
generally called \emph{tree patterns} or \emph{data constructor patterns}. 
Special cases of these patterns are \emph{list patterns} and \emph{tuple 
patterns}. The former lets one split a list into a sequence of elements in its 
beginning and a tail with the help of list constructor \codehaskell{:} and an 
empty list constructor \codehaskell{[]} e.g. \codehaskell{[x:y:rest]}. The 
latter does the same with tuples using tuple constructor 
\codehaskell{(,,...,)} e.g. \codehaskell{([x:xs],'b',(1,2.0),"hi",True)}.

Pattern matching is not used solely with algebraic data types and can equally 
well be applied to built-in types. The following Haskell code defines factorial 
function in the form of equations:

\begin{lstlisting}[language=Haskell]
factorial 0 = 1
factorial n = n * factorial (n-1)
\end{lstlisting}

Here 0 in the left hand side of the first \emph{equation} is an example of a 
\emph{value pattern} (also known as \emph{constant pattern}) that will only 
match when the actual argument passed to the function factorial is 0. The 
\emph{variable pattern} \codehaskell{n} (also referred to as \emph{identifier 
pattern}) in the left hand side of the second equation will match any value, 
\emph{binding} variable \codehaskell{n} to that value in the right hand side of 
equation. Similarly to variable  
pattern, \emph{wildcard pattern} \codehaskell{_} will match any value with the 
exception that the matched value will not be bound to any variable. Value 
patterns, variable patterns and wildcard patterns are generally called 
\emph{primitive patterns}. Patterns like variable and wildcard patterns that 
never fail to match are called \emph{irrefutable}, in contrast to 
\emph{refutable} patterns like value patterns, which may fail to match.

In Haskell 98\cite{Haskell98Book} the above definition of factorial could also 
be written as:

\begin{lstlisting}[language=Haskell]
factorial 0 = 1
factorial (n+1) = (n+1) * factorial n
\end{lstlisting}

The \codehaskell{(n+1)} pattern in the left hand side of equation is an example of 
\emph{n+k pattern}. Accordingly to its informal semantics ``Matching an $n+k$ 
pattern (where $n$ is a variable and $k$ is a positive integer literal) against 
a value $v$ succeeds if $v \ge k$, resulting in the binding of $n$ to $v-k$, and 
fails otherwise''\cite{haskell98}. n+k patterns were introduced into Haskel to 
let users express inductive functions on natural numbers in much the same way as 
functions defined through case analysis on algebraic data types. Besides 
succinct notation, such language feature could facilitate automatic proof of 
termination of such functions by compiler. Peano numbers, used as an analogy to 
algebraic data type representation of natural numbers, is not always the best 
abstraction for representing other mathematical operations however. This,  
together with numerous ways of defining semantics of generalized n+k patterns 
were some of the reasons why the feature was never generalized in Haskell to 
other kinds of expressions, even though there were plenty of known applications. 
Moreover, numerous debates over semantics and usefulness of the feature 
resulted in n+k patterns being removed from the language altogether in Haskell 
2010 standard\cite{haskell2010}. Generalization of n+k patterns, called 
\emph{application patterns} has been studied by Nikolaas N. Oosterhof in his 
Master's thesis\cite{OosterhofThesis}.

While n+k patterns were something very few languages had, another common feature of 
many programming languages with pattern matching are guards. A \emph{guard} 
is a predicate attached to a pattern that may make use of the variables bound in 
it. The result of its evaluation will determine whether the case clause and the 
body associated with it will be \emph{accepted} or \emph{rejected}. The 
following OCaml code for $exp$ language from Section~\ref{sec:intro} defines the 
rules for factorizing expressions $e_1e_2+e_1e_3$ into $e_1(e_2+e_3)$ and 
$e_1e_2+e_3e_2$ into $(e_1+e_3)e_2$ with the help of guards spelled out after 
keyword \codeocaml{when}:

\begin{lstlisting}[language=Caml,keepspaces,columns=flexible]
let factorize e =
    match e with
      Plus(Times(e1,e2), Times(e3,e4)) when e1 = e3 
          -> Times(e1, Plus(e2,e4))
    | Plus(Times(e1,e2), Times(e3,e4)) when e2 = e4 
          -> Times(Plus(e1,e3), e4)
    |   e -> e
    ;;
\end{lstlisting}

One may wonder why could not we simply write the above case clause as 
\codeocaml{Plus(Times(e,e2), Times(e,e4))} to avoid the guard? Patterns that 
permit use of the same variable in them multiple times are called 
\emph{equivalence patterns}, while the requirement of absence of such patterns 
in a language is called \emph{linearity}. Unfortunately, neither OCaml nor 
Haskell support such patterns. Miranda\cite{Miranda85} is one of the languages 
that permit them. 

The example above illustrates yet another common pattern-matching facility -- 
\emph{nesting of patterns}. With a simple expression in the case clause we 
define a predicate that tests the top-level expression to be tagged with a
\codeocaml{Plus} constructor, while both of its arguments to be marked with 
\codeocaml{Times} constructor, binding their arguments (or potentially pattern 
matching further) respectively. Note that the visitor design pattern does not 
provide this level of flexibility and each of the nested tests might have 
required a new visitor to be written. Nesting of patterns like the one above is 
typically where users resort to \emph{type tests} and \emph{type casts} that in 
case of C++ can be combined into a single call to \code{dynamic_cast}.

Related to nested patterns are \emph{as-patterns} that help one take a value 
apart while still maintaining its integrity. The following rule could have been 
a part of a hypothetical rewriting system in OCaml similar to the one above. Its 
intention is to rewrite expressions of the form $\frac{e_1/e_2}{e_3/e_4}$ into 
$\frac{e_1}{e_2}\frac{e_4}{e_3} \wedge e_2\neq0 \wedge e_3\neq0 \wedge e_4\neq0$.

\begin{lstlisting}[language=Caml,keepspaces,columns=flexible]
    | Divide(Divide(_,e2) as numerator, Divide(e3,e4))
          -> Times(numerator, Divide(e4, e3))
\end{lstlisting}

We introduced a name ``numerator'' as a synonym of the result of matching the 
entire sub-expression \codeocaml{Divide(_,e2)} in order to refer it without 
recomposing in the right-hand side of the case clause. We omitted the 
conjunction of relevant non-zero checks for brevity, one can see that we will 
need access to \codeocaml{e2} in it however.

Decomposing algebraic data types through pattern matching has an important 
drawback that was originally spotted by Wadler\cite{Wadler87}: they expose 
concrete representation of an abstract data type, which conflicts with the 
principle of \emph{data abstraction}. To overcome the problem he proposed the 
notion of \emph{views} that represent conversions between different 
representations that are implicitly applied during pattern matching. As an 
example, imagine polar and cartesian representations of complex numbers. A user 
might choose polar representation as a concrete representation for the abstract 
data type \codeocaml{complex}, treating cartesian representation as view or vice 
versa:\footnote{We use syntax from Wadler's original paper for this example}

\begin{lstlisting}[language=Haskell,columns=flexible]
complex ::= Pole real real
view complex ::= Cart real real
  in  (Pole r t) = Cart (r * cos t) (r * sin t)
  out (Cart x y) = Pole (sqrt(x^2 + y^2)) (atan2 x y)
\end{lstlisting}

The operations then might be implemented in whatever representation is the most 
suitable, while the compiler will implicitly convert representation if needed:

\begin{lstlisting}[language=Haskell,columns=flexible]
  add  (Cart x1 y1) (Cart x2 y2) = Cart (x1 + x2) (y1 + y2)
  mult (Pole r1 t1) (Pole r2 t2) = Pole (r1 * r2) (t1 + t2)
\end{lstlisting}

The idea of views were later adopted in various forms in several languages: 
Haskell\cite{views96}, Standard ML\cite{views98}, Scala (in the form of 
\emph{extractors}\cite{EmirThesis}) and F$\sharp$ (under the name of 
\emph{active patterns}\cite{Syme07}).

%Views in functional programming languages [92, 71] are conversions from one data type to
%another that are implicitly applied in pattern matching. They play a role similar to extractors
%in Scala, in that they permit to abstract from the concrete data-type of the matched objects.
%However, unlike extractors, views are anonymous and are tied to a particular target data
%type.

Logic programming languages like Prolog take pattern matching to even greater 
level. The main difference between pattern matching in logic languages and 
functional languages is that functional pattern matching is a ``one-way'' 
matching where patterns are matched against values, possibly binding some 
variables in the pattern along the way. Pattern matching in logic programming is 
``two-way'' matching based on \emph{unification} where patterns can be matched 
against other patterns, possibly binding some variables in both patterns and 
potentially leaving some variables \emph{unbound} or partially bound -- i.e. 
bound to patterns. A hypothetical example of such functionality can be matching 
a pattern \codeocaml{Plus(x,Times(x,1))} against another pattern 
\codeocaml{Plus(Divide(y,2),z)}, which will result in binding \codeocaml{x} to a 
\codeocaml{Divide(y,2)} and \codeocaml{z} to \codeocaml{Times(Divide(y,2),1)} 
with \codeocaml{y} left unbound, leaving both \codeocaml{x} and \codeocaml{z} 
effectively a pattern.

%[From Emir 2.1.2]
%Apart from testing for constructors, patterns can also test whether a data item is equal to
%a literal constant, a named constant or, in languages with subtyping, whether it has a certain
%type. The nesting of patterns can express structural constraints, which can be used to
%represent information.
%For instance, the pattern (Node 42 Leaf) matches values of SrchT that contains the literals
%and a leaf in this particular configuration.
%Nested patterns make programs very concise and readable, because the shape of a pattern
%determines the meaning of the program, which leaves many visual clues in the source code.
%For instance, to a programmer with a mathematical background but no prior exposure to
%pattern matching, it soon becomes self-evident that a pattern like (42,y) matches pairs
%whose left component is 42 and whose right component can be any value.

%[From Emir 2.1.3]
%An algebraic data type definition T fixes the structure of the instances of T once and for all.
%The constructor tags are special cases of T, which provides a relationship between the set
%of instances tagged with a particular constructor and the set of instances of T that is akin
%to nominal (explicitly declared) subtyping. One major difference is that an algebraic data
%type forms a "closed world": the set of constructors and their signature cannot be changed.
%The reason for this restriction ist that an algebraic data types defines a sum type and allows
%straightforward reasoning on its fixed structure. A welcome consequence of this restriction
%is that algebraic data types can be represented efficiently by replacing constructor tags with
%an integer constant.

%Since the set of constructors forms a closed world, an automatic check for incompleteness
%can be performed on match expressions: The compiler can thus warn programmers who by
%mistake omit a case from their match expressions, which would leave the match expression
%incomplete. This check is very helpful if there are many constructors or when nested patterns
%allow for combinatorial combinations of algebraic data types (e.g. for a pair of two SrchT
%instances).

\section{Pattern Matching for C++} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:pm}

C++ does not have a direct support of algebraic data types, but they can usually 
be emulated in a number of ways. A pattern-matching solution that strives to be 
general will have to account for different encodings and be applicable to all of 
them.

\subsection{Algebraic Data Types in C++}

Consider an ML data type of the form:

\begin{lstlisting}[language=ML,keepspaces,columns=flexible,escapechar=@]
datatype DT = @$C_1$@ of {@$L_{11}:T_{11},...,L_{1m}:T_{1m}$@} 
              | ...
              | @$C_k$@ of {@$L_{k1}:T_{k1},...,L_{kn}:T_{kn}$@}
\end{lstlisting}

\noindent We are aware of at least 3 different ways to encode them in C++:

\begin{itemize}
\item Polymorphic Base Class
\item Tagged Class
\item Discriminated Union
\end{itemize}

\subsubsection{Polymorphic Base Class}

In this encoding user declares a polymorphic base class \code{DT} that will 
be extended by classes representing all the variants. Base class might declare 
several virtual functions that will be overriden by derived classes, for example 
\code{accept} used in a Visitor Design Pattern. Among the frameworks we dealt 
with, Pivot\cite{Pivot09} and Phoenix\cite{Phoenix} used this approach.

\begin{lstlisting}[keepspaces,columns=flexible]
class DT { virtual @$\sim$@DT{} };
class @$C_1$@ : public DT {@$T_{11} L_{11}; ... T_{1m} L_{1m};$@} 
...
class @$C_k$@ : public DT {@$T_{k1} L_{k1}; ... T_{kn} L_{kn};$@} 
\end{lstlisting}

The uncover the actual variant of such an algebraic data type, the user might 
use \code{dynamic_cast} to query one of the $k$ expected run-time types or she 
might employ a visitor design pattern devised for this algebraic data type.

\subsubsection{Tagged Class}

This encoding is similar to the \emph{Polymorphic Base Class} in that we use 
derived classes to encode the variants. The main difference is that the user 
foresees a dedicated member in the base class, whose value will uniquely 
determine the exact derived class a given object is an instance of. Constructors 
of each variant $C_i$ are reponsible for properly initializing the dedicated 
member with a unique value $c_i$ associated with that variant. Clang\cite{Clang} 
uses this approach.

\begin{lstlisting}[keepspaces,columns=flexible]
class DT { enum kinds {@$c_1, ..., c_k$@} m_kind; };
class @$C_1$@ : public DT {@$T_{11} L_{11}; ... T_{1m} L_{1m};$@} 
...
class @$C_k$@ : public DT {@$T_{k1} L_{k1}; ... T_{kn} L_{kn};$@} 
\end{lstlisting}

In such scenario the user might use a simple switch statement to uncover the 
type of the variant combined with a \code{static_cast} to properly cast the 
pointer or reference to an object. People might prefer this encoding to the one 
above for performance reasons. A visitor design pattern can be implemented with 
this encoding as well with the exception that instead of a virtual \code{accept} 
member-function a base class will have a non-virtual \code{select} 
member-function implemented with a switch to dispatch to appropriate 
\code{visit} call back. \code{select} will often be parameterized with the type 
of the visitor to eliminate dynamic dispatch altogether.

\subsubsection{Discriminated Union}

This encoding is popular in projects that are either implemented in C or 
originated from C before coming to C++. It involves a type that contains a union 
of its possible variants, discriminated with a dedicated value stored as a part 
of the structure. The approach is used in EDG front-end\cite{EDG}.

\begin{lstlisting}[keepspaces,columns=flexible]
struct DT
{
    enum kinds {@$c_1, ..., c_k$@} m_kind;
    union
    {
        struct @$C_1$@ {@$T_{11} L_{11}; ... T_{1m} L_{1m};$@} @$C_1$@;
        ...
        struct @$C_k$@ {@$T_{k1} L_{k1}; ... T_{kn} L_{kn};$@} @$C_k$@; 
    };
};
\end{lstlisting}

As before, the user can use a switch statement to identify the variant $c_i$ and 
then access its members via $C_i$ union member.

\subsection{Syntax}

We present rather informally abstract syntax enabled by our SELL. We do not try 
to capture all of the C++ syntax here because we do not in fact change or extend 
the language. All the facilities available through our library are nothing else 
but a syntactic sugar enabled through the clever use of template and macro 
mechanisms already present in the language. We do make use of several 
non-terminals from the C++ grammar to put the use of our constructs into context. 
For the complete C++ grammar we refer the curious reader to Appendix A of the 
current C++ standard\cite{C++0x}.

% TODO:
%()	Function call
%[]	Array subscripting
%*	Indirection (dereference)
%&	Address-of
%sizeof	Size-of

\begin{center}
\begin{tabular}{rp{0em}cl}
\Rule{type-id}             & $\tau$  &        & C++\cite[\textsection A.7]{C++0x} \\
\Rule{statement}           & $s$     &        & C++\cite[\textsection A.5]{C++0x} \\
\Rule{expression}          & $e^\tau$&        & C++\cite[\textsection A.4]{C++0x} \\
\Rule{constant-expression} & $c^\tau$&        & C++\cite[\textsection A.4]{C++0x} \\
\Rule{identifier}          & $v^\tau$&        & C++\cite[\textsection A.2]{C++0x} \\
                           &         &        & \\
\Rule{binary operator}     & $\oplus$& $\in$  & $\lbrace*,/,\%,+,-,\ll,\gg,\&,\wedge,|,$ \\
                           &         &        & $<,\leq,>,\geq,=,\neq,\&\&,||\rbrace$ \\
\Rule{unary operator}      &$\ominus$& $\in$  & $\lbrace*,\&,+,-,!,\sim\rbrace$ \\
\Rule{layout}              & $l$     & \is{}  & $c^{int}$ \\
\Rule{xt variable}         & $w^{variable\langle\tau\rangle}$ & & \ \\
\Rule{xt expression}       & $x$     & \is{}  & $w$ \Alt{} $x \oplus c$ \Alt{} $c \oplus x$ \Alt{} $\ominus x$ \Alt{} $(x)$ \Alt{} $x \oplus x$ \\
\Rule{wildcard pattern}    & $\_^{wildcard}$& & \\
\Rule{n+k pattern}         & $n$     & \is{}  & $w$ \Alt{} $n \oplus c$ \Alt{} $c \oplus n$ \Alt{} $\ominus n$ \Alt{} $(n)$ \Alt{} $\_$ \\
\Rule{guard pattern}       & $g$     & \is{}  & $n \models x$ \Alt{} $t \models x$ \\
\Rule{tree pattern}        & $t$     & \is{}  & \code{match<}$\tau\left[,l\right]$\code{>(}$\left[c|v|\pi\right]^*$\code{)} \\
\Rule{pattern}             & $\pi$   & \is{}  & $\_$\Alt{} $n$ \Alt{} $g$ \Alt{} $t$ \\
\Rule{match expression}    & $m$     & \is{}  & $\pi(e)$ \\
                           &         &        & \\
\Rule{target expression}   & $T$     & \is{}  & $\tau$ \Alt{} $l$ \\
\Rule{case clause}         & $C$     & \is{}  & \code{Case(}$T\left[,v\right]^*$\code{)} \\
                           &         & \Alt{} & \code{Que(} $T\left[,c|v|\pi\right]^*$\code{)} \\
\Rule{match statement}     & $M$     & \is{}  & \code{Match(}$e$\code{)} $\left[C s^*\right]^*$ \code{EndMatch} \\
\end{tabular}
\end{center}

\noindent
{\bf type-id} Represents a type expression that designates any valid C++ type. 
We will be using this meta-variable in the superscript of other meta-variables 
in order to indicate a C++ type of the entity they represent.

\noindent
{\bf statement} Refers to any valid statement allowed by the C++ grammar. Our 
match statement $M$ would have been extending this grammar rule with an extra 
case should have it been defined in the grammar directly.

\noindent
{\bf expression} Any valid C++ expression. An expression $e^\tau$ would refer to 
a C++ expression, whose result type is $\tau$.

\noindent
{\bf constant-expression} An expression computable at compile time. Similarly to 
expression, when we mention its type in the superscript, we refer to constant 
expressions of that type only.

\noindent
{\bf identifier} The way we use this construct in our grammar will only refer to 
variable names.

\noindent
{\bf binary operator} and {\bf unary operator} Subset of C++ operators we make 
use of and provide support for in our pattern matching library.

\noindent
{\bf layout} Layouts are enumerators user can use to define alternative bindings 
for the same class. When layout is not mentioned, the default layout is used, 
which is the only required layout a user has to define if she wishes to make use 
of bindings.

\noindent
{\bf xt variable} Expression template variables are variables whose type is 
\code{variable<T>} for any given type \code{T}. They are terminal symbols that 
let one build an expression template by overloading corresponding operators.

\noindent
{\bf xt expression} Expression template built by applying a given operator to 
argument expression templates. Expression templates represent a C++ technique 
for lazy evaluations.

\noindent
{\bf wildcard pattern} A wildcard pattern in our library is represented by a 
predeclared global variable of our type \code{wildcard} that bears no state.

\noindent
{\bf n+k pattern} Our n+k patterns are essentially limited to arbitrary 
expressions with at most one variable in them.

\noindent
{\bf guard pattern} Our guard patterns consist of two expressions essentially: 
an expression being matched (left operand) and a condition (right operand), that 
is allowed to make use of the variable bound in the left hand side. We 
effectively allow guard patterns on arguments of a tree patterns as well as 
right after it.

\noindent
{\bf tree pattern} Tree patterns take a type being matched and an optional 
bindings layout for it as template arguments. Any nested subexpressions are 
taken as run-time arguments. Besides patterns already mentioned above, we allow 
as subpatterns the use of constants and regularl C++ variables as \emph{value 
patterns} and \emph{variable patterns} respectively. Tree patterns can be 
arbitrarily nested.

\noindent
{\bf pattern} This metavariable just summarizes different kinds of patterns we 
support.

\noindent
{\bf match expression} Once a pattern is created, it can be applied to an 
expression in order to check whether that expression matches the pattern. The 
result of application is always \code{bool} except for tree pattern, where it is 
a value convertible to \code{bool}. The actual value in this case is going to be 
a pointer to target type \code{T} in case of a successful match and a 
\code{nullptr} otherwise.

\noindent
{\bf target expression} Target expression can either be a type, representing a 
type being matched or a constant value, representing a layout for discriminated 
union encoding of algebraic data types.

\noindent
{\bf case clause} We support two kinds of case clauses, both of which take a 
target expression as their first argument. \code{Case} clause is only accepting 
names of variables as additional arguments and it introduces variables with such 
names into the clause's scope, bound to corresponding members. \code{Que} clause 
requires any variables mentioned in its argument list be explicitly declared by 
the user. In turn, similarly to tree pattern, it allows arbitrary pattern 
expressions to be used.

\noindent                           
{\bf match statement} Match statement is an analog of a switch statement that 
allows case clauses to be used as its case statements. We require it to be 
terminated with a dedicate EndMatch macro, to properly close the syntactic 
structure introduced with \code{Match} and followed by \code{Case} and 
\code{Que} macros.


The important difference between algebraic data types and classes in C++ is that
algebraic data types are closed and once constructors have been defined, no new
constructors can be added. C++ classes on the other hand are always open: user 
may extend any class with a new constructor. Work on extensible data types 
exist\cite{ExtensibleDatatypes,LohHinze2006}

%Emir gives the following terminology in 2.1.1:
%The \emph{match expression} Match(...) contains \emph{case clauses} Case(T,...), 
%each with a pattern to match instances tagged with corresponding constructor.
%
% Algebraic data types like SrchT are defined inductively as the least set 
% closed under their constructor functions.

Interestingly enough C++ has a pure functional sublanguage in it that has a 
striking similarity to ML and Haskell. The sublanguage in question is template 
facilities of C++ that has been shown to be Turing 
complete\cite{veldhuizen:templates_turing_complete}. In fact, there were 
attempts to use Haskell as a pseudo code language for template metaprogramming in 
C++\cite{Milewski11}. A key observation in this analogy is that partial and 
explicit template specialization of C++ class templates is similar to defining 
equations for Haskell functions. Consider as an example the above factorial 
function expressed in terms of compile-time pattern-matching facilities of C++:

\begin{lstlisting}
template <int N> 
struct factorial { enum { result = N*factorial<N-1>::result }; };
template <>
struct factorial<0> { enum { result = 1 }; };
\end{lstlisting}

Coincidentally, we use this compile-time pattern-matching facility as a 
meta-language to implement its run-time counterpart.

A place where C++ does have a primitive run-time pattern matching is the catch 
clause of exception handling. The order of clauses matters, which is similar to 
the order of patterns. 

The result of invoking \code{match<T>(a,b,c)} is a \emph{pattern} that can be applied 
to a given instance of any type U, that is related by inheritance to T (i.e. is 
a base of, derived from or a sibling of). Applying given pattern to an instance 
returns a pointer to type T if matching succeeds along with binding all the 
variables and subexpressions the pattern was created with.

---------------

Similarly to Haskell, we employ \emph{first-fit} pattern matching under which the 
equations are matched linearly from top to bottom. This is why putting 
Otherwise() not at the end of the switch statement will effectively close all 
subsequent equations.

We first present informally the pattern-matching facilities our library exposes.

Let's assume we have a simple class hierarchy of shapes:

\begin{lstlisting}
typedef std::pair<double,double> loc;

struct Shape
{
    virtual @$\sim$@Shape() {} // to enable RTTI
};

struct Circle : Shape
{
    Circle(const loc& c, const double& r) : center(c), radius(r) {}
    const loc& get_center() const { return center; }
    loc    center;
    double radius;
};


struct Square : Shape
{
    Square(const loc& c, const double& s) : upper_left(c), side(s) {}
    loc    upper_left;
    double side;
};

struct Triangle : Shape
{
    Triangle(const loc& a, const loc& b, const loc& c) : first(a), second(b), third(c) {}
    loc first, second, third;
};
\end{lstlisting}

Before the library can be used, the user has to provide decomposition into a 
tuple of all the data structures against which pattern matching will be 
performed. This is done through specializing traits-like class match\_members:

\begin{lstlisting}
template <> struct bindings<Shape>    {};
template <> struct bindings<Circle>   { CM(0,Circle::get_center); CM(1,Circle::radius); };
template <> struct bindings<Square>   { CM(0,Square::upper_left); CM(1,Square::side);   };
template <> struct bindings<Triangle> { CM(0,Triangle::first);    
                                        CM(1,Triangle::second); 
                                        CM(2,Triangle::third); };
\end{lstlisting}

The first argument of CM represent a position, while the second argument 
represents the member of the class that will be matched against in that position. 
Members don't have to be data members only, but can also be nullary member 
functions providing access to given subcomponent (as Circle::get\_center above).
With these definition we can write our first function using pattern matching.

\begin{lstlisting}
double area(const Shape& shape)
{
    wildcard _; // Meta variable
    loc      x,y,z;
    double   r,s;

    if (match<Circle>(_,r)(shape))
        return 3.14 * r * r;

    if (match<Square>(_,s)(shape))
        return s * s;

    if (match<Triangle>(x,y,z)(shape))
        return heron(x,y,z);

    assert(!"Inexhaustive search");
}
\end{lstlisting}

Unfortunately we have to predeclare variables as we are in a library setting and 
cannot change the compiler, while C++ requires all the variables to be forward 
declared. The binding of variables though works exactly as in other languages. 
One may have noticed that the wildcard has to be predeclared as well. This is 
not required as the library may provide a global variable with such name, we 
just wanted to mention here that the name of the meta variable may be arbitrary, 
it is its type that triggers the proper matching behavior.

TODO: Discuss exceptions while accessing members

We note that our approach is not limited to handling only these specific 
representations of algebraic data types in C++, but can be applied to any class 
hierarchy, viewing patternm matching as a generalization of 
dynamic\_cast.

\subsection{Guards}

The following pattern will match circles with any center but only those whose 
radius is greater than 3 and smaller than 5. The value of the radius of such 
matching Circle will be bound to r.

\begin{lstlisting}
    variable<double> r;
    if (match<Circle>(_, r |= r > 3 && r < 5)(shape)) ...
\end{lstlisting}

The expression in the guard can be arbitrarily complicated and unlike the 
pattern itself, the variables might be mentioned several times as by the time 
the guard is going to be evaluated, the variable will be bound. The |= operator 
that defines the guard was chosen arbitrarily from those that have pretty low 
precedence in C++ in order to allow most of the other operators be used in the 
condition part (right hand side) without parenthesis. The variable in the left 
hand side of the guard operator is the one that will be bound by the pattern. 
The condition part of the guard may include only this variable and the variables 
bound in preceding positions. For example:

\begin{lstlisting}
    variable<double> x,y;
    if (match<Circle>(match<loc>(x, y |= y == x))(shape)) ...
\end{lstlisting}

This code will effectively match circles with the center on the line $y=x$. Note 
that the more straitforward notation:

\begin{lstlisting}
    if (match<Circle>(match<loc>(x, x))(shape)) ...
\end{lstlisting}

is invalid in most of the languages as it uses the same variable twice in the 
binding position. This can be given a semantics that the first use is the 
binding use, while the second one is the use as a bound value, but one would 
have to argue it won't lead to confusion and mistakes in more complicated 
expressions.

The important bit about our implementation of guards is that variables used in 
guards have to be explicitly wrapped into \code{variable<>} template in order to let 
the library build the corresponding expression template. The convenient notion 
that allowed us to use normal variables inside matches seen before will not work 
for guards as the expression would simply be evaluated using the C++ semantics 
and the resulting value will be passed to the match function as the value (and 
not the expression) we would like to match against.

We chose to provide syntax for guards directly in binding expressions in order 
to make sure we can determine certain pattern doesn't match as soon as possible 
and thus not have to compute matching for subsequent arguments. An alternative 
syntax for guards used in other languages is after the entire match expression, 
using traditional predicates.

\subsection{The (in)famous n+k patterns}

Similarly to Haskell (until 2010), we provide support for the n+k patterns. With 
them one can define factorial in the following way:

\begin{lstlisting}
int factorial(int n)
{
    variable<int> m;

    if (match<int>(0)(n))   return 1;
    if (match<int>(m+1)(n)) return (m+1)*factorial(m);
    return 0; // Should never happen
}
\end{lstlisting}

Unlike Haskell however, our patterns are not limited n+k form only and are 
generalized to any invertible operations. The definition of fast algorithm that 
computes x to the power of n can be written as following in the library:

\begin{lstlisting}
double power(double x, int n)
{
    variable<int> m;

    if (match<int>(0)(n))     return 1.0;
    if (match<int>(1)(n))     return x;
    if (match<int>(m*2)(n))   return sqr(power(x,m));
    if (match<int>(m*2+1)(n)) return x*power(x,2*m);
    return 0.0; // Should never happen
}
\end{lstlisting}

Another typical example that appears in the context of discussions about 
generalizing n+k patterns in Haskell is fast fibbonaci algorithm given below:

\begin{lstlisting}
int fib(int n)
{
    variable<int> m;

    if (match<int>(1)(n))     return 1;
    if (match<int>(2)(n))     return 1;
    if (match<int>(m*2)(n))   return sqr(fib(m+1)) - sqr(fib(m-1));
    if (match<int>(m*2+1)(n)) return sqr(fib(m+1)) + sqr(fib(m));
    return 0.0; // Should never happen
}
\end{lstlisting}

Interestingly enought instead of generalization, the n+k patterns were made 
obsolete in Haskell as of 2010\cite{HaskelDocMakingThis}. This was result of 
many discussions trying to provide semantics to them in the context of user 
defined types. Here, we are not claiming to solve the relevant discussions, but 
instead are making sure that our solution is transparent in such a way that we 
can use the C++0x forthcoming concept mechanism to deal with relevant issues. In 
particular when having a generalized n+k pattern on \code{variable<T>} we try to make 
sure that 

Scala uses a very stylistic approach to disambiguating variables that need to be 
bound from named constants. In particular they require that named constants 
start with capital letter while variables start with lowercase 
letter\cite[\textsection 2.8]{EmirPhd}. While such a requirement is inline with similar 
requirements for naming a constructor in various functional languages, this will 
raise eyebrowse in C++. We thus form our distinction between variables to be 
bound and values to be matched based on type of the expression: expressions that 
will bind to a reference type are assumed to be used as variables that have to 
be bound; expressions that will only bind to const reference are assumed to be 
values that have to be matched instead, even if they are named.

\subsection{Views}

Our extractors are similar to extractors in Scala, which in turn resemble Views 
proposed for Haskell.

TODO: Add discussion of pattern matching in generic code.

%[From Emir PhD Thesis 1.3]
%Adapting algebraic data types to the object-oriented context has been initiated by Wadler
%and Odersky's PIZZA extension to the JAVA programming language [70]. This language offers
%generics, closures and also algebraic data types and pattern matching. This extension
%was the first version of case classes: within the scope of class B, algebraic data type constructors
%Ki could be defined writing a constructor signature caseKi(T1f1, . . . , Tnfn). The
%compiler lifted these, turning them to full classes that extended the containing class B. Thus,
%classes Ki existed that inherited methods from B. The compiler also recognized calls to the
%constructor that were not preceded by the new keyword.

%In the SCALA programming language [69], case classes turned into classes that did not need
%to live in the scope of an enclosing class. The case has become merely a modifier that can
%turn any class into a case class - with the sole restriction that case classes could not inherit
%from case classes.

%This restriction was motivated by the implementation: at the time all these systems were
%designed, the JVM did not have the same aggressive optimizations that they have now. So
%the designers did not want to commit to slow instanceof checks and thus restricted case
%classes such that they could not have a direct or indirect parent that is also a case class. This
%way, a pattern match could always be optimized using integer tags (Chapter 4) takes up the
%idea or replacing type tests with integer tags.

Our notion of \emph{layout} is similar to Wadler's notion of Case class\cite{}

Discuss layouts as a way of handling pattern matching for cases of multiple 
inheritance.

%[From Emir PhD Thesis 1.4]
%For instancem, in his compiler textbook Appel [6,
%pp.94] contrasts compilers with graphic user interface toolkits, observing two orthogonal directions
%of modularity: both applications have a matrix of data and operations, but whereas
%for compilers, the data (syntax trees) is seldom changed but operations (compiler passes)
%are evolving, for a user interface toolkit, the operations (Redisplay, Move, . . . ) are fixed and
%the data (widgets) are unknown. Compilers need to separate operations from the classes
%that represent syntax trees, since it is inconvenient to change every syntax tree class when
%a single operation is added. In contrast, graphical user interface toolkits blend well with
%object-oriented style, since every widget can be implemented as a new class that will implement
%the interface that contains all the operations it has to support.

\section{Evaluation} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:eval}

In this section we evaluate the performance of our solution in comparison to the 
de facto standard -- visitor design pattern.

To evaluate the performance of our solution we've taken a working piece of code 
that operates visitor pattern on a fairly large class hierarchy and 
reimplemented it using pattern matching.

Preliminary evaluation results obtained on synthetic examples are as following:

As long as dynamic cast doesn't have to be invoked (e.g. we do n+k patterns or 
guards, the overhead is reasonable and is between 15 and 30 persent.

As soon as dynamic cast has to be used inside the match, the overhead easily 
becomes 10 times slower than visitor's single virtual function call. Because of 
sequential order of tests, the overhead for classes tested later becomes 
significant, effectively requiring the user to prioritize the order of tests.

\section{Discussion} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:dsc}

We considered using smaller types for storing line numbers based on our 
observation that we haven't found many C++ source files that had more than 65535 
lines. This was saving us space for hash tables but resulted in worse 
performance due to access of smaller words from memory.

We also looked into storing differences between switch'es head line number and 
case's line number, following the observation that very occasionaly we saw more 
than 256 cases in a pattern-matching switch. This also degraded performance so 
we did not use it.

We would like to note that in presence of deeper hierarchy, visitors often 
implement members by forwarding call to their base, which may incure additional 
overhead.

\section{Related Work} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:rw}

A good survey of work on general pattern matching can be found in in a term 
project paper by Miller\cite{Miller10}.

Great overview of pattern matching in Scala compared to several other languages 
is presented in\cite{ScalaPM}.

Prop was an attempt to add pattern matching together with algebraic data types 
and other functional features into C++\cite{Prop96}.

JMatch was a similar incentive to add pattern matching to Java.

Sankel provides a good educational overview of how algebraic data types can be 
implemented in C++\cite{SankelFP10,Sankel10}. 

Emir's PhD thesis provides an extensive analysis of pattern matching in the 
context of object-oriented languages\cite{EmirThesis}.

Cook et al used expression templates to implement a query language to Pivot's 
IPR\cite{iql04}. The principal difference of their work from this work is that 
authors were essentially creating a pattern matcher for a given class hierarchy 
and thus could take the semantics of the entities represented by classes in the 
hierarchy into account. Our approach is parametrized over class hierarchy and 
thus provides a rather lower level pattern-matching functionality that lets one 
simplify work with that hierarchy.  One can think of it as a generalized 
dynamic\_cast.

In his dissertation, Pirkelbauer provides a different pattern matcher against 
Pivot's IPR\cite{PirkelbauerThesis}.

Veldhuizen discovered a very powerful technique called Expression 
templates\cite{Veldhuizen95expressiontemplates}.

Other languages that use pattern matching include: ...

Dos Reis et al compares functional and imperative approaches to generic 
programming and discusses the role of pattern matching in expressing generic 
algorithms in the functional approach\cite{dos_reis:05:what_is_gp}. They also 
demonstrate with an elegant example the amount of boilerplate code necessary to 
write in C++ in order to describe a sum-functor.k

Boost::proto is a library for creating DSL using expression templates.

TOM is a pattern matching compiler that adds pattern-matching facilities to 
imperative languages such as C, Java, or Eiffel.\cite{Moreau:2003}

%[From Extensible Algebraic Datatypes with Defaults]
%The traditional object-oriented and functional approaches
%both make extensions in one dimension easy, but extensions
%in the other dimension very hard. In the object-oriented approach,
%data is modelled by a set of classes, sharing a common
%interface. For the lambda term example, there would
%be an interface or abstract class Term specifying the eval
%method with subclasses Lambda, Apply and Variable. Each
%subclass defines its own implementation of eval. W hereas
%extending the datatype with new variants is simply done by
%creating new classes, adding new operations involves modifications
%of the abstract base class.
%On the other hand, in the functional approach, the variants
%of a datatype are typically implemented as an algebraic
%type. Here, defining new operations is easy. One just writes
%a new function which matches against the data variants.
%But since ordinary algebraic datatypes cannot be extended
%without modifications to the source code, it would not be
%possible to add new variants.
%Each of the two approaches can encode the other. In
%one direction, object-oriented languages can model the functional
%approach using the Visitor design pattern [14]. In
%the other direction, objects can be represented in functional
%languages as closures taking an algebraic datatype of messages
%as parameter. However, each of these encodings exchanges
%both the strengths and weaknesses of one approach
%with the strengths and the weaknesses of the other; neither
%encoding gains simultaneous extensibility of both data and
%operations.

\section{Future Work} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:fw}

Describe formally concepts used in our expression templates.

Find better recursive patterns for sequences.

Make patterns more reusable by eliminating variables from those, saved into 
auto.

Multi-threaded environment support.

\section{Conclusions} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:cc}

We described a technique for implementing efficiently various language 
facilities that depend on a run-time type of an argument: type switching, type 
testing, pattern matching etc. The technique is open to class extensions and 
interacts well with multiple inheritance in C++ (including repetitive and 
virtual inheritance) as well as templates. The technique can also be reused in 
other object-oriented language that use v-tables to implement dynamic dispatch.

Using the above technique we implemented a pattern-matching library for C++ that 
closely resembles pattern-matching facilities available in other languages on a 
first-class bases. Our implementation is very similar or outperforms its closest 
contender -- visitor design pattern as well as overcomes the restrictions, 
inconveniences and difficulties in teaching and using, typically associated with 
it.

We used the library to rewrite an existing code that was relying heavily on 
visitors and discovered that resulting code became much shorter, simpler, easier 
to maintain and comprehend.

%In this work we describe design and implementation of a library that brings 
%pattern matching facilities similar to those of functional programming languages 
%into C++. Our solution does not requre any changes to the compiler and in its 
%main part can be implemented in the standard C++98. Several extensions might 
%require use of C++0x features, readily available in todays mainstream compilers.
%The solution is non-intrusive and can be applied to any given class taxonomy 
%retroactively. Its main utility lays in avoiding the control inversion problem 
%typical to Visitor Design Pattern, which results in more clear, direct and much 
%more consciece code. Our evaluation demonstrates that the solution scales to 
%real-sized projects, while the performance results show that it comes close to 
%its hand-crafted visitor alternative. The main novelty of the paper is in 
%generalizing Haskell's n+k patterns to any invertible operations and 
%demonstrating how to do it generically in a library setting. Backward semantics 
%of expression templates used to implement this feature is also to the best of 
%our knowledge first application of backward semantics to expression templates.

\section{ToDo} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
%\item + Profile Guided Optimizations on Visual C++ code
\item Separate sequential, random, repetitive into separate test programs
      and make one that combines them all. This is to test PGO effectiveness.
%\item Computation of irrelevant that minimizes amount of collisions
\item Proof that recomputations of irrelevant won't be done forever and will 
      stabilize
\item Instrument existing apps to see VTBL behavior
\item Finish experimenting with congruence hierarchy
%\item + Take difference of line numbers to have case labels small.
\item Justification/proof from Itanium ABI for our approach
%\item + Rethink switch for unions
%\item + Unify syntax of all the switches
\item Multiple dispatch switch
\item Different values of the same dynamic type
\item FIX: Value that would match type but wouldn't match condition may slow 
      down execution significantly. We need exit from switch instead of fall 
      through
\item Lock-free version to be used in multi-threaded environments.
\item Emir's PhD thesis has measurements, compare to those.
\end{itemize}

Discuss: Separating matching arguments from selector prevents us from optimizing
for some obvious but typical cases when type 

Discuss:
Visual C++ seems to generate better visitors code: 185 vs 222 units for GCC.
GCC seems to generate better matching code: 208 vs 209 units for Visual C++.
64 bit code in Visual C++ actually becomes faster: 143(x64) vs 185(w32) for 
visitors and 196(x64) vs 209(w32) for pattern matching. We can't at the moment 
generate 64bit GCC code.
Unlike GCC, we could not find a way to do branch hinting for Visual C++.

MS Visual C++ 10

 32 | Visitors | Matching      64 | Visitors | Matching 
--------------------------    --------------------------
SEQ |   185    |   209        SEQ |   145    |   190    
RND |   186    |   208        RND |   143    |   196    

GCC 4.5.2

 32 | Visitors | Matching      64 | Visitors | Matching 
--------------------------    --------------------------
SEQ |   215    |   189        SEQ |          |          
RND |   222    |   208        RND |          |          

\section{Acknowledgements} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Gregory Berkolaiko for entropy idea. Jaakko Jarvi for Haskell help. Andrew Sutton 
for suggestions. Jasson Cassey for branch hinting. Mani Zandifar for PAPI help.

\section{Scratch}

%[From LohHinze2006]
%The problem of supporting the modular extensibility of both data
%and functions in one programming language at the same time is
%known as the expression problem. Functional languages traditionally
%make it easy to add new functions, but extending data
%(adding new data constructors) requires modifying existing code.
%
%[From Modular Typechecking of Hierarchically Extensible Datatypes and Functions]
%Many researchers have noted a difference in the extensibility bene?ts offered
%by the functional and object-oriented (OO) styles [Reynolds 1978; Cook 1991;
%Odersky and Wadler 1997; Krishnamurthi et al. 1998; Findler and Flatt 1998;
%Garrigue 2000; Zenger and Odersky 2001]. Functional languages like ML allow new operations to be easily added to existing datatypes (by adding new
%fun declarations), without requiring access to existing code. However, new data
%variants cannot be added without a potentially whole-program modi?cation
%(since existing functions must be modi?ed in place to handle the new variants). On the other hand, traditional OO approaches allow new data variants
%to be easily added to existing class hierarchies (by declaring subclasses with
%overriding methods), without modifying existing code. However, adding new operations to existing classes requires access to the source code for those classes
%(since methods cannot be added to existing classes without modifying them in
%place).
%...
%However, such simplicity comes at a cost to programmers, who are forced to choose
%up front whether to represent an abstraction with datatypes or with classes. As
%described above, this decision impacts the kind of extensibility allowable for the
%abstraction. It may be dif?cult to determine a priori which kind of extensibility
%will be required, and it is dif?cult to change the decision after the fact. Further, it is not possible for the abstraction to enjoy both kinds of extensibility at
%once.
%...
%An alternative approach is to generalize existing ML constructs to support
%the OO style. OML [Reppy and Riecke 1996], for example, introduces an objtype
%construct for modeling class hierarchies. This construct can be seen as a generalization of ML datatypes to be hierarchical and extensible. Therefore, programmers need not decide between datatypes and classes up front; both are
%embodied in the objtype construct. However, OML still maintains a distinction
%between methods and functions, which have different bene?ts. New methods
%may not be added to existing objtypes without modifying existing code, while
%ordinary ML functions may be. Methods dynamically dispatch on their associated objtype, while functions support ML-style pattern matching.
%...
%ML? [Bourdoncle and Merz 1997] integrates the OO style further with existing ML constructs. Like OML, ML? generalizes ML datatypes to be hierarchical and extensible. Further, methods are simulated via function cases that use
%OO-style dynamic dispatch semantics. In this approach, programmers need
%not choose between two forms of extensibility; a single language mechanism
%supports the easy addition of both new operations and new variants to existing
%datatypes.
%...
%Classes additionally generalize ML-style datatypes to be extensible, whereby
%new variants can be written in modules other than the one declaring the
%datatype, and hierarchical, whereby variants can have their own "subvariants."
%In addition to
%being extensible and hierarchical, classes are also full-?edged types while ML
%variants are not. For example, classes can appear in a function's argument or
%return type.
%Single inheritance of classes is compatible with the ML style, in which each 
%data variant conceptually singly inherits from the corresponding datatype, as 
%shown in the above encoding of datatypes into classes. However, EML can support 
%multiple interface inheritance, like Java.
%...
%Intuitively, case c1
%is more speci?c than case c2 if the set of values matching c1's pattern is a
%subset of the set of values matching c2's pattern.
%...
%Unlike (both concrete and abstract) classes, interfaces may not appear in
%patterns. This restriction is the EML analogue of Java's restriction that an interface have no concrete methods. Both restrictions remove the potential for
%dynamic-dispatch ambiguities caused by multiple inheritance. Because of EML's
%restriction, interfaces do not impact ITC any differently from abstract classes.
%Therefore we ignore interfaces in the remainder of the paper.

\bibliographystyle{abbrvnat}
\bibliography{mlpatmat}
\end{document}
