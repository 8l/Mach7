\section{Proposed Solution}
\label{sec:copc}

C++ does not have direct support of algebraic data types, but they can be 
encoded with classes in a number of ways. One common such encoding is to 
introduce an abstract base class representing an algebraic data type with 
several derived classes representing variants. The variants can then be 
discriminated with either run-time type information (referred to as 
\emph{polymorphic encoding}) or a dedicated member of a base class 
(referred to  as \emph{tagged encoding}).

Our handling of type switches for polymorphic and tagged encodings differs 
with each having its pros and cons described in details in \textsection\ref{sec:cmp}.
In this section we will concentrate on the open type switch for 
polymorphic encoding. The type switch for tagged encoding (\textsection\ref{sec:cotc}) 
is simpler and more efficient, however, making it open will eradicate its 
performance advantages. The difference in performance is the price we pay for 
keeping the solution open.  The core of the proposal relies on two keys
aspects of C++ implementations:
\begin{enumerate}
\item a constant-time access to the vtable pointer embedded in an object of
  polymorphic class type;
\item injectivity of the relation between an object's inheritance path
  and the vtable pointer extracted from that object.
\end{enumerate}

\subsection{Virtual Table Pointers}
\label{sec:vtp}

In this section we show that under certain conditions the compiler cannot share 
the same virtual tables between different classes or their subobjects. This 
allows us to use virtual table pointers to \emph{uniquely} identify the 
subobjects within the most derived class.

The C++ standard~\cite{C++0x} does not prescribe any specific 
implementation technique for virtual function dispatch.
However, in practice, all C++ compilers use a strategy based on so-called
virtual function tables (or vtables for short) for efficient disptach. 
The vtable is part of the reification of a polymorphic class type.  
 C++ compilers embed a pointer to a vtable in every object of
polymorphic type.  We need a constant-time access to that vtable pointer
from an object.  CFront, the first C++ compiler puts the vtable pointer
at the end of an object.  The so-called ``common vendor C++ ABI''
\cite{C++ABI} requires the vtable pointer to be at offset 0 of an object.
We do not have access to the unpublished Microsoft ABI, but we have
experimental evidence that Microsoft's C++ compiler also puts the vtable
pointer at the start of an object.

C++ supports multiple-inheritance of two kinds: repeated and virtual (shared). 
\emph{Repeated inheritance} creates multiple independent subobjects of the same 
type within the most derived type. \emph{Virtual inheritance} creates only one 
shared subobject, regardless of the inheritance paths. Consequently,
it is not sufficient to talk only about the 
static and dynamic types of an object -- one has to talk about a 
\emph{subobject} of a certain static type accessible through a given inheritance 
path within a dynamic type. The notion of subobject has been formalized 
before~\cite{RF95,WNST06,RDL11}. We follow here the presentation of Ramamanandro 
et al~\cite{RDL11}.

A base class subobject of a given complete object is represented by a pair 
$\sigma = \langle h,l\rangle$ with $h \in \{Repeated,Shared\}$ representing the 
kind of inheritance (single inheritance is $Repeated$ with one base class) and $l$ 
representing the path in a non-virtual inheritance graph.
A predicate $C\leftY\sigma\rightY A$ states that $\sigma$ 
designates a subobject of static type $A$ within the most derived object of 
type $C$.

A class that declares or inherits a virtual function is called a 
\emph{polymorphic class}~\cite[\textsection 10.3]{C++0x}.  We say that
a class is \emph{dynamic} \cite{C++ABI} if it requires a virtual table pointer 
(because it or its bases have one or more virtual member functions or
virtual base classes). A \emph{virtual table pointer} (vtbl-pointer)
is a data-member of an object pointing to the object's dynamic type vtable.
In addition to dispatching virtual function calls, it is used to access
virtual base class subobjects, and to 
access \emph{RunTime Type Identification} (RTTI) data.  An object of a class
type with multiple inheritance may contain several vtable pointers
(included in its subobjects.)  We assume that for every expression of
static type \code{T} (a dynamic class type), a C++ compiler provides
access to the vtable pointer of the (sub)object designated by that 
expression (or at least document the position of that
pointer within an object.)  For the common vendor C++ ABI, we can state:
\begin{lemma}
  In an object layout that adheres to the ``common vendor C++ ABI'', 
  an object of a polymorphic class always has a virtual table pointer
  at offset 0.
\label{lem:vtbl}
\end{lemma}

\noindent

With no further assumption, we cannot use a vtable to uniquely identify
its dynamic type or those of its subobjects.  The reason is it is a popular 
compression technique to share the virtual table of a derived 
class with those of some of its subobjects. 
Use of such optimization will violate the 
uniqueness of vtbl-pointers; however, we show below that in the presense of 
RTTI, an implementation compliant to the C++ common vendor ABI is guaranteed
to have different values  of vtbl-pointers in different subobjects.

%C++ standard requires an argument of \code{dynamic_cast} to be a pointer to or 
%an lvalue of a polymorphic type when performing \emph{downcast} -- a cast from 
%base to derived~\cite[\textsection 5.2.7-6]{C++0x}. We can thus always safely 
%extract virtual table pointer from offset 0 of any valid argument to 
%\code{dynamic_cast}.

%Similarly, each class that has virtual member functions or virtual bases has an 
%associated set of virtual tables. There may be multiple virtual tables for a 
%particular class, if it is used as a base class for other classes. However, the 
%virtual table pointers within all the objects (instances) of a particular 
%most-derived class point to the same set of virtual tables.

The exact content of the virtual table is not important for our discussion, but 
we point out a few fields in it. The following definitions are 
copied verbatim from the C++ ABI~\cite[\textsection 2.5.2]{C++ABI}:

\begin{itemize}
\setlength{\itemsep}{0pt}
\setlength{\parskip}{0pt}
\item The \emph{typeinfo pointer} points to the typeinfo object used for RTTI. 
      It is always present.  
\item The \emph{offset to top} holds the displacement to the top of the object 
      from the location within the object of the vtbl-pointer that 
      addresses this virtual table. It is always present.
\item \emph{Virtual Base (vbase) offsets} are used to access the virtual bases 
      of an object. Such an entry is required for each virtual base class.
\end{itemize}

\noindent
Given a virtual table pointer \code{vtbl}, we will refer to these fields as 
\code{rtti(vtbl)}, \code{off2top(vtbl)} and \code{vbase(vtbl)} respectively. 
We will also assume presence of a function $offset(\sigma)$ that defines the 
offset of the base class identified by the end of the path $\sigma$ within a 
class identified by its first element.

\begin{theorem}
In an object layout that adheres to the C++ ABI with present runtime type 
information, the equality of vtbl-pointers of two objects of the same 
static type implies that they both belong to subobjects with the same 
inheritance path in the same most-derived type.

\noindent
$\forall a_1, a_2 : A\ |\ a_1\in C_1\leftY\sigma_1\rightY A \wedge a_2\in C_2\leftY\sigma_2\rightY A $ \\ 
$a_1.vtbl_i = a_2.vtbl_i \Rightarrow C_1 = C_2 \wedge \sigma_1 = \sigma_2$
\label{thm:vtbl}
\end{theorem}
\begin{proof}
Let us assume first $a_1.vtbl_i = a_2.vtbl_i$ but $C_1 \neq C_2$. In this case we 
have \code{rtti}$(a_1.vtbl_i) = $\code{rtti}$(a_2.vtbl_i)$. By definition 
\code{rtti}$(a_1.vtbl_i) = C_1$ while \code{rtti}$(a_2.vtbl_i) = C_2$, which 
contradicts that $C_1 \neq C_2$. Thus $C_1 = C_2 = C$.

Let us assume now that $a_1.vtbl_i = a_2.vtbl_i$ but $\sigma_1 \neq \sigma_2$. 
Let $\sigma_i=\langle h_i,l_i\rangle,i=1,2$ 

If $h_1 \neq h_2$ then one of them refers to a virtual base while the other to a 
repeated one. Assuming $h_1$ refers to a virtual path, \code{vbase}$(a_1.vtbl_i)$ 
has to be defined inside the vtable according to the ABI, while 
\code{vbase}$(a_2.vtbl_i)$ -- should not. This would contradict again that both 
$vtbl_i$ refer to the same virtual table.

We have thus $h_1 = h_2 = h$. If $h = Shared$ than there is only one path to 
such $A$ in $C$, which would contradict $\sigma_1 \neq \sigma_2$. 
If $h = Repeated$ then we must have that $l_1 \neq l_2$. In this case let $k$ be 
the first position in which they differ: 
$l_1^j=l_2^j \forall j<k \wedge l_1^k\neq l_2^k$. Since our class $A$ is a base 
class for classes $l_1^k$ and $l_2^k$, both of which are in turn base classes of 
$C$, the object identity requirement of C++ require that the relevant subobjects 
of type $A$ have different offsets within class $C$: 
$offset(\sigma_1)\neq offset(\sigma_2)$ However 
$offset(\sigma_1)=$\code{off2top}$(a_1.vtbl_i)=$\code{off2top}$(a_2.vtbl_i)=offset(\sigma_2)$ 
since $a_1.vtbl_i = a_2.vtbl_i$, which contradicts that the offsets are different.
\end{proof}

\noindent
Conjecture in the other direction is not true in general as there may be 
duplicate v-tables for the same type present at run-time. This happens in 
many C++ implementations in the presence of DLLs as the same class compiled into 
executable and DLL it loads may have identical v-tables inside the 
executable's and DLL's binaries.

Note also that we require both static types to be the same. Dropping this 
requirement and saying that equality of vtbl-pointers also implies equality of 
the static types is not true in general because a derived class will share the 
vtbl-pointer with its primary base class (see Lemma~\ref{lem:vtbl}). The theorem 
can be reformulated, however, stating that one static type will necessarily be a 
subtype of the other. The current forumlation is sufficient for our purposes, 
while reformulation will require more elaborate discussion of the algebra 
of subobjects~\cite{RDL11}, which we touch only briefly.

\begin{corollary}
Results of \code{dynamic_cast} can be reapplied to a different instance from 
within the same subobject. 

$\forall A,B \forall a_1, a_2 : A\ |\ a_1.vtbl_i = a_2.vtbl_i \Rightarrow$ \\
\code{dynamic_cast<B>}$(a_1).vtbl_j = $\code{dynamic_cast<B>}$(a_2).vtbl_j \vee$ \\
\code{dynamic_cast<B>}$(a_1)$ throws $\wedge$ \code{dynamic_cast<B>}$(a_2)$ throws.
\label{crl:vtbl}
\end{corollary}

\noindent
During construction and deconstruction of 
an object, the value of a given vtbl-pointer may change. In particular, 
that value will reflect the dynamic type of the object to be the type of the 
fully constructed part only. However, this does not affect our reasoning, as during 
such transition we also treat the object to have the type of its fully 
constructed base only. Such interpretation is in line with the C++ semantics for 
virtual function calls and the use of RTTI during construction and destruction of an 
object. Once the complete object is fully constructed, the value of the 
vtbl-pointer will remain the same for the lifetime of the object.

\subsection{Memoization Device}
\label{sec:memdev}

Let us look at a slightly more general problem than type switching. Consider a 
generalization of the switch statement that takes predicates on a subject as its 
clauses and executes the first statement $s_i$ whose predicate is enabled: 

\begin{lstlisting}[keepspaces]
switch (x) { case P1(x): s1; ... case Pn(x): sn; }
\end{lstlisting}

\noindent
Assuming that predicates depend only on $x$ and nothing else as well as that 
they do not involve any side effects, we can be sure that the next time we come 
to such a switch with the same value, the same predicate will be enabled 
first. Thus, we would like to avoid evaluating predicates and jump straight to 
the statement it guards. In a way we would like the switch to  memoize which 
case is enabled for a given value of $x$.

The idea is to generate a simple cascading-if statement interleaved with jump 
targets and instructions that associate the original value with enabled targed. 
The code before the statement looks up whether the association for a given value 
has already been established, and, if so, jumps directly to the target; otherwise 
the sequential execution of the cascading-if is started. To ensure 
that the actual code associated with the predicates remains unaware of this 
optimization, the code preceeding it after the target must re-establish any 
invariant guaranteed by sequential execution (\textsection\ref{sec:vtblmem}).

The above code can easily be produced in a compiler setting, but producing it in 
a library setting is a challenge. Inspired by Duff's Device~\cite{Duff}, 
we devised a construct that we call \emph{Memoization Device} that does just 
that in standard C++:

\begin{lstlisting}
typedef decltype(x) T;
static std::unordered_map<T,int> jump_target_map;

switch (int& target = jump_target_map[x]) {
default: // entered when we have not seen x yet
    if (P1(x)) { target = 1; case 1: s1; } else 
    if (P2(x)) { target = 2; case 2: s2; } else
      ...
    if (Pn(x)) { target = @$n$@; case @$n$@: sn; } else
                target = @$n+1$@;
case @$n+1$@: // none of the predicates is true on x
}
\end{lstlisting}

\noindent
The static \code{jump_target_map} hash table will be allocated upon first entry 
to the function. The map is initially empty and according to its logic, 
request for a key $x$ not yet in the map will allocate a 
new entry with its associated data default initialized (to 0 for int). Since 
there is no case label 0 in the switch, default case will be taken, which, in 
turn, will initiate sequential execution of the interleaved cascading-if 
statement. Assignments to \code{target} effectively establish association 
between value $x$ and corresponding predicate, since \code{target} is just a 
reference to \code{jump_target_map[x]}. The last assignment records absence of 
enabled predicates for the value.

To change the first-fit semantics of the above construct into \emph{sequential 
all-fit}, we remove the \code{else}s and rely on fall-through behavior of the 
switch. We also make the assignments conditional to make sure only the first one 
gets recorded:

\begin{lstlisting}
    if (Pi(x)) { if (target == 0) target = i; case i: si; }
\end{lstlisting}

\noindent
Note that the protocol that has to be maintained by this structure does not 
depend on the actual values of case labels. We only require them to be 
different and include a predefined default value. The default clause can be 
replaced with a case clause for the predefined value, however keeping the default  
clause result in a faster code. A more important performance consideration is to 
keep the values close to each other. Not following this rule might result in a 
compiler choosing a decision tree over a jump table implementation of the 
switch, which in our experience significantly degrades the performance.

The first-fit semantics is not an inherent property of the memoization device. 
Assuming that the conditions are either mutually exclusive or imply one another, we 
can build a decision-tree-based memoization device that will effectively have 
\emph{most-specific} semantics -- an analog of best-fit semantics in predicate 
dispatching~\cite{ErnstKC98}.

Imagine that the predicates with the numbers $2i$ and $2i+1$ are mutually exclusive and 
each imply the value of the predicate with number $i$ i.e. $\forall x \in Domain(P)$
\begin{eqnarray*}
P_{2i+1}(x)\rightarrow P_i(x) \wedge P_{2i}(x)\rightarrow P_i(x) \wedge \neg(P_{2i+1}(x) \wedge P_{2i}(x))
\end{eqnarray*}
\noindent
The following decision-tree based memoization device will execute the statement 
$s_i$ associated with the \emph{most-specific} predicate $P_i$ (i.e. the 
predicate that implies all other predicates true on $x$) that evaluates to true or will 
skip the entire statement if none of the predicates is true on $x$.

\begin{lstlisting}
switch (int& target = jump_target_map[x]) {
default:
    if (P1(x)) {
        if (P2(x)) {
            if (P4(x)) { target = 4; case 4: s4; } else
            if (P5(x)) { target = 5; case 5: s5; } 
            target = 2; case 2: s2;
        } else
        if (P3(x)) {
            if (P6(x)) { target = 6; case 6: s6; } else
            if (P7(x)) { target = 7; case 7: s7; } 
            target = 3; case 3: s3;
        }
        target = 1; case 1: s1;
    } else { target = 0; case 0: ; }
}
\end{lstlisting}

\noindent
An example of predicates that satisfy this condition are class membership tests
where the truth of testing membership in a derived class implies 
the truth of testing membership in its base class. Our library 
solution prefers the simpler cascading-if approach only because the necessary 
structure of the code can be laid out directly with macros. A compiler solution 
will use the decision-tree approach whenever possible to lower the cost of the 
first match from linear in case's number to logarithmic as seen in Figure\ref{fig:DCastVis1}.

%When the predicates do not satisfy the implication or mutual exclusion properties 
%mentioned above, a compiler of a language based on predicate dispatching would 
%typically issue an ambiguity error. Some languages might choose to resolve it 
%according to lexical or some other ordering. In any case, the presence of 
%ambiguities or their resolution has nothing to do with memoization device 
%itself. The latter only helps optimize the execution once a particular choice of 
%semantics has been made and code implementing it has been laid out.

The main advantage of the memoization device is that it can be built around 
almost any code, providing that we can re-establish the invariants, guaranteed 
by sequential execution. Its main disadvantage is the size of the hash table 
that grows proportionally to the number of different values seen. Fortunately, 
the values can often be grouped into equivalence classes that do not change the 
outcome of the predicate. The map can then associate the equivalence class of a 
value with a target instead of associating the value with it. The next 
subsection does exactly that for polymorphic objects.

\subsection{V-Table Pointer Memoization}
\label{sec:vtblmem}

The memoization device can almost immediately be used for multi-way type testing by 
using \code{dynamic_cast<Di>} as a predicate $P_i$. This cannot be considered a 
type switching solution, however, as one would expect to also have a reference 
to the uncovered type. Using a \code{static_cast<Di>} upon successful type test 
would have been a solution if we did not have multiple inheritance. It certainly 
can be used as such in languages with only single inheritance. For the fully 
functional C++ solution, we combine the memoization device with the properties 
of virtual table pointers into a \emph{V-Table Pointer Memoization} technique.

We saw that vtbl-pointers uniquely determine the subobject within an object 
(Theorem~\ref{thm:vtbl}), while the result of a \code{dynamic_cast} can be reapplied 
from the same subobject (Corollary~\ref{crl:vtbl}). The idea is thus to group 
all the objects accordingly to the value of their vtbl-pointer and associate both 
target and the required offset with it through memoization device:

\begin{lstlisting}
typedef std::pair<ptrdiff_t,size_t> type_switch_info;
static std::unordered_map<intptr_t, type_switch_info> jump_target_map;
intptr_t          vtbl = *reinterpret_cast<const intptr_t*>(p);
type_switch_info& info = jump_target_map[vtbl];
const void*       tptr; 
switch (info.second) ...
\end{lstlisting}

\noindent
The code for the $i^{th}$ case now evaluates the required offset on the first 
entry and associates it and the target with the vtbl-pointer of the subject.
The call to \code{adjust_ptr<Di>} re-establishes the invariant that 
\code{matched} is a reference to type \code{Di} of the subject \code{p}.
%The condition of the inner if-statement is only needed to implement the 
%sequential all-fit semantics and can be removed when fall-through behavior is 
%not required.

\begin{lstlisting}
    if (tptr = dynamic_cast<const Di*>(p)) {
        if (info.second == 0) { // supports fall-through
            info.first  = intptr_t(tptr)-intptr_t(p); // offset
            info.second = @$i$@; // jump target
        }
case @$i$@: // @$i$@ is a constant here - clause's position in switch
        auto matched = adjust_ptr<Di>(p,info.first); 
        si;
    }
\end{lstlisting}

\noindent
The use of dynamic cast makes a huge difference in comparison to the use of 
static cast we dismissed above. First of all the C++ type system is much more 
restrictive about the static cast and many cases where it is not allowed can 
still be handled by dynamic cast. Examples of these include downcasting from an 
ambiguous base class or cross-casting between unrelated base classes.

An important benefit we get from this optimization is that the number of values 
stored in the hash table is on the order $O(|A|)$, where $A$ represents the 
static type of an object, while $|A|$ represents the number of classes directly 
or indirectly derived from $A$. The linear coefficient of the big-o notation 
reflects possibly multiple vtbl-pointers in derived classes due to multiple 
inheritance.

The most important benefit of this optimization, however, is the constant time 
on average used to dispatch each of the case clauses, regardless of their 
position in the type switch. The worst complexity can be proportional to the 
size of the map, but we show in the next section that most of the time we will 
be bypassing traditional access to its elements. We need this extra 
optimization because, as-is, the type switch is still about 50\% slower than 
the visitor design pattern.

%Note that we can apply the reasoning of \textsection\ref{sec:memdev} and change 
%the first-fit semantics of the resulting match statement into a best-fit 
%semantics simply by changing the underlain cascading-if structure with decision 
%tree. A compiler implementation of a type switch based on V-Table Pointer 
%Memoization will certainly take advantage of this optimization to cut down the 
%cost of the first run on a given vtbl-pointer, when the actual memoization happens.

\subsubsection{Structure of Virtual Table Pointers}
\label{sec:sovtp}

Virtual table pointers are not constant values and are not even guaranteed to be 
the same between different runs of the same application. Techniques like 
\emph{address space layout randomization} or simple \emph{rebasing} of the entire 
module are likely to change these values. The relative distance between them is 
likely to remain the same though as long as they come from the same module.

Knowing that vtbl-pointers point into an array of function pointers, we should 
expect them to be aligned accordingly and thus have a few lowest bits as zero. 
Similarly, since many derived classes do not introduce new virtual functions, 
the size of their virtual tables remains the same. When allocated sequentially 
in memory, we can expect a certain number of lowest bits in the vtbl-pointers 
pointing to them to be the same.

These assumptions, supported by actual observations, has made virtual table 
pointers of classes related by inheritance ideally suitable for indexing -- the 
values obtained by throwing away the common bits on the right were compactly 
distributed in small disjoint ranges. We use them to address a cache 
built on top of the hash table in order to eliminate a hash table lookup in most 
of the cases.

Depending on the number of actual collisions that happen in the cache, our 
v-table pointer memoization technique can come close to, and even outperform, the 
visitor design pattern. The numbers are, of course, averaged over many runs as 
the first run on every vtbl-pointer will take an amount of time as shown in 
Figure\ref{fig:DCastVis1}. We did however test our technique on real code and 
can confirm that it does perform well in the real-world use cases.

The information about jump targets and necessary offsets is just an example of 
information we might want to be able to associate with, and access via, virtual 
table pointers. Our implementation of \code{memoized_cast}~\cite{TR}, for example, 
effectively reuses this general data structure with a different type of element 
values. We thus created a generic reusable class \code{vtblmap<T>} that maps 
vtbl-pointers to elements of type T. We will refer to the combined cache and 
hash-table data structure, extended with the logic for minimizing conflicts 
presented below, as a \emph{vtblmap} data structure.

\subsubsection{Minimization of Conflicts}
\label{sec:moc}

The small number of cycles that the visitor design pattern needs to uncover a 
type does not let us put too sophisticated cache indexing mechanisms into the 
critical path of execution. This is why we limit our indexing function to shifts 
and masking operations as well as choose the size of the cache to be a power of 2.

As usual, by \emph{conflict} we mean a situation in which two or more keys (virtual 
table pointers here) are mapped to the same location in cache using a given indexing 
function. The presence of conflicts means that accessing values of \code{vtblmap<T>} 
associated with some vtbl-pointers may result in slower lookup of the element 
inside the underlying hash table relative to a direct fetch from the cache.
This `slower' lookup, as we mentioned, is constant on average and linear in the 
size of the hash map in the worst case.

Given $n$ vtbl-pointers we can always find a cache size that will render no 
conflicts between them. The necessary size of such a cache, however, can be too 
big to justify the use of memory. This is why, in our current implementation, we 
always consider only 2 different cache sizes: $2^k$ and $2^{k+1}$ where 
$2^{k-1} < n \leq 2^k$. This guarantees that the cache size is never more than 4 
times bigger than the minimum required cache size.

During our experiments, we noticed that often the change in the smallest 
different bit happens only in a few vtbl-pointers, which was effectively 
cutting the available cache space in half. To overcome this problem, we let the 
number of bits by which we shift the vtbl-pointer vary further and compute it in 
a way that minimizes the number of conflicts.

To avoid doing any computations in the critical path, \code{vtblmap} only 
recomputes the optimal shift and the size of the cache when an actual collision 
happens. In order to avoid constant recomputations when conflicts are unavoidable, 
we only reconfigure the optimal parameters if 
the number of vtbl-pointers in the \code{vtblmap} has increased since the last 
recomputation. Since the number of vtbl-pointers is of the order $O(|A|)$, where 
$A$ is the static type of all vtbl-pointers coming through a \code{vtblmap}, the 
restriction assures that reconfigurations will not happen infinitely often.

To minimize the number of recomputations even further, our library communicates 
to the \code{vtblmap<T>}, through its constructor, the number of case clauses in 
the underlain match statement. We use this number as an estimate of the expected 
size of the \code{vtblmap} and pre-allocate the cache accordingly to this estimated 
number. The cache is still allowed to grow based on the actual number of 
vtbl-pointers that comes through a \code{vtblmap}, but it never shrinks from the
initial value. This improvement significantly minimizes the number of collisions 
at early stages, as well as the number of possibilities we have to consider 
during reconfiguration.

The above logic always chooses the configuration that renders 
no conflicts, when such a configuration is possible during recomputation of 
optimal parameters. When this is not possible, it is natural to prefer collisions 
to happen on less-frequent vtbl-pointers.

We studied the frequency of vtbl-pointers that come through various match statements
of a C++ pretty-printer that we implemented on top of the Pivot 
framework~\cite{Pivot09} using our pattern-matching library. We ran the 
pretty-printer on a set of C++ standard library headers and then ranked all the  
classes from the most-frequent to the least-frequent ones, on average. The 
resulting probability distribution resembled the power-law distribution, which means 
that for that specific application, the probability of some vtbl-pointers was much 
higher than the probability of many other vtbl-pointers taken altogether. In 
our case, the two most frequent classes were representing the use of a variable in 
a program, and their combined frequency was larger than the combined frequency 
of all the other nodes. Naturally, we would like to avoid conflicts on such 
classes in the cache, when possible.

To do this, our library provides a configuration flag that enables tracing the
frequencies of each vtbl-pointer in a switch and uses this information to 
minimize the number of conflicts. Due to page limitations, we refer the reader 
to the technical report accompanying this paper for more details on our 
experiments with the use of vtbl-pointer frequencies~\cite{TR}. Here we will only 
mention that, by default, we do not enable frequency tracing, because the 
significant drop in the number of actual collisions was not reflected in a 
noticeable decrease in execution time. This was because the total 
number of actual collisions, even in non-frequency based caching, was much smaller 
than the number of successful cache hits.
