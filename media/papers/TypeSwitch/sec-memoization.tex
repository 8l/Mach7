\section{Proposed Solution}
\label{sec:copc}

C++ does not have direct support of algebraic data types, but they can usually 
be encoded with classes in a number of ways. One common such encoding is to 
introduce an abstract base class representing an algebraic data type with 
several derived classes representing variants. The variants can then be 
discriminated with either run-time type information (further referred to as 
\emph{polymorphic encoding}) or a dedicated member of a base class (further 
referred to as \emph{tagged encoding}).

Our handling of type switches for polymorphic and tagged encoding is different 
with each having its pros and cons described in details in \textsection\ref{sec:cmp}.
In the remainder of this section we will concentrate more on the type switch for 
polymorphic encoding as it is truly open. The type switch for tagged encoding 
(\textsection\ref{sec:cotc}) is somewhat more efficient, however, we believe 
that making it more open will also eradicate the performance advantages it 
currently has. The difference in performance can be seen as a price one pays for 
keeping the solution open.

\subsection{Virtual Table Pointers}
\label{sec:vtp}

Before we discuss our solution we would like to talk about certain properties of 
the C++ run-time system that we rely on. The ultimate goal of this subsection is 
to show that every polymorpic object in C++ has a run-time value embedded into 
it that \emph{uniquely} determines the sub-object within the most derived object, 
pointed to by this-pointer of a given static type.

Strictly speaking, C++ standard does not require implementations to use any 
given technique (e.g. use virtual tables to implement virtual functions), 
however interoperability requirements have forced compiler vendors to design a 
set of rules called Common Vendor Application Binary Interface (further refered 
to as the C++ ABI)~\cite{C++ABI}. Most C++ compilers today follow these rules, 
with the notable exception of Microsoft Visual C++. We show that the technique 
presented here will work with any C++ compiler that follows C++ ABI. Microsoft's 
own ABI is not publically available and thus we could not verify that it satisfies 
our requirements. Nevertheless we did run numerous experiments with various 
class hierarchies and have sufficient confidence that our approach can be used 
in Visual C++. This is why we include experimental results for this compiler as 
well.

Besides single inheritance, which is supported by most object-oriented languages, C++ 
supports multiple-inheritance of two kinds: repeated and virtual. Under repeated 
inheritance, a given derived class may inherit a certain base class in several ways. 
Objects of such class will have several subobjects of that base class. Under 
virtual inheritance there will only be one shared subobject, accessible through 
different inheritance paths. Because of this peculiarity of the C++ type system 
it is not sufficient to talk only about the static and dynamic types of an object -- 
one has to talk about a subobject of a certain static type accessible through a
given inheritance path within a dynamic type.

The notion of subobject has been formalized before~\cite{RF95,WNST06,RDL11}.
We follow here the presentation of Ramamanandro et al~\cite{RDL11}.

A base class subobject of a given complete object is represented by a pair 
$\sigma = \langle h,l\rangle$ with $h \in \{Repeated,Shared\}$ representing the 
kind of inheritance (single inheritance is $Repeated$ with one base class) and $l$ 
representing the path in a non-virtual inheritance graph.

A predicate $C\leftY\sigma\rightY A$ they introduce means that $\sigma$ 
designates a base class subobject of class $C$, with subobject's static type 
being $A$.

A class that declares or inherits a virtual function is called a 
\emph{polymorphic class}~\cite[\textsection 10.3]{C++0x}. The C++ ABI in turn defines 
\emph{dynamic class} to be a class requiring a virtual table pointer (because it 
or its bases have one or more virtual member functions or virtual base classes). 
A polymorphic class is thus a dynamic class by definition.

A \emph{virtual table pointer} (vtbl-pointer) is a member of object's layout 
pointing to a virtual table. A \emph{virtual table} is a table of information used 
to dispatch virtual functions, access virtual base class subobjects, and to 
access information for runtime type identification (RTTI). Because of repeated
inheritance, an object of given type may have several vtbl-pointers in it. Each 
such pointer corresponds to one of the polymorphic base classes. Given an object 
$a$ of static type $A$ that has $k$ vtbl-pointers in it, we will use the same 
notation we use for regular fields to refer them: $a.vtbl_i$.

A \emph{primary base class} for a dynamic class is the unique base class (if any) 
with which it shares the virtual table pointer at offset 0. The data layout 
procedure for non-POD types described in \textsection2.4 of the C++ ABI~\cite{C++ABI} 
requires dynamic classes either to allocate vtable pointer at offset 0 or share 
the virtual table pointer from its primary base class, which is by definition at 
offset 0. For our purpose this means that we can rely on a virtual table pointer 
always being present at offset 0 for all dynamic classes, and thus for all polymorphic 
classes.

\begin{lemma}
In an object layout that adheres to the C++ ABI, a polymorphic class always has a 
virtual table pointer at offset 0.
\label{lem:vtbl}
\end{lemma}

\noindent
Knowing how to extract a vtbl-pointer as well as that all the objects of the 
same most derived type share the same vtbl-pointer, the idea is to try to use 
its value to uniquely identify the type and even sub-object within it, pointed 
to by this-pointer. Unfortunately nothing in the C++ ABI states these pointers 
should be unique. A popular optimization technique of sharing base's class 
virtual table for a derived class that does not override any virtual methods 
will surely violate this assumption. Nevertheless, we show below that in the 
presense of RTTI, a C++ ABI-compliant implementation is guaranteed to have 
different values of vtbl-pointers in different sub-objects.

%C++ standard requires an argument of \code{dynamic_cast} to be a pointer to or 
%an lvalue of a polymorphic type when performing \emph{downcast} -- a cast from 
%base to derived~\cite[\textsection 5.2.7-6]{C++0x}. We can thus always safely 
%extract virtual table pointer from offset 0 of any valid argument to 
%\code{dynamic_cast}.

%Similarly, each class that has virtual member functions or virtual bases has an 
%associated set of virtual tables. There may be multiple virtual tables for a 
%particular class, if it is used as a base class for other classes. However, the 
%virtual table pointers within all the objects (instances) of a particular 
%most-derived class point to the same set of virtual tables.

The exact content of the virtual table is not important for this discussion. We 
would like to point out a few fields in it that we will refer to later.

\begin{itemize}
\setlength{\itemsep}{0pt}
\setlength{\parskip}{0pt}
\item The \emph{typeinfo pointer} points to the typeinfo object used for RTTI. 
      It is always present.  
\item The \emph{offset to top} holds the displacement to the top of the object 
      from the location within the object of the virtual table pointer that 
      addresses this virtual table, as a \code{ptrdiff_t}. It is always present.
\item \emph{Virtual Base (vbase) offsets} are used to access the virtual bases 
      of an object. Such an entry is added to the derived class object address 
      (i.e. the address of its virtual table pointer) to get the address of a 
      virtual base class subobject. Such an entry is required for each virtual 
      base class.
\end{itemize}

\noindent
Given a virtual table pointer \code{vtbl}, we will refer to these fields as 
\code{rtti(vtbl)}, \code{off2top(vtbl)} and \code{vbase(vtbl)} respectively. 
We will also assume presence of a function $offset(\sigma)$ that defines the 
offset of the base class identified by the end of the path $\sigma$ within a 
class identified by its first element.

\begin{theorem}
In an object layout that adheres to the C++ ABI, if virtual table pointers of two 
objects of the same static type are the same, then they both refer to subobjects 
with the same inheritance path in the same most-derived type.
\begin{eqnarray*}
    \forall a_1, a_2 : A\ |\ a_1\in C_1\leftY\sigma_1\rightY A \wedge a_2\in C_2\leftY\sigma_2\rightY A \\
    a_1.vtbl_i = a_2.vtbl_i \Rightarrow C_1 = C_2 \wedge \sigma_1 = \sigma_2
\end{eqnarray*}
\label{thm:vtbl}
\end{theorem}
\begin{proof}
Let us assume first $a_1.vtbl_i = a_2.vtbl_i$ but $C_1 \neq C_2$. In this case we 
have \code{rtti}$(a_1.vtbl_i) = $\code{rtti}$(a_2.vtbl_i)$. By definition 
\code{rtti}$(a_1.vtbl_i) = C_1$ while \code{rtti}$(a_2.vtbl_i) = C_2$, which 
contradicts that $C_1 \neq C_2$. Thus $C_1 = C_2 = C$.

Let us assume now that $a_1.vtbl_i = a_2.vtbl_i$ but $\sigma_1 \neq \sigma_2$. 
Let $\sigma_i=\langle h_i,l_i\rangle,i=1,2$ 

If $h_1 \neq h_2$ then one of them refers to virtual base while the other to 
repeated. Assuming $h_1$ refers to virtual path, \code{vbase}$(a_1.vtbl_i)$ has 
to be defined inside the vtable accordingly to ABI, while 
\code{vbase}$(a_2.vtbl_i)$ -- should not. This would contradict again that both 
$vtbl_i$ refer the same virtual table.

We have thus $h_1 = h_2 = h$. If $h = Shared$ than there is only one path to 
such $A$ in $C$, which would contradict $\sigma_1 \neq \sigma_2$. 
If $h = Repeated$ then we must have that $l_1 \neq l_2$. In this case let $k$ be 
the first position in which they differ: 
$l_1^j=l_2^j \forall j<k \wedge l_1^k\neq l_2^k$. Since our class $A$ is a base 
class for classes $l_1^k$ and $l_2^k$, both of which are in turn base classes of 
$C$, object identity requirement of C++ require that the relevant subobjects of 
type $A$ have different offsets within class $C$: 
$offset(\sigma_1)\neq offset(\sigma_2)$ However 
$offset(\sigma_1)=$\code{off2top}$(a_1.vtbl_i)=$\code{off2top}$(a_2.vtbl_i)=offset(\sigma_2)$ 
since $a_1.vtbl_i = a_2.vtbl_i$, which contradicts that offsets are different.
\end{proof}

Conjecture in the other direction is not true in general as there may be 
duplicate virtual tables for the same type present at run-time. This happens in 
many C++ implementations in the presence of dynamically linked libraries as the
same class compiled into executable and into a DLL it loads may have identical 
virtual tables inside the executable's and DLL's binaries.

\begin{corollary}
Results of \code{dynamic_cast} can be reapplied to a different instance from 
within the same subobject. 

$\forall A,B \forall a_1, a_2 : A\ |\ a_1.vtbl_i = a_2.vtbl_i \Rightarrow$ \\
\code{dynamic_cast<B>}$(a_1).vtbl_j = $\code{dynamic_cast<B>}$(a_2).vtbl_j \vee$ \\
\code{dynamic_cast<B>}$(a_1)$ throws $\wedge$ \code{dynamic_cast<B>}$(a_2)$ throws.
\label{crl:vtbl}
\end{corollary}

Lastly we would like to point out that during construction and deconstruction of 
an object, the value of a given virtual table pointer may change. In particular, 
that value will reflect the dynamic type of the object to be the type of the 
fully constructed part only. This fact does not affect our reasoning, as during 
such transition we also treat the object to have the type of its fully 
constructed base only. Such interpretation is in line with the C++ semantics for 
virtual function calls and the use of RTTI during construction and destruction of an 
object. Once the complete object is fully constructed, the value of the virtual 
table pointer will remain the same for the lifetime of the object.

\subsection{Memoization Device}
\label{sec:memdev}

Let us look at a slightly more general problem than type switching. Consider a 
generalization of the switch statement that takes predicates on a subject as its 
clauses and executes the first statement $s_i$ whose predicate got enabled: 

\begin{lstlisting}
switch (x)
{
case P1(x): s1;
 ...
case Pn(x): sn;
}
\end{lstlisting}

\noindent
Assuming that predicates depend only on $x$ and nothing else as well as that 
they do not involve any side effects, we can be sure that the next time we come 
to such a switch with the same value, the same predicate will be enabled 
first. Thus, we would like to avoid evaluating predicates and jump straight to 
the statement it guards. In a way we would like the switch to  memoize which 
case is enabled for a given value of $x$.

Inspired by Duff's Device~\cite{Duff}, we devised a construct that we call 
\emph{Memoization Device} that does just that:

\begin{lstlisting}
typedef decltype(x) T;
static std::unordered_map<T,int> jump_target_map;

switch (int& target = jump_target_map[x])
{
default: // entered when we haven't seen x yet
    if (P1(x)) { target = 1;   case 1: s1; } else 
    if (P2(x)) { target = 2;   case 2: s2; } else
      ...
    if (Pn(x)) { target = n;   case n: sn; } else
                 target = n+1;
case n+1: // none of predicates is true on x
}
\end{lstlisting}

\noindent
The static \code{jump_target_map} maps values to jump targets, and will be 
allocated upon first entry to the function. The map is initially empty and is 
updated from within the switch as we proceed through the interleaved 
cascading-if statement. Accordingly to the logic of the STL's \code{unordered_map}, 
a key $x$ that is not yet in the map will result in allocation of a new entry 
with its associated data (of type int) default initialized to 0. Since there is 
no case label 0 in the switch, default case will be taken, which, in turn, will 
initiate sequential execution of the interleaved cascading-if statement.

The sequential execution of the cascading-if statement will keep checking 
predicates $P_j(x)$ until the first predicate $P_i(x)$ that returns true. By 
assigning $i$ to \code{target} we will effectively associate $i$ with $x$ since 
\code{target} is just a reference to \code{jump_target_map[x]}. This association 
will make sure that the next time we are called with the value $x$ we will jump 
directly to the label $i$. When none of the predicates returns true, we will 
record it by associating $x$ with $n+1$, so that the next time we can jump 
directly to the end of the switch on $x$. 

The above construct effectively gives the entire statement first-fit semantics. 
In order to evaluate all the statements whose predicates are true, and thus 
give the construct all-fit semantics, we might want to be able to preserve the 
fall-through behavior of the switch. In this case we can still skip the initial 
predicates returning false and start from the first successful one. This can be 
easily achieved by removing all else statements and making if-statements 
independent as well as wrapping all assignments to \code{target} with a condition, 
to make sure only the first successful predicate executes it:

\begin{lstlisting}
    if (Pi(x)) { if (target == 0) target = i; case i: si; }
\end{lstlisting}

\noindent
Note that the protocol that has to be maintained by this structure does not 
depend on the actual value of case labels. The only property we rely on here is 
that they are all different and that there is a predefined default value, 
distinct from any of them. In fact, the default clause we used here can be 
replaced with case clause with the predefined value. From experience, however, 
we have noticed that keeping the default clause results in a faster code. A more 
important performance consideration is to keep the values close to each other. 
Not following this rule might result in a compiler choosing a decision tree over a 
jump table implementation of the switch, which will significantly degrade the 
performance.

The first-fit semantics is not an inherent property of the memoization device however. 
Assuming that the conditions are either mutually exclusive or imply one another, we 
can build a decision-tree-based memoization device that will effectively have 
\emph{most-specific} semantics -- an analog of best-fit semantics in predicate 
dispatching~\cite{ErnstKC98}.

Imagine that the predicates with the numbers $2i$ and $2i+1$ are mutually exclusive and 
each imply the value of the predicate with number $i$ i.e. $\forall x \in Domain(P)$
\begin{eqnarray*}
P_{2i+1}(x)\rightarrow P_i(x) \wedge P_{2i}(x)\rightarrow P_i(x) \wedge \neg(P_{2i+1}(x) \wedge P_{2i}(x))
\end{eqnarray*}
\noindent
The following decision-tree based memoization device will execute the statement 
$s_i$ associated with the \emph{most-specific} predicate $P_i$ (i.e. the 
predicate that implies all other predicates true on $x$) that evaluates to true or will 
skip the entire statement if none of the predicates is true on $x$.

\begin{lstlisting}
switch (int& target = jump_target_map[x])
{
default:
    if (P1(x)) {
        if (P2(x)) {
            if (P4(x)) { target = 4; case 4: s4; } else
            if (P5(x)) { target = 5; case 5: s5; } 
            target = 2; case 2: s2;
        } else
        if (P3(x)) {
            if (P6(x)) { target = 6; case 6: s6; } else
            if (P7(x)) { target = 7; case 7: s7; } 
            target = 3; case 3: s3;
        }
        target = 1; case 1: s1;
    } else {
        target = 0; case 0:   ;
    }
}
\end{lstlisting}

\noindent
An example of predicates that satisfy this condition are class membership tests
where the truth of a predicate that tests membership in a derived class implies 
the truth of a predicate that tests membership in its base class. Our library 
solution prefers the simpler cascading-if approach only because the necessary 
structure of the code can be laid out directly with macros. A compiler solution 
will use the decision-tree approach whenever possible to lower the cost of the 
first match from linear in case's number to logarithmic as seen in Figure\ref{fig:DCastVis1}.

When the predicates do not satisfy the implication or mutual exclusion properties 
mentioned above, a compiler of a language based on predicate dispatching would 
typically issue an ambiguity error. Some languages might choose to resolve it 
according to lexical or some other ordering. In any case, the presence of 
ambiguities or their resolution has nothing to do with memoization device 
itself. The latter only helps optimize the execution once a particular choice of 
semantics has been made and code implementing it has been laid out.

The main advantage of the memoization device is that it does not impose any 
restriction on the type of a subject. It can easily support multiple scrutiny 
by turning $x$ into a tuple. Another advantage is that conditions and statements 
do not have to be repeated several times textually, which lets us turn the 
boilerplate code of maintaining memoization logic into macros.

The main disadvantage of such a solution is, of course, the size of the hash table 
that grows proportionally to the number of different values coming through the 
function. We will see, however, that oftentimes the values can be grouped into 
equivalence classes, such that values in the same class do not change the 
predicate. The map can then associate the equivalence class of a value with a
target instead of associating the value with it.

\subsection{V-Table Pointer Memoization}
\label{sec:vtblmem}

The memoization device can almost immediately be used for multi-way type testing by 
using \code{dynamic_cast<Di>} as a predicate $P_i$. This cannot be considered a 
type switching solution, however, as one would expect to also have a reference 
to the uncovered type. Using a \code{static_cast<Di>} upon successful type test 
would have been a solution if we did not have multiple inheritance. It certainly 
can be used as such in languages with only single inheritance, e.g.  
Java. For the fully functional C++ solution, we combine the memoization device with 
the properties of virtual table pointers into a \emph{V-Table Pointer 
Memoization} technique.

We showed in Corollary~\ref{crl:vtbl} that the result of a dynamic cast can be 
reapplied on subobjects with the same virtual table pointer. With this in mind, 
we can now apply the memoization device to polymorphic objects grouped by their 
vtbl-pointer. The head of the switch requires few extra definitions:

\begin{lstlisting}
typedef std::pair<ptrdiff_t,size_t> type_switch_info;
static std::unordered_map<intptr_t, type_switch_info> jump_target_map;
intptr_t          vtbl = *reinterpret_cast<const intptr_t*>(p);
type_switch_info& info = jump_target_map[vtbl];
const void*       tptr; 
\end{lstlisting}

\noindent
We use the virtual table pointer extracted from a polymorphic object pointed to 
by \code{p} as a key for association. The value stored along the key in 
association now keeps both: the target for the switch as well as a memoized 
offset for dynamic cast. The snippet corresponding to the $i^{th}$ case now 
looks as following:

\begin{lstlisting}
    if (tptr = dynamic_cast<const Di*>(p)) {
        if (info.second == 0) {
            info.first  = intptr_t(tptr)-intptr_t(p); // offset
            info.second = @$i$@; // jump target
        }
case @$i$@: // @$i$@ is a constant here - clause's position in switch
        auto matched = adjust_ptr<Di>(p,info.first); 
        si;
    }
\end{lstlisting}

\noindent
The main condition remains the same. We keep checking for the first initialization 
because we allow fall-through behavior here, letting the user break from the 
switch when needed. Upon first entry we compute the offset that the dynamic cast 
performed and save it together with target associated to the virtual table 
pointer. On the next iteration we will jump directly to the case label and 
restore the invariant of \code{matched} being a properly-casted reference to the 
derived object.

The use of dynamic cast makes a huge difference in comparison to the use of 
static cast we dismissed above. First of all the C++ type system is much more 
restrictive about static cast and many cases where it is not allowed can 
still be handled by dynamic cast. Examples of these include downcasting from an 
ambiguous base class or cross-casting between unrelated base classes.

An important benefit we get from this optimization is that we do not store the 
actual values (pointers to objects) in the hash table anymore, but group them 
into equivalence classes based on their virtual table pointers. The number of 
such pointers in a program is always bound by $O(|A|)$, where $A$ represents the 
static type of an object, while $|A|$ represents the number of classes directly 
or indirectly derived from $A$. The linear coefficient hidden in big-o notation 
reflects possibly multiple vtbl-pointers in derived classes due to the use of 
multiple inheritance.

However, the most important benefit of this optimization is the constant time on average 
used to dispatch each of the case clauses, regardless of their position in the 
type switch. The constant time on average comes from the average complexity 
of accessing an element in an \code{unordered_map}, while its worst complexity can 
be proportional to the size of the map. We show in the next section, however, 
that most of the time we will be bypassing traditional access to elements of the 
map, because, as-is, the type switch is still about 50\% slower than the visitor 
design pattern.

%Note that we can apply the reasoning of \textsection\ref{sec:memdev} and change 
%the first-fit semantics of the resulting match statement into a best-fit 
%semantics simply by changing the underlain cascading-if structure with decision 
%tree. A compiler implementation of a type switch based on V-Table Pointer 
%Memoization will certainly take advantage of this optimization to cut down the 
%cost of the first run on a given vtbl-pointer, when the actual memoization happens.

\subsubsection{Structure of Virtual Table Pointers}
\label{sec:sovtp}

Virtual table pointers are not constant values and are not even guaranteed to be 
the same between different runs of the same application. Techniques like 
\emph{address space layout randomization} or simple \emph{rebasing} of the entire 
module are likely to change these values. The relative distance between them is 
likely to remain the same though as long as they come from the same module.

Knowing that vtbl-pointers point into an array of function pointers, we should 
expect them to be aligned accordingly to the alignment requirements of pointer 
types on the target machine. Similarly, since many derived classes do not 
introduce new virtual functions, the size of their virtual tables remains the 
same. When allocated sequentially in memory, we can expect a certain amount of 
lowest bits in the vtbl-pointers pointing to them to be the same.

These assumptions, supported by actual observations, has made virtual table 
pointers of classes related by inheritance ideally suitable for indexing -- the 
values obtained by throwing away the common bits on the right were compactly 
distributed in small disjoint ranges. We use those values to address a cache 
built on top of the hash table in order to eliminate a hash table lookup in most 
of the cases.

Depending on the number of actual collisions that happen in the cache, our 
v-table pointer memoization technique can come close to, and even outperform, the 
visitor design pattern. The numbers are, of course, averaged over many runs as 
the first run on every vtbl-pointer will take an amount of time as shown in 
Figure\ref{fig:DCastVis1}. We did however test our technique on real code and 
can confirm that it does perform well in the real-world use cases.

The information about jump targets and necessary offsets is just an example of 
information we might want to be able to associate with, and access via, virtual 
table pointers. Our implementation of \code{memoized_cast}, for example, 
effectively reuses this general data structure with a different type of element 
values. We thus created a generic reusable class \code{vtblmap<T>} that maps 
vtbl-pointers to elements of type T. We will refer to the combined cache and 
hash-table data structure, extended with the logic for minimizing conflicts 
presented below, as a \emph{vtblmap} data structure.

\subsubsection{Minimization of Conflicts}
\label{sec:moc}

The small number of cycles that the visitor design pattern needs to uncover a 
type does not let us put too sophisticated cache indexing mechanisms into the 
critical path of execution. This is why we limit our indexing function to shifts 
and masking operations as well as choose the size of the cache to be a power of 2.

As usual, by \emph{conflict} we mean a situation in which two or more keys (virtual 
table pointers here) are mapped to the same location in cache using a given indexing 
function. The presence of conflicts means that accessing values of \code{vtblmap<T>} 
associated with some vtbl-pointers may result in slower lookup of the element 
inside the underlying hash table relative to a direct fetch from the cache.
This `slower' lookup, as we mentioned, is constant on average and linear in the 
size of the hash map in the worst case.

Given $n$ vtbl-pointers we can always find a cache size that will render no 
conflicts between them. The necessary size of such a cache, however, can be too 
big to justify the use of memory. This is why, in our current implementation, we 
always consider only 2 different cache sizes: $2^k$ and $2^{k+1}$ where 
$2^{k-1} < n \leq 2^k$. This guarantees that the cache size is never more than 4 
times bigger than the minimum required cache size.

During our experiments, we noticed that often the change in the smallest 
different bit happens only in a few vtbl-pointers, which was effectively 
cutting the available cache space in half. To overcome this problem, we let the 
number of bits by which we shift the vtbl-pointer vary further and compute it in 
a way that minimizes the number of conflicts.

To avoid doing any computations in the critical path, \code{vtblmap} only 
recomputes the optimal shift and the size of the cache when an actual collision 
happens. In order to avoid constant recomputations when conflicts are unavoidable, 
we add an additional restriction of only reconfiguring the optimal parameters if 
the number of vtbl-pointers in the \code{vtblmap} has increased since the last 
recomputation. Since the number of vtbl-pointers is of the order $O(|A|)$, where 
$A$ is the static type of all vtbl-pointers coming through a \code{vtblmap}, the 
restriction assures that reconfigurations will not happen infinitely often.

To minimize the number of recomputations even further, our library communicates 
to the \code{vtblmap<T>}, through its constructor, the number of case clauses in 
the underlain match statement. We use this number as an estimate of the expected 
size of the \code{vtblmap} and pre-allocate the cache accordingly to this estimated 
number. The cache is still allowed to grow based on the actual number of 
vtbl-pointers that comes through a \code{vtblmap}, but it never shrinks from the
initial value. This improvement significantly minimizes the number of collisions 
at early stages, as well as the number of possibilities we have to consider 
during reconfiguration.

The above logic of \code{vtblmap} always chooses the configuration that renders 
no conflicts, when such a configuration is possible during recomputation of 
optimal parameters. When this is not possible, it is natural to prefer collisions 
to happen on less-frequent vtbl-pointers.

We studied the frequency of vtbl-pointers that come through various match statements
of a C++ pretty-printer that we implemented on top of the Pivot 
framework~\cite{Pivot09} using our pattern-matching library. We ran the 
pretty-printer on a set of C++ standard library headers and then ranked all the  
classes from the most-frequent to the least-frequent ones, on average. The 
resulting probability distribution resembled the power-law distribution, which means 
that for that specific application, the probability of some vtbl-pointers was much 
higher than the probability of many other vtbl-pointers taken altogether. In 
our case, the two most frequent classes were representing the use of a variable in 
a program, and their combined frequency was larger than the frequency of all the 
other nodes. Naturally, we would like to avoid conflicts on such classes in the 
cache, when possible.

To do this, our library provides a configuration flag that enables tracing the
frequencies of each vtbl-pointer in a switch and uses this information to 
minimize the number of conflicts. Due to page limitations, we refer the reader 
to the technical report accompanying this paper for more details on our 
experiments with the use of vtbl-pointer frequencies~\cite{TR}. Here we will only 
mention that, by default, we do not enable frequency tracing, because the 
significant drop in the number of actual collisions was not reflected in a 
noticeable decrease in execution time. This was because the total 
number of actual collisions, even in non-frequency based caching, was much smaller 
than the number of successful cache hits.
